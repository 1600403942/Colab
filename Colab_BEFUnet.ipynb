{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "GPU availability"
      ],
      "metadata": {
        "id": "mhhx8MbxloVB"
      },
      "id": "mhhx8MbxloVB"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR2lXA6RlnE4",
        "outputId": "036eb36c-18ec-4ce1-d33f-199a47eead7e"
      },
      "id": "aR2lXA6RlnE4",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar  7 12:51:46 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6iTphJ7Qjtpq"
      },
      "id": "6iTphJ7Qjtpq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db7e6f84",
      "metadata": {
        "id": "db7e6f84"
      },
      "source": [
        " Clone the BEFUnet repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8787023",
      "metadata": {
        "id": "b8787023"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Omid-Nejati/BEFUnet.git\n",
        "%cd /content/BEFUnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Packages"
      ],
      "metadata": {
        "id": "NG54HBvOmstN"
      },
      "id": "NG54HBvOmstN"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "XB8kbccDmrwy"
      },
      "id": "XB8kbccDmrwy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Synapse Dataset"
      ],
      "metadata": {
        "id": "pAe_RG0zmXV1"
      },
      "id": "pAe_RG0zmXV1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c94fc45",
      "metadata": {
        "id": "4c94fc45"
      },
      "outputs": [],
      "source": [
        "!gdown 1IGe2kUzBwpMR-HYUotc1pacNjrEo1ftz\n",
        "!unzip -xq ./data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfe6a31c",
      "metadata": {
        "id": "cfe6a31c"
      },
      "source": [
        "Train Model on Synapse Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e123c9",
      "metadata": {
        "id": "34e123c9",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b51bd12-a894-4b46-8e0d-bef93bee2e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "iteration 8383 : loss : 0.130909, loss_ce: 0.018933 loss_dice: 0.205560\n",
            "iteration 8384 : loss : 0.247649, loss_ce: 0.029945 loss_dice: 0.392785\n",
            "iteration 8385 : loss : 0.142819, loss_ce: 0.043097 loss_dice: 0.209301\n",
            "iteration 8386 : loss : 0.119909, loss_ce: 0.054214 loss_dice: 0.163706\n",
            "iteration 8387 : loss : 0.120749, loss_ce: 0.035330 loss_dice: 0.177695\n",
            "iteration 8388 : loss : 0.153861, loss_ce: 0.025095 loss_dice: 0.239705\n",
            "iteration 8389 : loss : 0.117910, loss_ce: 0.053822 loss_dice: 0.160635\n",
            "iteration 8390 : loss : 0.196263, loss_ce: 0.018883 loss_dice: 0.314516\n",
            "iteration 8391 : loss : 0.159574, loss_ce: 0.022476 loss_dice: 0.250973\n",
            "iteration 8392 : loss : 0.186397, loss_ce: 0.018319 loss_dice: 0.298448\n",
            "iteration 8393 : loss : 0.067184, loss_ce: 0.024137 loss_dice: 0.095882\n",
            "iteration 8394 : loss : 0.137181, loss_ce: 0.032384 loss_dice: 0.207045\n",
            "iteration 8395 : loss : 0.147556, loss_ce: 0.046553 loss_dice: 0.214891\n",
            "iteration 8396 : loss : 0.134903, loss_ce: 0.028668 loss_dice: 0.205726\n",
            "iteration 8397 : loss : 0.146358, loss_ce: 0.006200 loss_dice: 0.239797\n",
            "iteration 8398 : loss : 0.126358, loss_ce: 0.028695 loss_dice: 0.191466\n",
            "iteration 8399 : loss : 0.060730, loss_ce: 0.020023 loss_dice: 0.087868\n",
            "iteration 8400 : loss : 0.138194, loss_ce: 0.021971 loss_dice: 0.215677\n",
            "iteration 8401 : loss : 0.156884, loss_ce: 0.014332 loss_dice: 0.251919\n",
            "iteration 8402 : loss : 0.139439, loss_ce: 0.031490 loss_dice: 0.211404\n",
            "iteration 8403 : loss : 0.051232, loss_ce: 0.010978 loss_dice: 0.078067\n",
            "iteration 8404 : loss : 0.094832, loss_ce: 0.035399 loss_dice: 0.134454\n",
            "iteration 8405 : loss : 0.099432, loss_ce: 0.028893 loss_dice: 0.146458\n",
            "iteration 8406 : loss : 0.228900, loss_ce: 0.019025 loss_dice: 0.368818\n",
            "iteration 8407 : loss : 0.090657, loss_ce: 0.011066 loss_dice: 0.143718\n",
            "iteration 8408 : loss : 0.111551, loss_ce: 0.040500 loss_dice: 0.158918\n",
            "iteration 8409 : loss : 0.221057, loss_ce: 0.022810 loss_dice: 0.353222\n",
            "iteration 8410 : loss : 0.112279, loss_ce: 0.020105 loss_dice: 0.173728\n",
            "iteration 8411 : loss : 0.095674, loss_ce: 0.035018 loss_dice: 0.136112\n",
            "iteration 8412 : loss : 0.086287, loss_ce: 0.024586 loss_dice: 0.127421\n",
            "iteration 8413 : loss : 0.141300, loss_ce: 0.027145 loss_dice: 0.217403\n",
            "iteration 8414 : loss : 0.104576, loss_ce: 0.018304 loss_dice: 0.162090\n",
            "iteration 8415 : loss : 0.286604, loss_ce: 0.003407 loss_dice: 0.475402\n",
            "iteration 8416 : loss : 0.117173, loss_ce: 0.041557 loss_dice: 0.167584\n",
            "iteration 8417 : loss : 0.223957, loss_ce: 0.022599 loss_dice: 0.358195\n",
            "iteration 8418 : loss : 0.080725, loss_ce: 0.028067 loss_dice: 0.115830\n",
            "iteration 8419 : loss : 0.131552, loss_ce: 0.053890 loss_dice: 0.183327\n",
            "iteration 8420 : loss : 0.149513, loss_ce: 0.028625 loss_dice: 0.230105\n",
            "iteration 8421 : loss : 0.148534, loss_ce: 0.030716 loss_dice: 0.227079\n",
            "iteration 8422 : loss : 0.143231, loss_ce: 0.014898 loss_dice: 0.228787\n",
            "iteration 8423 : loss : 0.126812, loss_ce: 0.036220 loss_dice: 0.187207\n",
            "iteration 8424 : loss : 0.254378, loss_ce: 0.005437 loss_dice: 0.420339\n",
            "iteration 8425 : loss : 0.278672, loss_ce: 0.005190 loss_dice: 0.460993\n",
            "iteration 8426 : loss : 0.110187, loss_ce: 0.038431 loss_dice: 0.158024\n",
            "iteration 8427 : loss : 0.128361, loss_ce: 0.042153 loss_dice: 0.185833\n",
            "iteration 8428 : loss : 0.132247, loss_ce: 0.037018 loss_dice: 0.195732\n",
            "iteration 8429 : loss : 0.169193, loss_ce: 0.014150 loss_dice: 0.272555\n",
            "iteration 8430 : loss : 0.128260, loss_ce: 0.014034 loss_dice: 0.204411\n",
            "iteration 8431 : loss : 0.118973, loss_ce: 0.050479 loss_dice: 0.164636\n",
            "iteration 8432 : loss : 0.125345, loss_ce: 0.021499 loss_dice: 0.194576\n",
            "iteration 8433 : loss : 0.137932, loss_ce: 0.020319 loss_dice: 0.216340\n",
            "iteration 8434 : loss : 0.088972, loss_ce: 0.007744 loss_dice: 0.143124\n",
            "iteration 8435 : loss : 0.074217, loss_ce: 0.029269 loss_dice: 0.104183\n",
            "iteration 8436 : loss : 0.408765, loss_ce: 0.006662 loss_dice: 0.676833\n",
            "  8%|██                         | 38/500 [1:17:38<10:51:39, 84.63s/it]iteration 8437 : loss : 0.122306, loss_ce: 0.013964 loss_dice: 0.194534\n",
            "iteration 8438 : loss : 0.108202, loss_ce: 0.007628 loss_dice: 0.175251\n",
            "iteration 8439 : loss : 0.113101, loss_ce: 0.028264 loss_dice: 0.169660\n",
            "iteration 8440 : loss : 0.148308, loss_ce: 0.012300 loss_dice: 0.238980\n",
            "iteration 8441 : loss : 0.076734, loss_ce: 0.013354 loss_dice: 0.118987\n",
            "iteration 8442 : loss : 0.082369, loss_ce: 0.015284 loss_dice: 0.127092\n",
            "iteration 8443 : loss : 0.096922, loss_ce: 0.050781 loss_dice: 0.127683\n",
            "iteration 8444 : loss : 0.117242, loss_ce: 0.011008 loss_dice: 0.188065\n",
            "iteration 8445 : loss : 0.090846, loss_ce: 0.031222 loss_dice: 0.130595\n",
            "iteration 8446 : loss : 0.159719, loss_ce: 0.044398 loss_dice: 0.236599\n",
            "iteration 8447 : loss : 0.085399, loss_ce: 0.032916 loss_dice: 0.120388\n",
            "iteration 8448 : loss : 0.124104, loss_ce: 0.024102 loss_dice: 0.190772\n",
            "iteration 8449 : loss : 0.111192, loss_ce: 0.029608 loss_dice: 0.165581\n",
            "iteration 8450 : loss : 0.404579, loss_ce: 0.001665 loss_dice: 0.673188\n",
            "iteration 8451 : loss : 0.124320, loss_ce: 0.019076 loss_dice: 0.194482\n",
            "iteration 8452 : loss : 0.297883, loss_ce: 0.014351 loss_dice: 0.486904\n",
            "iteration 8453 : loss : 0.132259, loss_ce: 0.036568 loss_dice: 0.196054\n",
            "iteration 8454 : loss : 0.120526, loss_ce: 0.043432 loss_dice: 0.171922\n",
            "iteration 8455 : loss : 0.072567, loss_ce: 0.018002 loss_dice: 0.108943\n",
            "iteration 8456 : loss : 0.090465, loss_ce: 0.012531 loss_dice: 0.142421\n",
            "iteration 8457 : loss : 0.092699, loss_ce: 0.014524 loss_dice: 0.144816\n",
            "iteration 8458 : loss : 0.074850, loss_ce: 0.038056 loss_dice: 0.099380\n",
            "iteration 8459 : loss : 0.118069, loss_ce: 0.023121 loss_dice: 0.181367\n",
            "iteration 8460 : loss : 0.107314, loss_ce: 0.049780 loss_dice: 0.145670\n",
            "iteration 8461 : loss : 0.136658, loss_ce: 0.037000 loss_dice: 0.203096\n",
            "iteration 8462 : loss : 0.140915, loss_ce: 0.032669 loss_dice: 0.213080\n",
            "iteration 8463 : loss : 0.310412, loss_ce: 0.017640 loss_dice: 0.505594\n",
            "iteration 8464 : loss : 0.099701, loss_ce: 0.034585 loss_dice: 0.143111\n",
            "iteration 8465 : loss : 0.105214, loss_ce: 0.036987 loss_dice: 0.150698\n",
            "iteration 8466 : loss : 0.115533, loss_ce: 0.012868 loss_dice: 0.183976\n",
            "iteration 8467 : loss : 0.149162, loss_ce: 0.010881 loss_dice: 0.241349\n",
            "iteration 8468 : loss : 0.092711, loss_ce: 0.030812 loss_dice: 0.133978\n",
            "iteration 8469 : loss : 0.203437, loss_ce: 0.024348 loss_dice: 0.322829\n",
            "iteration 8470 : loss : 0.096546, loss_ce: 0.038206 loss_dice: 0.135440\n",
            "iteration 8471 : loss : 0.078375, loss_ce: 0.033989 loss_dice: 0.107966\n",
            "iteration 8472 : loss : 0.169077, loss_ce: 0.014456 loss_dice: 0.272157\n",
            "iteration 8473 : loss : 0.170040, loss_ce: 0.010136 loss_dice: 0.276643\n",
            "iteration 8474 : loss : 0.111064, loss_ce: 0.038178 loss_dice: 0.159656\n",
            "iteration 8475 : loss : 0.124154, loss_ce: 0.019235 loss_dice: 0.194099\n",
            "iteration 8476 : loss : 0.126620, loss_ce: 0.023137 loss_dice: 0.195608\n",
            "iteration 8477 : loss : 0.194326, loss_ce: 0.026603 loss_dice: 0.306141\n",
            "iteration 8478 : loss : 0.116588, loss_ce: 0.019872 loss_dice: 0.181066\n",
            "iteration 8479 : loss : 0.146907, loss_ce: 0.029226 loss_dice: 0.225360\n",
            "iteration 8480 : loss : 0.149770, loss_ce: 0.026859 loss_dice: 0.231711\n",
            "iteration 8481 : loss : 0.143850, loss_ce: 0.022238 loss_dice: 0.224924\n",
            "iteration 8482 : loss : 0.089622, loss_ce: 0.032731 loss_dice: 0.127549\n",
            "iteration 8483 : loss : 0.197049, loss_ce: 0.050864 loss_dice: 0.294505\n",
            "iteration 8484 : loss : 0.123877, loss_ce: 0.037888 loss_dice: 0.181203\n",
            "iteration 8485 : loss : 0.111820, loss_ce: 0.011222 loss_dice: 0.178885\n",
            "iteration 8486 : loss : 0.070581, loss_ce: 0.017261 loss_dice: 0.106128\n",
            "iteration 8487 : loss : 0.078541, loss_ce: 0.024653 loss_dice: 0.114466\n",
            "iteration 8488 : loss : 0.066011, loss_ce: 0.019889 loss_dice: 0.096759\n",
            "iteration 8489 : loss : 0.103838, loss_ce: 0.037941 loss_dice: 0.147770\n",
            "iteration 8490 : loss : 0.067205, loss_ce: 0.015704 loss_dice: 0.101538\n",
            "iteration 8491 : loss : 0.196440, loss_ce: 0.012791 loss_dice: 0.318873\n",
            "iteration 8492 : loss : 0.130840, loss_ce: 0.012033 loss_dice: 0.210045\n",
            "iteration 8493 : loss : 0.184433, loss_ce: 0.043180 loss_dice: 0.278601\n",
            "iteration 8494 : loss : 0.105302, loss_ce: 0.017531 loss_dice: 0.163816\n",
            "iteration 8495 : loss : 0.171023, loss_ce: 0.008003 loss_dice: 0.279702\n",
            "iteration 8496 : loss : 0.077246, loss_ce: 0.026364 loss_dice: 0.111167\n",
            "iteration 8497 : loss : 0.148109, loss_ce: 0.014211 loss_dice: 0.237375\n",
            "iteration 8498 : loss : 0.152850, loss_ce: 0.039553 loss_dice: 0.228382\n",
            "iteration 8499 : loss : 0.069045, loss_ce: 0.031284 loss_dice: 0.094220\n",
            "iteration 8500 : loss : 0.182477, loss_ce: 0.016723 loss_dice: 0.292981\n",
            "iteration 8501 : loss : 0.144075, loss_ce: 0.034200 loss_dice: 0.217325\n",
            "iteration 8502 : loss : 0.078875, loss_ce: 0.017466 loss_dice: 0.119814\n",
            "iteration 8503 : loss : 0.199727, loss_ce: 0.019463 loss_dice: 0.319903\n",
            "iteration 8504 : loss : 0.145439, loss_ce: 0.037174 loss_dice: 0.217615\n",
            "iteration 8505 : loss : 0.104065, loss_ce: 0.025367 loss_dice: 0.156530\n",
            "iteration 8506 : loss : 0.294502, loss_ce: 0.005731 loss_dice: 0.487016\n",
            "iteration 8507 : loss : 0.136528, loss_ce: 0.038626 loss_dice: 0.201796\n",
            "iteration 8508 : loss : 0.113150, loss_ce: 0.034545 loss_dice: 0.165553\n",
            "iteration 8509 : loss : 0.194944, loss_ce: 0.007955 loss_dice: 0.319602\n",
            "iteration 8510 : loss : 0.144458, loss_ce: 0.043953 loss_dice: 0.211462\n",
            "iteration 8511 : loss : 0.183653, loss_ce: 0.023220 loss_dice: 0.290608\n",
            "iteration 8512 : loss : 0.088233, loss_ce: 0.037200 loss_dice: 0.122255\n",
            "iteration 8513 : loss : 0.101707, loss_ce: 0.025234 loss_dice: 0.152689\n",
            "iteration 8514 : loss : 0.073553, loss_ce: 0.021602 loss_dice: 0.108188\n",
            "iteration 8515 : loss : 0.102572, loss_ce: 0.031754 loss_dice: 0.149784\n",
            "iteration 8516 : loss : 0.131273, loss_ce: 0.026750 loss_dice: 0.200954\n",
            "iteration 8517 : loss : 0.205681, loss_ce: 0.024278 loss_dice: 0.326616\n",
            "iteration 8518 : loss : 0.198063, loss_ce: 0.010884 loss_dice: 0.322848\n",
            "iteration 8519 : loss : 0.088055, loss_ce: 0.027470 loss_dice: 0.128445\n",
            "iteration 8520 : loss : 0.114406, loss_ce: 0.016786 loss_dice: 0.179486\n",
            "iteration 8521 : loss : 0.080425, loss_ce: 0.014953 loss_dice: 0.124073\n",
            "iteration 8522 : loss : 0.126685, loss_ce: 0.012239 loss_dice: 0.202982\n",
            "iteration 8523 : loss : 0.086396, loss_ce: 0.027855 loss_dice: 0.125423\n",
            "iteration 8524 : loss : 0.101530, loss_ce: 0.035167 loss_dice: 0.145772\n",
            "iteration 8525 : loss : 0.111723, loss_ce: 0.020377 loss_dice: 0.172621\n",
            "iteration 8526 : loss : 0.100905, loss_ce: 0.025817 loss_dice: 0.150964\n",
            "iteration 8527 : loss : 0.074271, loss_ce: 0.031834 loss_dice: 0.102562\n",
            "iteration 8528 : loss : 0.080398, loss_ce: 0.026461 loss_dice: 0.116356\n",
            "iteration 8529 : loss : 0.139552, loss_ce: 0.029455 loss_dice: 0.212950\n",
            "iteration 8530 : loss : 0.103090, loss_ce: 0.041232 loss_dice: 0.144328\n",
            "iteration 8531 : loss : 0.092063, loss_ce: 0.028546 loss_dice: 0.134407\n",
            "iteration 8532 : loss : 0.166739, loss_ce: 0.045720 loss_dice: 0.247418\n",
            "iteration 8533 : loss : 0.241722, loss_ce: 0.022011 loss_dice: 0.388197\n",
            "iteration 8534 : loss : 0.093020, loss_ce: 0.023508 loss_dice: 0.139361\n",
            "iteration 8535 : loss : 0.140159, loss_ce: 0.032623 loss_dice: 0.211850\n",
            "iteration 8536 : loss : 0.103886, loss_ce: 0.035695 loss_dice: 0.149347\n",
            "iteration 8537 : loss : 0.183301, loss_ce: 0.020370 loss_dice: 0.291921\n",
            "iteration 8538 : loss : 0.097832, loss_ce: 0.053193 loss_dice: 0.127591\n",
            "iteration 8539 : loss : 0.306965, loss_ce: 0.003305 loss_dice: 0.509404\n",
            "iteration 8540 : loss : 0.093912, loss_ce: 0.047193 loss_dice: 0.125058\n",
            "iteration 8541 : loss : 0.065521, loss_ce: 0.018503 loss_dice: 0.096866\n",
            "iteration 8542 : loss : 0.153900, loss_ce: 0.014404 loss_dice: 0.246898\n",
            "iteration 8543 : loss : 0.224237, loss_ce: 0.003527 loss_dice: 0.371376\n",
            "iteration 8544 : loss : 0.162757, loss_ce: 0.030076 loss_dice: 0.251211\n",
            "iteration 8545 : loss : 0.081098, loss_ce: 0.023002 loss_dice: 0.119828\n",
            "iteration 8546 : loss : 0.096574, loss_ce: 0.016309 loss_dice: 0.150084\n",
            "iteration 8547 : loss : 0.136660, loss_ce: 0.064444 loss_dice: 0.184804\n",
            "iteration 8548 : loss : 0.063039, loss_ce: 0.016323 loss_dice: 0.094182\n",
            "iteration 8549 : loss : 0.139908, loss_ce: 0.030257 loss_dice: 0.213008\n",
            "iteration 8550 : loss : 0.208114, loss_ce: 0.049018 loss_dice: 0.314178\n",
            "iteration 8551 : loss : 0.138591, loss_ce: 0.047550 loss_dice: 0.199285\n",
            "iteration 8552 : loss : 0.160449, loss_ce: 0.048750 loss_dice: 0.234915\n",
            "iteration 8553 : loss : 0.198808, loss_ce: 0.022788 loss_dice: 0.316155\n",
            "iteration 8554 : loss : 0.145197, loss_ce: 0.020850 loss_dice: 0.228096\n",
            "iteration 8555 : loss : 0.183481, loss_ce: 0.012200 loss_dice: 0.297669\n",
            "iteration 8556 : loss : 0.156867, loss_ce: 0.026010 loss_dice: 0.244104\n",
            "iteration 8557 : loss : 0.137825, loss_ce: 0.024978 loss_dice: 0.213056\n",
            "iteration 8558 : loss : 0.124135, loss_ce: 0.016068 loss_dice: 0.196180\n",
            "iteration 8559 : loss : 0.088793, loss_ce: 0.027020 loss_dice: 0.129974\n",
            "iteration 8560 : loss : 0.130716, loss_ce: 0.036663 loss_dice: 0.193417\n",
            "iteration 8561 : loss : 0.095481, loss_ce: 0.028536 loss_dice: 0.140110\n",
            "iteration 8562 : loss : 0.148640, loss_ce: 0.035026 loss_dice: 0.224383\n",
            "iteration 8563 : loss : 0.176022, loss_ce: 0.031676 loss_dice: 0.272252\n",
            "iteration 8564 : loss : 0.090693, loss_ce: 0.037006 loss_dice: 0.126484\n",
            "iteration 8565 : loss : 0.135967, loss_ce: 0.020440 loss_dice: 0.212986\n",
            "iteration 8566 : loss : 0.144589, loss_ce: 0.021247 loss_dice: 0.226818\n",
            "iteration 8567 : loss : 0.136755, loss_ce: 0.012486 loss_dice: 0.219601\n",
            "iteration 8568 : loss : 0.065370, loss_ce: 0.006727 loss_dice: 0.104465\n",
            "iteration 8569 : loss : 0.113189, loss_ce: 0.037634 loss_dice: 0.163559\n",
            "iteration 8570 : loss : 0.137184, loss_ce: 0.016699 loss_dice: 0.217508\n",
            "iteration 8571 : loss : 0.124467, loss_ce: 0.027511 loss_dice: 0.189104\n",
            "iteration 8572 : loss : 0.124906, loss_ce: 0.026805 loss_dice: 0.190306\n",
            "iteration 8573 : loss : 0.136257, loss_ce: 0.035688 loss_dice: 0.203304\n",
            "iteration 8574 : loss : 0.120145, loss_ce: 0.048596 loss_dice: 0.167845\n",
            "iteration 8575 : loss : 0.171599, loss_ce: 0.023521 loss_dice: 0.270317\n",
            "iteration 8576 : loss : 0.248271, loss_ce: 0.025403 loss_dice: 0.396850\n",
            "iteration 8577 : loss : 0.122814, loss_ce: 0.030027 loss_dice: 0.184673\n",
            "iteration 8578 : loss : 0.147329, loss_ce: 0.011010 loss_dice: 0.238209\n",
            "iteration 8579 : loss : 0.147385, loss_ce: 0.040360 loss_dice: 0.218735\n",
            "iteration 8580 : loss : 0.120593, loss_ce: 0.048239 loss_dice: 0.168828\n",
            "iteration 8581 : loss : 0.204785, loss_ce: 0.022776 loss_dice: 0.326125\n",
            "iteration 8582 : loss : 0.208369, loss_ce: 0.026985 loss_dice: 0.329292\n",
            "iteration 8583 : loss : 0.074935, loss_ce: 0.038672 loss_dice: 0.099110\n",
            "iteration 8584 : loss : 0.139627, loss_ce: 0.015316 loss_dice: 0.222501\n",
            "iteration 8585 : loss : 0.155454, loss_ce: 0.053862 loss_dice: 0.223182\n",
            "iteration 8586 : loss : 0.274326, loss_ce: 0.018881 loss_dice: 0.444623\n",
            "iteration 8587 : loss : 0.185788, loss_ce: 0.037747 loss_dice: 0.284482\n",
            "iteration 8588 : loss : 0.064727, loss_ce: 0.011274 loss_dice: 0.100363\n",
            "iteration 8589 : loss : 0.111833, loss_ce: 0.023314 loss_dice: 0.170845\n",
            "iteration 8590 : loss : 0.127421, loss_ce: 0.053608 loss_dice: 0.176629\n",
            "iteration 8591 : loss : 0.112692, loss_ce: 0.059285 loss_dice: 0.148296\n",
            "iteration 8592 : loss : 0.130184, loss_ce: 0.032257 loss_dice: 0.195469\n",
            "iteration 8593 : loss : 0.299414, loss_ce: 0.029849 loss_dice: 0.479124\n",
            "iteration 8594 : loss : 0.085045, loss_ce: 0.012915 loss_dice: 0.133132\n",
            "iteration 8595 : loss : 0.139794, loss_ce: 0.032574 loss_dice: 0.211274\n",
            "iteration 8596 : loss : 0.133317, loss_ce: 0.030015 loss_dice: 0.202185\n",
            "iteration 8597 : loss : 0.111291, loss_ce: 0.041321 loss_dice: 0.157938\n",
            "iteration 8598 : loss : 0.059448, loss_ce: 0.008191 loss_dice: 0.093619\n",
            "iteration 8599 : loss : 0.097727, loss_ce: 0.043875 loss_dice: 0.133629\n",
            "iteration 8600 : loss : 0.147515, loss_ce: 0.038906 loss_dice: 0.219921\n",
            "iteration 8601 : loss : 0.238073, loss_ce: 0.026331 loss_dice: 0.379234\n",
            "iteration 8602 : loss : 0.096814, loss_ce: 0.033959 loss_dice: 0.138716\n",
            "iteration 8603 : loss : 0.178842, loss_ce: 0.009382 loss_dice: 0.291816\n",
            "iteration 8604 : loss : 0.091250, loss_ce: 0.024216 loss_dice: 0.135940\n",
            "iteration 8605 : loss : 0.167054, loss_ce: 0.012358 loss_dice: 0.270185\n",
            "iteration 8606 : loss : 0.098010, loss_ce: 0.033445 loss_dice: 0.141053\n",
            "iteration 8607 : loss : 0.127190, loss_ce: 0.030566 loss_dice: 0.191606\n",
            "iteration 8608 : loss : 0.163696, loss_ce: 0.030576 loss_dice: 0.252443\n",
            "iteration 8609 : loss : 0.122570, loss_ce: 0.038021 loss_dice: 0.178936\n",
            "iteration 8610 : loss : 0.164405, loss_ce: 0.022756 loss_dice: 0.258837\n",
            "iteration 8611 : loss : 0.247564, loss_ce: 0.005742 loss_dice: 0.408779\n",
            "iteration 8612 : loss : 0.180824, loss_ce: 0.008692 loss_dice: 0.295578\n",
            "iteration 8613 : loss : 0.176621, loss_ce: 0.060239 loss_dice: 0.254209\n",
            "iteration 8614 : loss : 0.181557, loss_ce: 0.070380 loss_dice: 0.255675\n",
            "iteration 8615 : loss : 0.139854, loss_ce: 0.017978 loss_dice: 0.221104\n",
            "iteration 8616 : loss : 0.141497, loss_ce: 0.054841 loss_dice: 0.199267\n",
            "iteration 8617 : loss : 0.228871, loss_ce: 0.011239 loss_dice: 0.373958\n",
            "iteration 8618 : loss : 0.154060, loss_ce: 0.047551 loss_dice: 0.225066\n",
            "iteration 8619 : loss : 0.117257, loss_ce: 0.018091 loss_dice: 0.183368\n",
            "iteration 8620 : loss : 0.170955, loss_ce: 0.045018 loss_dice: 0.254913\n",
            "iteration 8621 : loss : 0.091680, loss_ce: 0.023934 loss_dice: 0.136844\n",
            "iteration 8622 : loss : 0.220767, loss_ce: 0.035392 loss_dice: 0.344351\n",
            "iteration 8623 : loss : 0.147670, loss_ce: 0.028354 loss_dice: 0.227214\n",
            "iteration 8624 : loss : 0.206580, loss_ce: 0.011864 loss_dice: 0.336391\n",
            "iteration 8625 : loss : 0.144213, loss_ce: 0.028101 loss_dice: 0.221621\n",
            "iteration 8626 : loss : 0.157389, loss_ce: 0.040646 loss_dice: 0.235218\n",
            "iteration 8627 : loss : 0.133872, loss_ce: 0.030843 loss_dice: 0.202558\n",
            "iteration 8628 : loss : 0.138413, loss_ce: 0.032663 loss_dice: 0.208913\n",
            "iteration 8629 : loss : 0.161959, loss_ce: 0.047404 loss_dice: 0.238329\n",
            "iteration 8630 : loss : 0.130633, loss_ce: 0.015744 loss_dice: 0.207226\n",
            "iteration 8631 : loss : 0.185084, loss_ce: 0.027253 loss_dice: 0.290305\n",
            "iteration 8632 : loss : 0.203473, loss_ce: 0.024288 loss_dice: 0.322930\n",
            "iteration 8633 : loss : 0.073227, loss_ce: 0.019782 loss_dice: 0.108857\n",
            "iteration 8634 : loss : 0.255066, loss_ce: 0.019700 loss_dice: 0.411977\n",
            "iteration 8635 : loss : 0.150362, loss_ce: 0.039864 loss_dice: 0.224027\n",
            "iteration 8636 : loss : 0.154648, loss_ce: 0.037159 loss_dice: 0.232974\n",
            "iteration 8637 : loss : 0.198480, loss_ce: 0.018909 loss_dice: 0.318195\n",
            "iteration 8638 : loss : 0.138379, loss_ce: 0.030087 loss_dice: 0.210574\n",
            "iteration 8639 : loss : 0.111668, loss_ce: 0.037856 loss_dice: 0.160876\n",
            "iteration 8640 : loss : 0.110783, loss_ce: 0.018110 loss_dice: 0.172566\n",
            "iteration 8641 : loss : 0.148243, loss_ce: 0.059005 loss_dice: 0.207735\n",
            "iteration 8642 : loss : 0.047657, loss_ce: 0.019990 loss_dice: 0.066102\n",
            "iteration 8643 : loss : 0.214948, loss_ce: 0.009024 loss_dice: 0.352230\n",
            "iteration 8644 : loss : 0.127216, loss_ce: 0.048138 loss_dice: 0.179935\n",
            "iteration 8645 : loss : 0.122635, loss_ce: 0.010891 loss_dice: 0.197130\n",
            "iteration 8646 : loss : 0.161290, loss_ce: 0.047891 loss_dice: 0.236890\n",
            "iteration 8647 : loss : 0.135033, loss_ce: 0.030746 loss_dice: 0.204558\n",
            "iteration 8648 : loss : 0.163875, loss_ce: 0.026880 loss_dice: 0.255205\n",
            "iteration 8649 : loss : 0.172559, loss_ce: 0.019967 loss_dice: 0.274288\n",
            "iteration 8650 : loss : 0.176687, loss_ce: 0.027052 loss_dice: 0.276444\n",
            "iteration 8651 : loss : 0.072876, loss_ce: 0.033716 loss_dice: 0.098982\n",
            "iteration 8652 : loss : 0.242462, loss_ce: 0.032235 loss_dice: 0.382613\n",
            "iteration 8653 : loss : 0.161133, loss_ce: 0.079592 loss_dice: 0.215494\n",
            "iteration 8654 : loss : 0.152718, loss_ce: 0.022725 loss_dice: 0.239380\n",
            "iteration 8655 : loss : 0.144488, loss_ce: 0.051939 loss_dice: 0.206188\n",
            "iteration 8656 : loss : 0.135377, loss_ce: 0.040569 loss_dice: 0.198582\n",
            "iteration 8657 : loss : 0.114126, loss_ce: 0.043000 loss_dice: 0.161544\n",
            "iteration 8658 : loss : 0.216915, loss_ce: 0.000027 loss_dice: 0.361507\n",
            "  8%|██                         | 39/500 [1:19:01<10:47:05, 84.22s/it]iteration 8659 : loss : 0.119271, loss_ce: 0.025671 loss_dice: 0.181670\n",
            "iteration 8660 : loss : 0.273112, loss_ce: 0.061444 loss_dice: 0.414224\n",
            "iteration 8661 : loss : 0.168127, loss_ce: 0.076036 loss_dice: 0.229521\n",
            "iteration 8662 : loss : 0.241747, loss_ce: 0.030186 loss_dice: 0.382788\n",
            "iteration 8663 : loss : 0.121128, loss_ce: 0.027841 loss_dice: 0.183319\n",
            "iteration 8664 : loss : 0.086515, loss_ce: 0.023646 loss_dice: 0.128428\n",
            "iteration 8665 : loss : 0.129524, loss_ce: 0.018496 loss_dice: 0.203543\n",
            "iteration 8666 : loss : 0.155165, loss_ce: 0.044122 loss_dice: 0.229193\n",
            "iteration 8667 : loss : 0.113734, loss_ce: 0.034196 loss_dice: 0.166758\n",
            "iteration 8668 : loss : 0.174267, loss_ce: 0.090962 loss_dice: 0.229804\n",
            "iteration 8669 : loss : 0.168755, loss_ce: 0.029672 loss_dice: 0.261477\n",
            "iteration 8670 : loss : 0.168403, loss_ce: 0.089105 loss_dice: 0.221269\n",
            "iteration 8671 : loss : 0.119108, loss_ce: 0.039364 loss_dice: 0.172270\n",
            "iteration 8672 : loss : 0.165453, loss_ce: 0.071322 loss_dice: 0.228207\n",
            "iteration 8673 : loss : 0.089669, loss_ce: 0.036948 loss_dice: 0.124816\n",
            "iteration 8674 : loss : 0.102510, loss_ce: 0.015139 loss_dice: 0.160757\n",
            "iteration 8675 : loss : 0.199948, loss_ce: 0.028594 loss_dice: 0.314184\n",
            "iteration 8676 : loss : 0.190169, loss_ce: 0.056380 loss_dice: 0.279362\n",
            "iteration 8677 : loss : 0.229879, loss_ce: 0.083725 loss_dice: 0.327314\n",
            "iteration 8678 : loss : 0.135268, loss_ce: 0.012118 loss_dice: 0.217367\n",
            "iteration 8679 : loss : 0.149142, loss_ce: 0.023772 loss_dice: 0.232723\n",
            "iteration 8680 : loss : 0.154689, loss_ce: 0.031773 loss_dice: 0.236632\n",
            "iteration 8681 : loss : 0.163947, loss_ce: 0.056321 loss_dice: 0.235698\n",
            "iteration 8682 : loss : 0.096326, loss_ce: 0.013942 loss_dice: 0.151249\n",
            "iteration 8683 : loss : 0.140434, loss_ce: 0.049209 loss_dice: 0.201251\n",
            "iteration 8684 : loss : 0.138870, loss_ce: 0.030977 loss_dice: 0.210799\n",
            "iteration 8685 : loss : 0.215257, loss_ce: 0.058815 loss_dice: 0.319551\n",
            "iteration 8686 : loss : 0.167535, loss_ce: 0.061405 loss_dice: 0.238288\n",
            "iteration 8687 : loss : 0.120797, loss_ce: 0.028461 loss_dice: 0.182354\n",
            "iteration 8688 : loss : 0.133389, loss_ce: 0.042765 loss_dice: 0.193805\n",
            "iteration 8689 : loss : 0.203512, loss_ce: 0.013189 loss_dice: 0.330393\n",
            "iteration 8690 : loss : 0.303246, loss_ce: 0.013434 loss_dice: 0.496455\n",
            "iteration 8691 : loss : 0.243212, loss_ce: 0.036545 loss_dice: 0.380989\n",
            "iteration 8692 : loss : 0.119335, loss_ce: 0.026224 loss_dice: 0.181410\n",
            "iteration 8693 : loss : 0.088075, loss_ce: 0.031365 loss_dice: 0.125881\n",
            "iteration 8694 : loss : 0.154491, loss_ce: 0.054249 loss_dice: 0.221319\n",
            "iteration 8695 : loss : 0.155260, loss_ce: 0.081948 loss_dice: 0.204135\n",
            "iteration 8696 : loss : 0.145569, loss_ce: 0.029138 loss_dice: 0.223190\n",
            "iteration 8697 : loss : 0.132024, loss_ce: 0.037284 loss_dice: 0.195184\n",
            "iteration 8698 : loss : 0.111978, loss_ce: 0.010993 loss_dice: 0.179301\n",
            "iteration 8699 : loss : 0.155427, loss_ce: 0.014191 loss_dice: 0.249584\n",
            "iteration 8700 : loss : 0.163828, loss_ce: 0.021666 loss_dice: 0.258602\n",
            "iteration 8701 : loss : 0.114314, loss_ce: 0.021027 loss_dice: 0.176506\n",
            "iteration 8702 : loss : 0.211372, loss_ce: 0.035274 loss_dice: 0.328770\n",
            "iteration 8703 : loss : 0.121216, loss_ce: 0.027859 loss_dice: 0.183454\n",
            "iteration 8704 : loss : 0.124427, loss_ce: 0.007658 loss_dice: 0.202273\n",
            "iteration 8705 : loss : 0.115047, loss_ce: 0.007786 loss_dice: 0.186554\n",
            "iteration 8706 : loss : 0.113744, loss_ce: 0.017162 loss_dice: 0.178132\n",
            "iteration 8707 : loss : 0.165982, loss_ce: 0.023786 loss_dice: 0.260780\n",
            "iteration 8708 : loss : 0.104021, loss_ce: 0.034069 loss_dice: 0.150655\n",
            "iteration 8709 : loss : 0.192781, loss_ce: 0.035154 loss_dice: 0.297866\n",
            "iteration 8710 : loss : 0.183379, loss_ce: 0.054920 loss_dice: 0.269019\n",
            "iteration 8711 : loss : 0.178799, loss_ce: 0.030386 loss_dice: 0.277741\n",
            "iteration 8712 : loss : 0.144158, loss_ce: 0.037277 loss_dice: 0.215412\n",
            "iteration 8713 : loss : 0.230548, loss_ce: 0.038983 loss_dice: 0.358258\n",
            "iteration 8714 : loss : 0.198343, loss_ce: 0.078129 loss_dice: 0.278485\n",
            "iteration 8715 : loss : 0.180829, loss_ce: 0.048216 loss_dice: 0.269237\n",
            "iteration 8716 : loss : 0.183396, loss_ce: 0.056639 loss_dice: 0.267901\n",
            "iteration 8717 : loss : 0.171461, loss_ce: 0.084097 loss_dice: 0.229703\n",
            "iteration 8718 : loss : 0.192641, loss_ce: 0.076806 loss_dice: 0.269864\n",
            "iteration 8719 : loss : 0.263663, loss_ce: 0.036058 loss_dice: 0.415400\n",
            "iteration 8720 : loss : 0.246661, loss_ce: 0.048845 loss_dice: 0.378538\n",
            "iteration 8721 : loss : 0.171838, loss_ce: 0.030189 loss_dice: 0.266271\n",
            "iteration 8722 : loss : 0.217130, loss_ce: 0.006247 loss_dice: 0.357719\n",
            "iteration 8723 : loss : 0.160354, loss_ce: 0.037788 loss_dice: 0.242065\n",
            "iteration 8724 : loss : 0.229320, loss_ce: 0.025637 loss_dice: 0.365108\n",
            "iteration 8725 : loss : 0.103633, loss_ce: 0.026079 loss_dice: 0.155336\n",
            "iteration 8726 : loss : 0.167434, loss_ce: 0.046442 loss_dice: 0.248095\n",
            "iteration 8727 : loss : 0.287779, loss_ce: 0.017167 loss_dice: 0.468186\n",
            "iteration 8728 : loss : 0.138829, loss_ce: 0.039107 loss_dice: 0.205310\n",
            "iteration 8729 : loss : 0.224073, loss_ce: 0.027061 loss_dice: 0.355415\n",
            "iteration 8730 : loss : 0.110623, loss_ce: 0.051570 loss_dice: 0.149991\n",
            "iteration 8731 : loss : 0.179589, loss_ce: 0.052428 loss_dice: 0.264363\n",
            "iteration 8732 : loss : 0.170073, loss_ce: 0.053230 loss_dice: 0.247969\n",
            "iteration 8733 : loss : 0.219374, loss_ce: 0.021448 loss_dice: 0.351324\n",
            "iteration 8734 : loss : 0.183939, loss_ce: 0.074579 loss_dice: 0.256846\n",
            "iteration 8735 : loss : 0.148363, loss_ce: 0.044788 loss_dice: 0.217413\n",
            "iteration 8736 : loss : 0.138547, loss_ce: 0.044621 loss_dice: 0.201165\n",
            "iteration 8737 : loss : 0.124765, loss_ce: 0.033846 loss_dice: 0.185377\n",
            "iteration 8738 : loss : 0.106503, loss_ce: 0.024186 loss_dice: 0.161380\n",
            "iteration 8739 : loss : 0.126385, loss_ce: 0.033061 loss_dice: 0.188602\n",
            "iteration 8740 : loss : 0.220786, loss_ce: 0.017446 loss_dice: 0.356345\n",
            "iteration 8741 : loss : 0.095961, loss_ce: 0.033663 loss_dice: 0.137493\n",
            "iteration 8742 : loss : 0.081008, loss_ce: 0.027403 loss_dice: 0.116744\n",
            "iteration 8743 : loss : 0.080500, loss_ce: 0.037746 loss_dice: 0.109004\n",
            "iteration 8744 : loss : 0.164943, loss_ce: 0.023666 loss_dice: 0.259128\n",
            "iteration 8745 : loss : 0.121388, loss_ce: 0.036908 loss_dice: 0.177709\n",
            "iteration 8746 : loss : 0.248650, loss_ce: 0.026161 loss_dice: 0.396976\n",
            "iteration 8747 : loss : 0.167532, loss_ce: 0.035973 loss_dice: 0.255239\n",
            "iteration 8748 : loss : 0.174886, loss_ce: 0.080203 loss_dice: 0.238008\n",
            "iteration 8749 : loss : 0.225213, loss_ce: 0.048773 loss_dice: 0.342839\n",
            "iteration 8750 : loss : 0.142390, loss_ce: 0.037422 loss_dice: 0.212369\n",
            "iteration 8751 : loss : 0.207326, loss_ce: 0.075410 loss_dice: 0.295271\n",
            "iteration 8752 : loss : 0.304384, loss_ce: 0.057009 loss_dice: 0.469301\n",
            "iteration 8753 : loss : 0.258562, loss_ce: 0.090099 loss_dice: 0.370871\n",
            "iteration 8754 : loss : 0.175630, loss_ce: 0.048952 loss_dice: 0.260081\n",
            "iteration 8755 : loss : 0.245874, loss_ce: 0.083477 loss_dice: 0.354140\n",
            "iteration 8756 : loss : 0.266844, loss_ce: 0.104346 loss_dice: 0.375176\n",
            "iteration 8757 : loss : 0.194748, loss_ce: 0.081280 loss_dice: 0.270394\n",
            "iteration 8758 : loss : 0.261847, loss_ce: 0.117734 loss_dice: 0.357923\n",
            "iteration 8759 : loss : 0.201247, loss_ce: 0.086838 loss_dice: 0.277520\n",
            "iteration 8760 : loss : 0.193731, loss_ce: 0.053395 loss_dice: 0.287287\n",
            "iteration 8761 : loss : 0.229003, loss_ce: 0.129262 loss_dice: 0.295497\n",
            "iteration 8762 : loss : 0.228917, loss_ce: 0.098366 loss_dice: 0.315951\n",
            "iteration 8763 : loss : 0.411214, loss_ce: 0.003895 loss_dice: 0.682759\n",
            "iteration 8764 : loss : 0.269340, loss_ce: 0.048341 loss_dice: 0.416672\n",
            "iteration 8765 : loss : 0.192355, loss_ce: 0.061084 loss_dice: 0.279869\n",
            "iteration 8766 : loss : 0.167016, loss_ce: 0.029888 loss_dice: 0.258435\n",
            "iteration 8767 : loss : 0.229464, loss_ce: 0.013076 loss_dice: 0.373723\n",
            "iteration 8768 : loss : 0.157764, loss_ce: 0.064474 loss_dice: 0.219958\n",
            "iteration 8769 : loss : 0.254744, loss_ce: 0.039877 loss_dice: 0.397989\n",
            "iteration 8770 : loss : 0.174779, loss_ce: 0.078796 loss_dice: 0.238767\n",
            "iteration 8771 : loss : 0.217381, loss_ce: 0.083716 loss_dice: 0.306490\n",
            "iteration 8772 : loss : 0.234489, loss_ce: 0.024840 loss_dice: 0.374255\n",
            "iteration 8773 : loss : 0.243850, loss_ce: 0.024601 loss_dice: 0.390015\n",
            "iteration 8774 : loss : 0.144633, loss_ce: 0.034031 loss_dice: 0.218368\n",
            "iteration 8775 : loss : 0.110360, loss_ce: 0.041996 loss_dice: 0.155937\n",
            "iteration 8776 : loss : 0.065331, loss_ce: 0.028899 loss_dice: 0.089620\n",
            "iteration 8777 : loss : 0.160582, loss_ce: 0.052312 loss_dice: 0.232762\n",
            "iteration 8778 : loss : 0.159317, loss_ce: 0.052485 loss_dice: 0.230538\n",
            "iteration 8779 : loss : 0.160988, loss_ce: 0.052169 loss_dice: 0.233534\n",
            "iteration 8780 : loss : 0.170838, loss_ce: 0.044144 loss_dice: 0.255301\n",
            "iteration 8781 : loss : 0.199389, loss_ce: 0.057274 loss_dice: 0.294132\n",
            "iteration 8782 : loss : 0.094206, loss_ce: 0.019011 loss_dice: 0.144336\n",
            "iteration 8783 : loss : 0.107252, loss_ce: 0.033761 loss_dice: 0.156246\n",
            "iteration 8784 : loss : 0.239637, loss_ce: 0.081793 loss_dice: 0.344867\n",
            "iteration 8785 : loss : 0.137799, loss_ce: 0.020694 loss_dice: 0.215869\n",
            "iteration 8786 : loss : 0.170342, loss_ce: 0.022105 loss_dice: 0.269167\n",
            "iteration 8787 : loss : 0.196063, loss_ce: 0.022570 loss_dice: 0.311726\n",
            "iteration 8788 : loss : 0.178283, loss_ce: 0.067590 loss_dice: 0.252079\n",
            "iteration 8789 : loss : 0.087711, loss_ce: 0.023581 loss_dice: 0.130464\n",
            "iteration 8790 : loss : 0.142332, loss_ce: 0.043943 loss_dice: 0.207924\n",
            "iteration 8791 : loss : 0.116800, loss_ce: 0.025265 loss_dice: 0.177823\n",
            "iteration 8792 : loss : 0.207031, loss_ce: 0.055398 loss_dice: 0.308119\n",
            "iteration 8793 : loss : 0.185976, loss_ce: 0.010432 loss_dice: 0.303005\n",
            "iteration 8794 : loss : 0.175995, loss_ce: 0.097048 loss_dice: 0.228627\n",
            "iteration 8795 : loss : 0.107466, loss_ce: 0.009993 loss_dice: 0.172448\n",
            "iteration 8796 : loss : 0.197017, loss_ce: 0.011764 loss_dice: 0.320519\n",
            "iteration 8797 : loss : 0.162734, loss_ce: 0.041120 loss_dice: 0.243809\n",
            "iteration 8798 : loss : 0.214377, loss_ce: 0.008058 loss_dice: 0.351923\n",
            "iteration 8799 : loss : 0.193175, loss_ce: 0.106750 loss_dice: 0.250792\n",
            "iteration 8800 : loss : 0.064145, loss_ce: 0.016186 loss_dice: 0.096118\n",
            "iteration 8801 : loss : 0.056560, loss_ce: 0.015030 loss_dice: 0.084247\n",
            "iteration 8802 : loss : 0.123433, loss_ce: 0.022183 loss_dice: 0.190933\n",
            "iteration 8803 : loss : 0.128231, loss_ce: 0.036022 loss_dice: 0.189704\n",
            "iteration 8804 : loss : 0.212976, loss_ce: 0.041877 loss_dice: 0.327041\n",
            "iteration 8805 : loss : 0.154333, loss_ce: 0.023336 loss_dice: 0.241665\n",
            "iteration 8806 : loss : 0.247166, loss_ce: 0.009106 loss_dice: 0.405873\n",
            "iteration 8807 : loss : 0.204748, loss_ce: 0.042609 loss_dice: 0.312841\n",
            "iteration 8808 : loss : 0.164604, loss_ce: 0.059898 loss_dice: 0.234408\n",
            "iteration 8809 : loss : 0.167564, loss_ce: 0.036354 loss_dice: 0.255037\n",
            "iteration 8810 : loss : 0.097097, loss_ce: 0.026473 loss_dice: 0.144179\n",
            "iteration 8811 : loss : 0.142283, loss_ce: 0.048281 loss_dice: 0.204951\n",
            "iteration 8812 : loss : 0.150645, loss_ce: 0.050604 loss_dice: 0.217338\n",
            "iteration 8813 : loss : 0.158319, loss_ce: 0.024710 loss_dice: 0.247391\n",
            "iteration 8814 : loss : 0.151619, loss_ce: 0.015686 loss_dice: 0.242241\n",
            "iteration 8815 : loss : 0.161518, loss_ce: 0.036573 loss_dice: 0.244815\n",
            "iteration 8816 : loss : 0.141320, loss_ce: 0.025523 loss_dice: 0.218518\n",
            "iteration 8817 : loss : 0.135128, loss_ce: 0.011327 loss_dice: 0.217662\n",
            "iteration 8818 : loss : 0.135778, loss_ce: 0.039859 loss_dice: 0.199723\n",
            "iteration 8819 : loss : 0.069442, loss_ce: 0.033095 loss_dice: 0.093673\n",
            "iteration 8820 : loss : 0.186580, loss_ce: 0.027873 loss_dice: 0.292385\n",
            "iteration 8821 : loss : 0.097567, loss_ce: 0.017570 loss_dice: 0.150898\n",
            "iteration 8822 : loss : 0.145192, loss_ce: 0.028386 loss_dice: 0.223064\n",
            "iteration 8823 : loss : 0.213553, loss_ce: 0.021861 loss_dice: 0.341348\n",
            "iteration 8824 : loss : 0.172510, loss_ce: 0.038535 loss_dice: 0.261827\n",
            "iteration 8825 : loss : 0.135407, loss_ce: 0.027900 loss_dice: 0.207078\n",
            "iteration 8826 : loss : 0.076255, loss_ce: 0.031291 loss_dice: 0.106232\n",
            "iteration 8827 : loss : 0.090293, loss_ce: 0.022223 loss_dice: 0.135672\n",
            "iteration 8828 : loss : 0.084081, loss_ce: 0.024722 loss_dice: 0.123654\n",
            "iteration 8829 : loss : 0.072760, loss_ce: 0.015612 loss_dice: 0.110859\n",
            "iteration 8830 : loss : 0.134955, loss_ce: 0.046996 loss_dice: 0.193595\n",
            "iteration 8831 : loss : 0.069131, loss_ce: 0.014716 loss_dice: 0.105407\n",
            "iteration 8832 : loss : 0.113843, loss_ce: 0.023346 loss_dice: 0.174174\n",
            "iteration 8833 : loss : 0.059374, loss_ce: 0.020435 loss_dice: 0.085334\n",
            "iteration 8834 : loss : 0.227056, loss_ce: 0.012292 loss_dice: 0.370232\n",
            "iteration 8835 : loss : 0.147012, loss_ce: 0.037510 loss_dice: 0.220014\n",
            "iteration 8836 : loss : 0.152259, loss_ce: 0.032850 loss_dice: 0.231865\n",
            "iteration 8837 : loss : 0.161547, loss_ce: 0.036047 loss_dice: 0.245214\n",
            "iteration 8838 : loss : 0.184375, loss_ce: 0.013707 loss_dice: 0.298153\n",
            "iteration 8839 : loss : 0.151384, loss_ce: 0.043286 loss_dice: 0.223449\n",
            "iteration 8840 : loss : 0.164005, loss_ce: 0.073637 loss_dice: 0.224250\n",
            "iteration 8841 : loss : 0.179749, loss_ce: 0.054696 loss_dice: 0.263117\n",
            "iteration 8842 : loss : 0.094165, loss_ce: 0.015230 loss_dice: 0.146789\n",
            "iteration 8843 : loss : 0.131322, loss_ce: 0.028194 loss_dice: 0.200075\n",
            "iteration 8844 : loss : 0.174480, loss_ce: 0.031897 loss_dice: 0.269535\n",
            "iteration 8845 : loss : 0.104931, loss_ce: 0.036460 loss_dice: 0.150579\n",
            "iteration 8846 : loss : 0.096815, loss_ce: 0.032226 loss_dice: 0.139875\n",
            "iteration 8847 : loss : 0.136260, loss_ce: 0.024270 loss_dice: 0.210920\n",
            "iteration 8848 : loss : 0.141856, loss_ce: 0.058547 loss_dice: 0.197395\n",
            "iteration 8849 : loss : 0.151516, loss_ce: 0.025944 loss_dice: 0.235231\n",
            "iteration 8850 : loss : 0.089685, loss_ce: 0.013496 loss_dice: 0.140478\n",
            "iteration 8851 : loss : 0.126661, loss_ce: 0.015389 loss_dice: 0.200843\n",
            "iteration 8852 : loss : 0.126308, loss_ce: 0.028640 loss_dice: 0.191420\n",
            "iteration 8853 : loss : 0.090295, loss_ce: 0.022833 loss_dice: 0.135269\n",
            "iteration 8854 : loss : 0.174993, loss_ce: 0.012784 loss_dice: 0.283132\n",
            "iteration 8855 : loss : 0.191198, loss_ce: 0.019144 loss_dice: 0.305902\n",
            "iteration 8856 : loss : 0.132636, loss_ce: 0.050021 loss_dice: 0.187712\n",
            "iteration 8857 : loss : 0.139850, loss_ce: 0.027165 loss_dice: 0.214973\n",
            "iteration 8858 : loss : 0.118919, loss_ce: 0.047235 loss_dice: 0.166708\n",
            "iteration 8859 : loss : 0.105571, loss_ce: 0.035639 loss_dice: 0.152192\n",
            "iteration 8860 : loss : 0.424977, loss_ce: 0.003696 loss_dice: 0.705832\n",
            "iteration 8861 : loss : 0.157465, loss_ce: 0.006990 loss_dice: 0.257782\n",
            "iteration 8862 : loss : 0.093181, loss_ce: 0.026587 loss_dice: 0.137577\n",
            "iteration 8863 : loss : 0.146659, loss_ce: 0.019374 loss_dice: 0.231515\n",
            "iteration 8864 : loss : 0.156412, loss_ce: 0.043057 loss_dice: 0.231983\n",
            "iteration 8865 : loss : 0.095409, loss_ce: 0.039789 loss_dice: 0.132489\n",
            "iteration 8866 : loss : 0.164411, loss_ce: 0.044798 loss_dice: 0.244153\n",
            "iteration 8867 : loss : 0.136659, loss_ce: 0.032072 loss_dice: 0.206384\n",
            "iteration 8868 : loss : 0.133214, loss_ce: 0.033112 loss_dice: 0.199949\n",
            "iteration 8869 : loss : 0.118419, loss_ce: 0.018148 loss_dice: 0.185265\n",
            "iteration 8870 : loss : 0.130621, loss_ce: 0.025124 loss_dice: 0.200953\n",
            "iteration 8871 : loss : 0.107266, loss_ce: 0.037236 loss_dice: 0.153953\n",
            "iteration 8872 : loss : 0.144821, loss_ce: 0.028549 loss_dice: 0.222336\n",
            "iteration 8873 : loss : 0.246589, loss_ce: 0.019680 loss_dice: 0.397862\n",
            "iteration 8874 : loss : 0.221597, loss_ce: 0.013048 loss_dice: 0.360630\n",
            "iteration 8875 : loss : 0.164503, loss_ce: 0.040977 loss_dice: 0.246854\n",
            "iteration 8876 : loss : 0.097210, loss_ce: 0.036775 loss_dice: 0.137499\n",
            "iteration 8877 : loss : 0.091329, loss_ce: 0.030509 loss_dice: 0.131875\n",
            "iteration 8878 : loss : 0.062571, loss_ce: 0.018975 loss_dice: 0.091635\n",
            "iteration 8879 : loss : 0.154678, loss_ce: 0.027711 loss_dice: 0.239323\n",
            "iteration 8880 : loss : 0.087861, loss_ce: 0.000299 loss_dice: 0.146235\n",
            "save model to ./results/BEFUnet/BEFUnet_epoch_39.pth\n",
            "********************\n",
            "Running Inference after epoch 39\n",
            "Epoch 39\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A idx 0 case case0008 mean_dice 0.440814 mean_hd95 26.677257\n",
            "\n",
            "1it [02:09, 129.78s/it]\u001b[A idx 1 case case0022 mean_dice 0.606323 mean_hd95 35.009600\n",
            "\n",
            "2it [03:21, 95.62s/it] \u001b[A idx 2 case case0038 mean_dice 0.555209 mean_hd95 65.011304\n",
            "\n",
            "3it [04:43, 89.57s/it]\u001b[A idx 3 case case0036 mean_dice 0.620247 mean_hd95 65.231496\n",
            "\n",
            "4it [07:32, 120.97s/it]\u001b[A idx 4 case case0032 mean_dice 0.609783 mean_hd95 38.602940\n",
            "\n",
            "5it [09:45, 125.16s/it]\u001b[A idx 5 case case0002 mean_dice 0.665308 mean_hd95 11.603893\n",
            "\n",
            "6it [11:36, 120.34s/it]\u001b[A idx 6 case case0029 mean_dice 0.482067 mean_hd95 65.090394\n",
            "\n",
            "7it [12:51, 105.55s/it]\u001b[A idx 7 case case0003 mean_dice 0.506205 mean_hd95 73.675002\n",
            "\n",
            "8it [15:48, 128.20s/it]\u001b[A idx 8 case case0001 mean_dice 0.662551 mean_hd95 23.336367\n",
            "\n",
            "9it [17:52, 126.95s/it]\u001b[A idx 9 case case0004 mean_dice 0.603280 mean_hd95 61.072656\n",
            "\n",
            "10it [19:45, 122.62s/it]\u001b[A idx 10 case case0025 mean_dice 0.555670 mean_hd95 34.684433\n",
            "\n",
            "11it [20:53, 106.02s/it]\u001b[A idx 11 case case0035 mean_dice 0.638264 mean_hd95 10.194442\n",
            "\n",
            "12it [22:07, 110.64s/it]\n",
            "Mean class 1 mean_dice 0.755078 mean_hd95 31.841556\n",
            "Mean class 2 mean_dice 0.001779 mean_hd95 2.421832\n",
            "Mean class 3 mean_dice 0.663819 mean_hd95 95.750774\n",
            "Mean class 4 mean_dice 0.574080 mean_hd95 26.152997\n",
            "Mean class 5 mean_dice 0.878301 mean_hd95 25.499959\n",
            "Mean class 6 mean_dice 0.422276 mean_hd95 23.022960\n",
            "Mean class 7 mean_dice 0.758085 mean_hd95 111.023618\n",
            "Mean class 8 mean_dice 0.577062 mean_hd95 24.412827\n",
            "Testing performance in best val model: mean_dice : 0.578810 mean_hd95 : 42.515815\n",
            "  8%|██                        | 40/500 [1:42:33<61:39:17, 482.52s/it]iteration 8881 : loss : 0.070738, loss_ce: 0.023773 loss_dice: 0.102048\n",
            "iteration 8882 : loss : 0.160004, loss_ce: 0.048060 loss_dice: 0.234633\n",
            "iteration 8883 : loss : 0.143210, loss_ce: 0.037544 loss_dice: 0.213653\n",
            "iteration 8884 : loss : 0.229501, loss_ce: 0.007042 loss_dice: 0.377807\n",
            "iteration 8885 : loss : 0.184359, loss_ce: 0.012436 loss_dice: 0.298974\n",
            "iteration 8886 : loss : 0.180639, loss_ce: 0.062712 loss_dice: 0.259257\n",
            "iteration 8887 : loss : 0.147552, loss_ce: 0.020100 loss_dice: 0.232520\n",
            "iteration 8888 : loss : 0.157869, loss_ce: 0.051695 loss_dice: 0.228651\n",
            "iteration 8889 : loss : 0.171792, loss_ce: 0.061107 loss_dice: 0.245582\n",
            "iteration 8890 : loss : 0.125303, loss_ce: 0.015201 loss_dice: 0.198704\n",
            "iteration 8891 : loss : 0.230643, loss_ce: 0.031198 loss_dice: 0.363607\n",
            "iteration 8892 : loss : 0.092276, loss_ce: 0.030635 loss_dice: 0.133370\n",
            "iteration 8893 : loss : 0.208129, loss_ce: 0.035620 loss_dice: 0.323135\n",
            "iteration 8894 : loss : 0.165581, loss_ce: 0.061651 loss_dice: 0.234868\n",
            "iteration 8895 : loss : 0.190166, loss_ce: 0.024122 loss_dice: 0.300861\n",
            "iteration 8896 : loss : 0.142726, loss_ce: 0.041971 loss_dice: 0.209895\n",
            "iteration 8897 : loss : 0.233084, loss_ce: 0.029948 loss_dice: 0.368509\n",
            "iteration 8898 : loss : 0.072129, loss_ce: 0.024711 loss_dice: 0.103742\n",
            "iteration 8899 : loss : 0.195503, loss_ce: 0.033550 loss_dice: 0.303472\n",
            "iteration 8900 : loss : 0.169679, loss_ce: 0.026219 loss_dice: 0.265319\n",
            "iteration 8901 : loss : 0.121613, loss_ce: 0.031262 loss_dice: 0.181848\n",
            "iteration 8902 : loss : 0.179045, loss_ce: 0.047965 loss_dice: 0.266432\n",
            "iteration 8903 : loss : 0.171599, loss_ce: 0.039880 loss_dice: 0.259412\n",
            "iteration 8904 : loss : 0.389728, loss_ce: 0.002585 loss_dice: 0.647824\n",
            "iteration 8905 : loss : 0.069124, loss_ce: 0.027876 loss_dice: 0.096622\n",
            "iteration 8906 : loss : 0.180035, loss_ce: 0.017911 loss_dice: 0.288118\n",
            "iteration 8907 : loss : 0.136145, loss_ce: 0.039673 loss_dice: 0.200460\n",
            "iteration 8908 : loss : 0.139522, loss_ce: 0.047020 loss_dice: 0.201190\n",
            "iteration 8909 : loss : 0.249232, loss_ce: 0.012583 loss_dice: 0.406998\n",
            "iteration 8910 : loss : 0.163231, loss_ce: 0.012145 loss_dice: 0.263954\n",
            "iteration 8911 : loss : 0.166517, loss_ce: 0.045440 loss_dice: 0.247235\n",
            "iteration 8912 : loss : 0.120685, loss_ce: 0.060558 loss_dice: 0.160769\n",
            "iteration 8913 : loss : 0.129498, loss_ce: 0.029948 loss_dice: 0.195865\n",
            "iteration 8914 : loss : 0.137888, loss_ce: 0.009770 loss_dice: 0.223300\n",
            "iteration 8915 : loss : 0.084491, loss_ce: 0.030274 loss_dice: 0.120635\n",
            "iteration 8916 : loss : 0.142557, loss_ce: 0.010816 loss_dice: 0.230384\n",
            "iteration 8917 : loss : 0.146054, loss_ce: 0.048741 loss_dice: 0.210929\n",
            "iteration 8918 : loss : 0.085440, loss_ce: 0.019408 loss_dice: 0.129461\n",
            "iteration 8919 : loss : 0.095534, loss_ce: 0.034213 loss_dice: 0.136414\n",
            "iteration 8920 : loss : 0.130008, loss_ce: 0.029391 loss_dice: 0.197086\n",
            "iteration 8921 : loss : 0.188277, loss_ce: 0.016488 loss_dice: 0.302803\n",
            "iteration 8922 : loss : 0.142667, loss_ce: 0.034316 loss_dice: 0.214900\n",
            "iteration 8923 : loss : 0.169662, loss_ce: 0.017390 loss_dice: 0.271177\n",
            "iteration 8924 : loss : 0.160984, loss_ce: 0.042039 loss_dice: 0.240281\n",
            "iteration 8925 : loss : 0.129286, loss_ce: 0.017364 loss_dice: 0.203900\n",
            "iteration 8926 : loss : 0.071551, loss_ce: 0.017838 loss_dice: 0.107359\n",
            "iteration 8927 : loss : 0.178976, loss_ce: 0.041284 loss_dice: 0.270770\n",
            "iteration 8928 : loss : 0.119191, loss_ce: 0.025649 loss_dice: 0.181552\n",
            "iteration 8929 : loss : 0.098446, loss_ce: 0.023771 loss_dice: 0.148229\n",
            "iteration 8930 : loss : 0.240360, loss_ce: 0.025439 loss_dice: 0.383641\n",
            "iteration 8931 : loss : 0.245069, loss_ce: 0.039928 loss_dice: 0.381830\n",
            "iteration 8932 : loss : 0.141649, loss_ce: 0.057671 loss_dice: 0.197634\n",
            "iteration 8933 : loss : 0.169277, loss_ce: 0.013935 loss_dice: 0.272839\n",
            "iteration 8934 : loss : 0.137011, loss_ce: 0.028163 loss_dice: 0.209576\n",
            "iteration 8935 : loss : 0.164654, loss_ce: 0.048248 loss_dice: 0.242258\n",
            "iteration 8936 : loss : 0.133083, loss_ce: 0.027241 loss_dice: 0.203645\n",
            "iteration 8937 : loss : 0.246711, loss_ce: 0.011226 loss_dice: 0.403701\n",
            "iteration 8938 : loss : 0.137701, loss_ce: 0.047014 loss_dice: 0.198159\n",
            "iteration 8939 : loss : 0.096135, loss_ce: 0.021025 loss_dice: 0.146207\n",
            "iteration 8940 : loss : 0.093781, loss_ce: 0.024147 loss_dice: 0.140203\n",
            "iteration 8941 : loss : 0.081097, loss_ce: 0.032611 loss_dice: 0.113421\n",
            "iteration 8942 : loss : 0.077926, loss_ce: 0.021927 loss_dice: 0.115259\n",
            "iteration 8943 : loss : 0.349170, loss_ce: 0.000397 loss_dice: 0.581686\n",
            "iteration 8944 : loss : 0.063710, loss_ce: 0.014186 loss_dice: 0.096727\n",
            "iteration 8945 : loss : 0.211375, loss_ce: 0.036635 loss_dice: 0.327868\n",
            "iteration 8946 : loss : 0.271741, loss_ce: 0.011789 loss_dice: 0.445043\n",
            "iteration 8947 : loss : 0.176382, loss_ce: 0.048659 loss_dice: 0.261530\n",
            "iteration 8948 : loss : 0.152125, loss_ce: 0.069929 loss_dice: 0.206922\n",
            "iteration 8949 : loss : 0.222125, loss_ce: 0.106104 loss_dice: 0.299472\n",
            "iteration 8950 : loss : 0.142592, loss_ce: 0.040995 loss_dice: 0.210323\n",
            "iteration 8951 : loss : 0.181178, loss_ce: 0.022111 loss_dice: 0.287222\n",
            "iteration 8952 : loss : 0.137259, loss_ce: 0.052374 loss_dice: 0.193850\n",
            "iteration 8953 : loss : 0.192636, loss_ce: 0.028205 loss_dice: 0.302256\n",
            "iteration 8954 : loss : 0.132738, loss_ce: 0.061450 loss_dice: 0.180264\n",
            "iteration 8955 : loss : 0.134037, loss_ce: 0.050691 loss_dice: 0.189601\n",
            "iteration 8956 : loss : 0.143348, loss_ce: 0.047132 loss_dice: 0.207491\n",
            "iteration 8957 : loss : 0.157117, loss_ce: 0.084322 loss_dice: 0.205648\n",
            "iteration 8958 : loss : 0.171324, loss_ce: 0.028063 loss_dice: 0.266832\n",
            "iteration 8959 : loss : 0.108531, loss_ce: 0.069178 loss_dice: 0.134767\n",
            "iteration 8960 : loss : 0.131207, loss_ce: 0.018197 loss_dice: 0.206546\n",
            "iteration 8961 : loss : 0.106173, loss_ce: 0.021846 loss_dice: 0.162392\n",
            "iteration 8962 : loss : 0.206052, loss_ce: 0.006237 loss_dice: 0.339261\n",
            "iteration 8963 : loss : 0.135387, loss_ce: 0.061992 loss_dice: 0.184317\n",
            "iteration 8964 : loss : 0.175681, loss_ce: 0.057677 loss_dice: 0.254349\n",
            "iteration 8965 : loss : 0.201199, loss_ce: 0.021532 loss_dice: 0.320976\n",
            "iteration 8966 : loss : 0.162745, loss_ce: 0.025182 loss_dice: 0.254453\n",
            "iteration 8967 : loss : 0.146662, loss_ce: 0.014666 loss_dice: 0.234659\n",
            "iteration 8968 : loss : 0.213043, loss_ce: 0.013547 loss_dice: 0.346040\n",
            "iteration 8969 : loss : 0.166920, loss_ce: 0.016895 loss_dice: 0.266937\n",
            "iteration 8970 : loss : 0.080889, loss_ce: 0.032366 loss_dice: 0.113238\n",
            "iteration 8971 : loss : 0.139500, loss_ce: 0.039192 loss_dice: 0.206371\n",
            "iteration 8972 : loss : 0.214898, loss_ce: 0.032633 loss_dice: 0.336409\n",
            "iteration 8973 : loss : 0.203703, loss_ce: 0.046842 loss_dice: 0.308277\n",
            "iteration 8974 : loss : 0.113469, loss_ce: 0.031671 loss_dice: 0.168001\n",
            "iteration 8975 : loss : 0.223921, loss_ce: 0.013527 loss_dice: 0.364183\n",
            "iteration 8976 : loss : 0.129878, loss_ce: 0.040425 loss_dice: 0.189514\n",
            "iteration 8977 : loss : 0.152221, loss_ce: 0.023606 loss_dice: 0.237964\n",
            "iteration 8978 : loss : 0.104739, loss_ce: 0.027559 loss_dice: 0.156193\n",
            "iteration 8979 : loss : 0.113816, loss_ce: 0.025399 loss_dice: 0.172760\n",
            "iteration 8980 : loss : 0.151119, loss_ce: 0.023177 loss_dice: 0.236415\n",
            "iteration 8981 : loss : 0.141198, loss_ce: 0.041498 loss_dice: 0.207665\n",
            "iteration 8982 : loss : 0.104098, loss_ce: 0.044450 loss_dice: 0.143864\n",
            "iteration 8983 : loss : 0.144364, loss_ce: 0.027613 loss_dice: 0.222198\n",
            "iteration 8984 : loss : 0.164459, loss_ce: 0.035084 loss_dice: 0.250710\n",
            "iteration 8985 : loss : 0.082961, loss_ce: 0.030834 loss_dice: 0.117712\n",
            "iteration 8986 : loss : 0.151284, loss_ce: 0.080042 loss_dice: 0.198779\n",
            "iteration 8987 : loss : 0.086701, loss_ce: 0.027674 loss_dice: 0.126052\n",
            "iteration 8988 : loss : 0.155976, loss_ce: 0.011727 loss_dice: 0.252142\n",
            "iteration 8989 : loss : 0.102714, loss_ce: 0.024973 loss_dice: 0.154542\n",
            "iteration 8990 : loss : 0.191852, loss_ce: 0.025160 loss_dice: 0.302979\n",
            "iteration 8991 : loss : 0.116020, loss_ce: 0.040006 loss_dice: 0.166697\n",
            "iteration 8992 : loss : 0.112153, loss_ce: 0.021969 loss_dice: 0.172276\n",
            "iteration 8993 : loss : 0.109992, loss_ce: 0.033560 loss_dice: 0.160947\n",
            "iteration 8994 : loss : 0.112930, loss_ce: 0.018002 loss_dice: 0.176216\n",
            "iteration 8995 : loss : 0.137660, loss_ce: 0.025504 loss_dice: 0.212431\n",
            "iteration 8996 : loss : 0.166369, loss_ce: 0.015403 loss_dice: 0.267013\n",
            "iteration 8997 : loss : 0.117484, loss_ce: 0.027046 loss_dice: 0.177776\n",
            "iteration 8998 : loss : 0.095085, loss_ce: 0.033026 loss_dice: 0.136457\n",
            "iteration 8999 : loss : 0.126510, loss_ce: 0.053914 loss_dice: 0.174907\n",
            "iteration 9000 : loss : 0.099023, loss_ce: 0.019608 loss_dice: 0.151967\n",
            "iteration 9001 : loss : 0.157955, loss_ce: 0.024534 loss_dice: 0.246902\n",
            "iteration 9002 : loss : 0.114427, loss_ce: 0.053766 loss_dice: 0.154867\n",
            "iteration 9003 : loss : 0.086640, loss_ce: 0.017944 loss_dice: 0.132437\n",
            "iteration 9004 : loss : 0.209902, loss_ce: 0.022941 loss_dice: 0.334543\n",
            "iteration 9005 : loss : 0.090698, loss_ce: 0.019908 loss_dice: 0.137891\n",
            "iteration 9006 : loss : 0.166670, loss_ce: 0.051609 loss_dice: 0.243377\n",
            "iteration 9007 : loss : 0.144587, loss_ce: 0.050236 loss_dice: 0.207487\n",
            "iteration 9008 : loss : 0.117845, loss_ce: 0.049518 loss_dice: 0.163395\n",
            "iteration 9009 : loss : 0.094028, loss_ce: 0.018373 loss_dice: 0.144465\n",
            "iteration 9010 : loss : 0.107050, loss_ce: 0.049657 loss_dice: 0.145312\n",
            "iteration 9011 : loss : 0.144317, loss_ce: 0.030284 loss_dice: 0.220340\n",
            "iteration 9012 : loss : 0.283197, loss_ce: 0.031835 loss_dice: 0.450772\n",
            "iteration 9013 : loss : 0.108227, loss_ce: 0.028691 loss_dice: 0.161251\n",
            "iteration 9014 : loss : 0.230709, loss_ce: 0.017484 loss_dice: 0.372859\n",
            "iteration 9015 : loss : 0.272370, loss_ce: 0.028890 loss_dice: 0.434690\n",
            "iteration 9016 : loss : 0.075799, loss_ce: 0.026218 loss_dice: 0.108853\n",
            "iteration 9017 : loss : 0.116470, loss_ce: 0.044629 loss_dice: 0.164364\n",
            "iteration 9018 : loss : 0.210143, loss_ce: 0.022404 loss_dice: 0.335301\n",
            "iteration 9019 : loss : 0.117337, loss_ce: 0.010202 loss_dice: 0.188760\n",
            "iteration 9020 : loss : 0.137564, loss_ce: 0.016531 loss_dice: 0.218253\n",
            "iteration 9021 : loss : 0.154452, loss_ce: 0.035166 loss_dice: 0.233976\n",
            "iteration 9022 : loss : 0.246798, loss_ce: 0.028692 loss_dice: 0.392202\n",
            "iteration 9023 : loss : 0.199113, loss_ce: 0.054218 loss_dice: 0.295710\n",
            "iteration 9024 : loss : 0.151413, loss_ce: 0.016658 loss_dice: 0.241250\n",
            "iteration 9025 : loss : 0.063805, loss_ce: 0.017649 loss_dice: 0.094576\n",
            "iteration 9026 : loss : 0.105013, loss_ce: 0.013576 loss_dice: 0.165971\n",
            "iteration 9027 : loss : 0.101006, loss_ce: 0.018397 loss_dice: 0.156078\n",
            "iteration 9028 : loss : 0.087507, loss_ce: 0.021359 loss_dice: 0.131605\n",
            "iteration 9029 : loss : 0.165531, loss_ce: 0.036459 loss_dice: 0.251579\n",
            "iteration 9030 : loss : 0.103772, loss_ce: 0.028964 loss_dice: 0.153645\n",
            "iteration 9031 : loss : 0.157539, loss_ce: 0.046725 loss_dice: 0.231415\n",
            "iteration 9032 : loss : 0.096042, loss_ce: 0.042256 loss_dice: 0.131899\n",
            "iteration 9033 : loss : 0.227988, loss_ce: 0.024318 loss_dice: 0.363768\n",
            "iteration 9034 : loss : 0.124960, loss_ce: 0.031950 loss_dice: 0.186966\n",
            "iteration 9035 : loss : 0.164877, loss_ce: 0.039101 loss_dice: 0.248729\n",
            "iteration 9036 : loss : 0.153675, loss_ce: 0.045722 loss_dice: 0.225644\n",
            "iteration 9037 : loss : 0.236951, loss_ce: 0.057306 loss_dice: 0.356715\n",
            "iteration 9038 : loss : 0.162715, loss_ce: 0.039401 loss_dice: 0.244924\n",
            "iteration 9039 : loss : 0.075865, loss_ce: 0.025356 loss_dice: 0.109538\n",
            "iteration 9040 : loss : 0.151802, loss_ce: 0.028079 loss_dice: 0.234283\n",
            "iteration 9041 : loss : 0.135651, loss_ce: 0.055551 loss_dice: 0.189052\n",
            "iteration 9042 : loss : 0.126736, loss_ce: 0.037113 loss_dice: 0.186486\n",
            "iteration 9043 : loss : 0.160505, loss_ce: 0.024717 loss_dice: 0.251030\n",
            "iteration 9044 : loss : 0.171402, loss_ce: 0.045203 loss_dice: 0.255534\n",
            "iteration 9045 : loss : 0.251383, loss_ce: 0.017807 loss_dice: 0.407100\n",
            "iteration 9046 : loss : 0.152210, loss_ce: 0.028475 loss_dice: 0.234700\n",
            "iteration 9047 : loss : 0.091161, loss_ce: 0.031709 loss_dice: 0.130795\n",
            "iteration 9048 : loss : 0.171386, loss_ce: 0.039210 loss_dice: 0.259503\n",
            "iteration 9049 : loss : 0.066896, loss_ce: 0.026771 loss_dice: 0.093647\n",
            "iteration 9050 : loss : 0.110742, loss_ce: 0.042494 loss_dice: 0.156241\n",
            "iteration 9051 : loss : 0.121770, loss_ce: 0.043990 loss_dice: 0.173624\n",
            "iteration 9052 : loss : 0.139075, loss_ce: 0.053237 loss_dice: 0.196301\n",
            "iteration 9053 : loss : 0.142965, loss_ce: 0.017200 loss_dice: 0.226808\n",
            "iteration 9054 : loss : 0.112800, loss_ce: 0.031480 loss_dice: 0.167013\n",
            "iteration 9055 : loss : 0.147857, loss_ce: 0.012446 loss_dice: 0.238130\n",
            "iteration 9056 : loss : 0.158863, loss_ce: 0.027643 loss_dice: 0.246344\n",
            "iteration 9057 : loss : 0.062762, loss_ce: 0.021486 loss_dice: 0.090279\n",
            "iteration 9058 : loss : 0.189322, loss_ce: 0.063634 loss_dice: 0.273113\n",
            "iteration 9059 : loss : 0.154982, loss_ce: 0.031519 loss_dice: 0.237292\n",
            "iteration 9060 : loss : 0.146658, loss_ce: 0.018392 loss_dice: 0.232169\n",
            "iteration 9061 : loss : 0.153434, loss_ce: 0.040685 loss_dice: 0.228601\n",
            "iteration 9062 : loss : 0.109784, loss_ce: 0.042478 loss_dice: 0.154654\n",
            "iteration 9063 : loss : 0.178736, loss_ce: 0.021192 loss_dice: 0.283765\n",
            "iteration 9064 : loss : 0.080244, loss_ce: 0.019325 loss_dice: 0.120857\n",
            "iteration 9065 : loss : 0.305149, loss_ce: 0.008423 loss_dice: 0.502966\n",
            "iteration 9066 : loss : 0.095541, loss_ce: 0.030468 loss_dice: 0.138923\n",
            "iteration 9067 : loss : 0.099471, loss_ce: 0.028599 loss_dice: 0.146719\n",
            "iteration 9068 : loss : 0.169837, loss_ce: 0.009694 loss_dice: 0.276599\n",
            "iteration 9069 : loss : 0.101057, loss_ce: 0.028082 loss_dice: 0.149707\n",
            "iteration 9070 : loss : 0.165584, loss_ce: 0.022900 loss_dice: 0.260707\n",
            "iteration 9071 : loss : 0.104953, loss_ce: 0.037881 loss_dice: 0.149667\n",
            "iteration 9072 : loss : 0.104131, loss_ce: 0.028230 loss_dice: 0.154731\n",
            "iteration 9073 : loss : 0.147627, loss_ce: 0.022603 loss_dice: 0.230977\n",
            "iteration 9074 : loss : 0.120272, loss_ce: 0.030696 loss_dice: 0.179989\n",
            "iteration 9075 : loss : 0.137036, loss_ce: 0.028470 loss_dice: 0.209414\n",
            "iteration 9076 : loss : 0.147898, loss_ce: 0.008625 loss_dice: 0.240746\n",
            "iteration 9077 : loss : 0.092627, loss_ce: 0.038621 loss_dice: 0.128630\n",
            "iteration 9078 : loss : 0.126545, loss_ce: 0.038514 loss_dice: 0.185232\n",
            "iteration 9079 : loss : 0.148189, loss_ce: 0.042132 loss_dice: 0.218894\n",
            "iteration 9080 : loss : 0.205382, loss_ce: 0.031905 loss_dice: 0.321033\n",
            "iteration 9081 : loss : 0.074797, loss_ce: 0.031994 loss_dice: 0.103332\n",
            "iteration 9082 : loss : 0.124406, loss_ce: 0.028025 loss_dice: 0.188660\n",
            "iteration 9083 : loss : 0.079325, loss_ce: 0.032028 loss_dice: 0.110857\n",
            "iteration 9084 : loss : 0.129558, loss_ce: 0.029808 loss_dice: 0.196057\n",
            "iteration 9085 : loss : 0.154575, loss_ce: 0.012620 loss_dice: 0.249211\n",
            "iteration 9086 : loss : 0.098512, loss_ce: 0.016941 loss_dice: 0.152892\n",
            "iteration 9087 : loss : 0.077754, loss_ce: 0.017997 loss_dice: 0.117592\n",
            "iteration 9088 : loss : 0.089398, loss_ce: 0.024577 loss_dice: 0.132613\n",
            "iteration 9089 : loss : 0.125488, loss_ce: 0.056655 loss_dice: 0.171378\n",
            "iteration 9090 : loss : 0.180914, loss_ce: 0.025027 loss_dice: 0.284839\n",
            "iteration 9091 : loss : 0.115317, loss_ce: 0.040831 loss_dice: 0.164974\n",
            "iteration 9092 : loss : 0.105835, loss_ce: 0.038312 loss_dice: 0.150849\n",
            "iteration 9093 : loss : 0.120166, loss_ce: 0.053539 loss_dice: 0.164584\n",
            "iteration 9094 : loss : 0.160319, loss_ce: 0.012212 loss_dice: 0.259057\n",
            "iteration 9095 : loss : 0.114890, loss_ce: 0.026280 loss_dice: 0.173963\n",
            "iteration 9096 : loss : 0.138601, loss_ce: 0.017299 loss_dice: 0.219470\n",
            "iteration 9097 : loss : 0.163655, loss_ce: 0.049885 loss_dice: 0.239501\n",
            "iteration 9098 : loss : 0.304575, loss_ce: 0.006206 loss_dice: 0.503487\n",
            "iteration 9099 : loss : 0.086988, loss_ce: 0.018923 loss_dice: 0.132365\n",
            "iteration 9100 : loss : 0.092830, loss_ce: 0.011921 loss_dice: 0.146770\n",
            "iteration 9101 : loss : 0.133285, loss_ce: 0.036823 loss_dice: 0.197592\n",
            "iteration 9102 : loss : 0.115279, loss_ce: 0.097978 loss_dice: 0.126813\n",
            "  8%|██▏                       | 41/500 [1:43:57<46:18:11, 363.16s/it]iteration 9103 : loss : 0.241916, loss_ce: 0.016689 loss_dice: 0.392068\n",
            "iteration 9104 : loss : 0.167947, loss_ce: 0.031396 loss_dice: 0.258980\n",
            "iteration 9105 : loss : 0.146677, loss_ce: 0.039683 loss_dice: 0.218007\n",
            "iteration 9106 : loss : 0.185091, loss_ce: 0.037886 loss_dice: 0.283227\n",
            "iteration 9107 : loss : 0.075967, loss_ce: 0.013895 loss_dice: 0.117348\n",
            "iteration 9108 : loss : 0.127579, loss_ce: 0.034546 loss_dice: 0.189601\n",
            "iteration 9109 : loss : 0.077298, loss_ce: 0.024966 loss_dice: 0.112186\n",
            "iteration 9110 : loss : 0.142978, loss_ce: 0.021465 loss_dice: 0.223986\n",
            "iteration 9111 : loss : 0.127026, loss_ce: 0.040932 loss_dice: 0.184421\n",
            "iteration 9112 : loss : 0.167349, loss_ce: 0.058495 loss_dice: 0.239919\n",
            "iteration 9113 : loss : 0.123617, loss_ce: 0.064891 loss_dice: 0.162768\n",
            "iteration 9114 : loss : 0.078212, loss_ce: 0.023638 loss_dice: 0.114594\n",
            "iteration 9115 : loss : 0.107670, loss_ce: 0.037384 loss_dice: 0.154526\n",
            "iteration 9116 : loss : 0.147941, loss_ce: 0.041229 loss_dice: 0.219083\n",
            "iteration 9117 : loss : 0.159238, loss_ce: 0.026514 loss_dice: 0.247721\n",
            "iteration 9118 : loss : 0.141571, loss_ce: 0.044389 loss_dice: 0.206359\n",
            "iteration 9119 : loss : 0.086277, loss_ce: 0.018807 loss_dice: 0.131257\n",
            "iteration 9120 : loss : 0.232547, loss_ce: 0.012906 loss_dice: 0.378974\n",
            "iteration 9121 : loss : 0.247883, loss_ce: 0.007798 loss_dice: 0.407939\n",
            "iteration 9122 : loss : 0.064946, loss_ce: 0.026053 loss_dice: 0.090874\n",
            "iteration 9123 : loss : 0.062764, loss_ce: 0.022942 loss_dice: 0.089312\n",
            "iteration 9124 : loss : 0.187826, loss_ce: 0.020293 loss_dice: 0.299515\n",
            "iteration 9125 : loss : 0.082599, loss_ce: 0.018035 loss_dice: 0.125642\n",
            "iteration 9126 : loss : 0.075761, loss_ce: 0.018516 loss_dice: 0.113924\n",
            "iteration 9127 : loss : 0.106764, loss_ce: 0.044447 loss_dice: 0.148308\n",
            "iteration 9128 : loss : 0.081682, loss_ce: 0.013643 loss_dice: 0.127041\n",
            "iteration 9129 : loss : 0.404918, loss_ce: 0.002542 loss_dice: 0.673169\n",
            "iteration 9130 : loss : 0.113163, loss_ce: 0.013804 loss_dice: 0.179403\n",
            "iteration 9131 : loss : 0.135001, loss_ce: 0.022191 loss_dice: 0.210208\n",
            "iteration 9132 : loss : 0.131073, loss_ce: 0.025953 loss_dice: 0.201153\n",
            "iteration 9133 : loss : 0.131713, loss_ce: 0.012198 loss_dice: 0.211390\n",
            "iteration 9134 : loss : 0.129458, loss_ce: 0.032755 loss_dice: 0.193927\n",
            "iteration 9135 : loss : 0.115036, loss_ce: 0.023803 loss_dice: 0.175858\n",
            "iteration 9136 : loss : 0.117871, loss_ce: 0.008154 loss_dice: 0.191015\n",
            "iteration 9137 : loss : 0.096038, loss_ce: 0.023585 loss_dice: 0.144340\n",
            "iteration 9138 : loss : 0.083385, loss_ce: 0.010265 loss_dice: 0.132131\n",
            "iteration 9139 : loss : 0.242091, loss_ce: 0.023337 loss_dice: 0.387927\n",
            "iteration 9140 : loss : 0.077027, loss_ce: 0.017463 loss_dice: 0.116737\n",
            "iteration 9141 : loss : 0.142779, loss_ce: 0.033981 loss_dice: 0.215311\n",
            "iteration 9142 : loss : 0.110063, loss_ce: 0.022081 loss_dice: 0.168717\n",
            "iteration 9143 : loss : 0.077988, loss_ce: 0.033854 loss_dice: 0.107410\n",
            "iteration 9144 : loss : 0.158665, loss_ce: 0.031031 loss_dice: 0.243754\n",
            "iteration 9145 : loss : 0.063469, loss_ce: 0.012681 loss_dice: 0.097328\n",
            "iteration 9146 : loss : 0.233248, loss_ce: 0.014321 loss_dice: 0.379200\n",
            "iteration 9147 : loss : 0.102707, loss_ce: 0.022719 loss_dice: 0.156033\n",
            "iteration 9148 : loss : 0.160637, loss_ce: 0.059164 loss_dice: 0.228285\n",
            "iteration 9149 : loss : 0.197712, loss_ce: 0.060194 loss_dice: 0.289390\n",
            "iteration 9150 : loss : 0.121077, loss_ce: 0.058788 loss_dice: 0.162603\n",
            "iteration 9151 : loss : 0.160198, loss_ce: 0.061592 loss_dice: 0.225935\n",
            "iteration 9152 : loss : 0.216516, loss_ce: 0.019945 loss_dice: 0.347564\n",
            "iteration 9153 : loss : 0.147092, loss_ce: 0.046285 loss_dice: 0.214296\n",
            "iteration 9154 : loss : 0.100719, loss_ce: 0.032605 loss_dice: 0.146128\n",
            "iteration 9155 : loss : 0.130049, loss_ce: 0.017775 loss_dice: 0.204899\n",
            "iteration 9156 : loss : 0.125971, loss_ce: 0.006592 loss_dice: 0.205558\n",
            "iteration 9157 : loss : 0.121722, loss_ce: 0.024039 loss_dice: 0.186844\n",
            "iteration 9158 : loss : 0.116285, loss_ce: 0.039523 loss_dice: 0.167459\n",
            "iteration 9159 : loss : 0.151527, loss_ce: 0.052754 loss_dice: 0.217375\n",
            "iteration 9160 : loss : 0.173890, loss_ce: 0.040257 loss_dice: 0.262979\n",
            "iteration 9161 : loss : 0.122026, loss_ce: 0.030772 loss_dice: 0.182862\n",
            "iteration 9162 : loss : 0.153564, loss_ce: 0.044034 loss_dice: 0.226584\n",
            "iteration 9163 : loss : 0.153051, loss_ce: 0.035058 loss_dice: 0.231712\n",
            "iteration 9164 : loss : 0.132879, loss_ce: 0.026482 loss_dice: 0.203811\n",
            "iteration 9165 : loss : 0.169779, loss_ce: 0.029110 loss_dice: 0.263558\n",
            "iteration 9166 : loss : 0.144912, loss_ce: 0.037759 loss_dice: 0.216348\n",
            "iteration 9167 : loss : 0.120374, loss_ce: 0.018789 loss_dice: 0.188098\n",
            "iteration 9168 : loss : 0.135675, loss_ce: 0.016834 loss_dice: 0.214902\n",
            "iteration 9169 : loss : 0.145921, loss_ce: 0.044434 loss_dice: 0.213578\n",
            "iteration 9170 : loss : 0.102918, loss_ce: 0.023848 loss_dice: 0.155632\n",
            "iteration 9171 : loss : 0.103023, loss_ce: 0.055010 loss_dice: 0.135032\n",
            "iteration 9172 : loss : 0.147243, loss_ce: 0.034414 loss_dice: 0.222463\n",
            "iteration 9173 : loss : 0.231285, loss_ce: 0.017658 loss_dice: 0.373704\n",
            "iteration 9174 : loss : 0.122929, loss_ce: 0.028310 loss_dice: 0.186008\n",
            "iteration 9175 : loss : 0.151805, loss_ce: 0.029131 loss_dice: 0.233587\n",
            "iteration 9176 : loss : 0.189215, loss_ce: 0.015018 loss_dice: 0.305347\n",
            "iteration 9177 : loss : 0.123061, loss_ce: 0.017764 loss_dice: 0.193259\n",
            "iteration 9178 : loss : 0.085660, loss_ce: 0.016984 loss_dice: 0.131443\n",
            "iteration 9179 : loss : 0.167223, loss_ce: 0.018296 loss_dice: 0.266507\n",
            "iteration 9180 : loss : 0.135969, loss_ce: 0.035323 loss_dice: 0.203066\n",
            "iteration 9181 : loss : 0.061890, loss_ce: 0.030048 loss_dice: 0.083119\n",
            "iteration 9182 : loss : 0.091507, loss_ce: 0.031562 loss_dice: 0.131470\n",
            "iteration 9183 : loss : 0.132562, loss_ce: 0.028656 loss_dice: 0.201832\n",
            "iteration 9184 : loss : 0.120466, loss_ce: 0.026350 loss_dice: 0.183210\n",
            "iteration 9185 : loss : 0.208635, loss_ce: 0.038823 loss_dice: 0.321842\n",
            "iteration 9186 : loss : 0.162513, loss_ce: 0.015530 loss_dice: 0.260501\n",
            "iteration 9187 : loss : 0.056538, loss_ce: 0.017566 loss_dice: 0.082520\n",
            "iteration 9188 : loss : 0.124169, loss_ce: 0.013124 loss_dice: 0.198199\n",
            "iteration 9189 : loss : 0.095350, loss_ce: 0.037431 loss_dice: 0.133962\n",
            "iteration 9190 : loss : 0.104638, loss_ce: 0.044938 loss_dice: 0.144438\n",
            "iteration 9191 : loss : 0.080234, loss_ce: 0.025470 loss_dice: 0.116743\n",
            "iteration 9192 : loss : 0.149502, loss_ce: 0.031976 loss_dice: 0.227853\n",
            "iteration 9193 : loss : 0.163763, loss_ce: 0.042893 loss_dice: 0.244343\n",
            "iteration 9194 : loss : 0.104139, loss_ce: 0.028736 loss_dice: 0.154408\n",
            "iteration 9195 : loss : 0.205746, loss_ce: 0.031246 loss_dice: 0.322080\n",
            "iteration 9196 : loss : 0.123240, loss_ce: 0.039027 loss_dice: 0.179382\n",
            "iteration 9197 : loss : 0.288163, loss_ce: 0.010106 loss_dice: 0.473534\n",
            "iteration 9198 : loss : 0.083218, loss_ce: 0.014154 loss_dice: 0.129261\n",
            "iteration 9199 : loss : 0.074980, loss_ce: 0.028009 loss_dice: 0.106294\n",
            "iteration 9200 : loss : 0.139659, loss_ce: 0.015007 loss_dice: 0.222760\n",
            "iteration 9201 : loss : 0.068642, loss_ce: 0.024619 loss_dice: 0.097990\n",
            "iteration 9202 : loss : 0.102449, loss_ce: 0.027541 loss_dice: 0.152388\n",
            "iteration 9203 : loss : 0.188807, loss_ce: 0.022144 loss_dice: 0.299915\n",
            "iteration 9204 : loss : 0.164212, loss_ce: 0.018686 loss_dice: 0.261230\n",
            "iteration 9205 : loss : 0.140582, loss_ce: 0.033397 loss_dice: 0.212038\n",
            "iteration 9206 : loss : 0.199561, loss_ce: 0.019069 loss_dice: 0.319889\n",
            "iteration 9207 : loss : 0.141744, loss_ce: 0.034903 loss_dice: 0.212971\n",
            "iteration 9208 : loss : 0.086539, loss_ce: 0.023145 loss_dice: 0.128802\n",
            "iteration 9209 : loss : 0.153217, loss_ce: 0.018395 loss_dice: 0.243097\n",
            "iteration 9210 : loss : 0.189734, loss_ce: 0.009654 loss_dice: 0.309787\n",
            "iteration 9211 : loss : 0.110977, loss_ce: 0.036040 loss_dice: 0.160934\n",
            "iteration 9212 : loss : 0.141398, loss_ce: 0.027780 loss_dice: 0.217144\n",
            "iteration 9213 : loss : 0.184683, loss_ce: 0.027965 loss_dice: 0.289163\n",
            "iteration 9214 : loss : 0.119147, loss_ce: 0.053462 loss_dice: 0.162937\n",
            "iteration 9215 : loss : 0.176156, loss_ce: 0.041577 loss_dice: 0.265875\n",
            "iteration 9216 : loss : 0.140009, loss_ce: 0.065583 loss_dice: 0.189625\n",
            "iteration 9217 : loss : 0.101226, loss_ce: 0.031752 loss_dice: 0.147543\n",
            "iteration 9218 : loss : 0.190619, loss_ce: 0.020345 loss_dice: 0.304135\n",
            "iteration 9219 : loss : 0.086417, loss_ce: 0.036973 loss_dice: 0.119380\n",
            "iteration 9220 : loss : 0.178929, loss_ce: 0.010524 loss_dice: 0.291199\n",
            "iteration 9221 : loss : 0.206902, loss_ce: 0.033686 loss_dice: 0.322379\n",
            "iteration 9222 : loss : 0.072791, loss_ce: 0.018054 loss_dice: 0.109282\n",
            "iteration 9223 : loss : 0.150157, loss_ce: 0.031876 loss_dice: 0.229012\n",
            "iteration 9224 : loss : 0.150981, loss_ce: 0.016519 loss_dice: 0.240622\n",
            "iteration 9225 : loss : 0.096461, loss_ce: 0.036265 loss_dice: 0.136592\n",
            "iteration 9226 : loss : 0.119851, loss_ce: 0.042767 loss_dice: 0.171240\n",
            "iteration 9227 : loss : 0.098032, loss_ce: 0.045992 loss_dice: 0.132726\n",
            "iteration 9228 : loss : 0.147629, loss_ce: 0.030383 loss_dice: 0.225793\n",
            "iteration 9229 : loss : 0.146301, loss_ce: 0.016957 loss_dice: 0.232530\n",
            "iteration 9230 : loss : 0.111637, loss_ce: 0.014315 loss_dice: 0.176518\n",
            "iteration 9231 : loss : 0.075565, loss_ce: 0.018643 loss_dice: 0.113514\n",
            "iteration 9232 : loss : 0.111295, loss_ce: 0.025849 loss_dice: 0.168258\n",
            "iteration 9233 : loss : 0.287910, loss_ce: 0.007531 loss_dice: 0.474829\n",
            "iteration 9234 : loss : 0.069828, loss_ce: 0.017924 loss_dice: 0.104431\n",
            "iteration 9235 : loss : 0.150912, loss_ce: 0.026799 loss_dice: 0.233654\n",
            "iteration 9236 : loss : 0.095926, loss_ce: 0.023704 loss_dice: 0.144074\n",
            "iteration 9237 : loss : 0.086749, loss_ce: 0.021730 loss_dice: 0.130094\n",
            "iteration 9238 : loss : 0.060270, loss_ce: 0.014126 loss_dice: 0.091033\n",
            "iteration 9239 : loss : 0.133108, loss_ce: 0.011029 loss_dice: 0.214495\n",
            "iteration 9240 : loss : 0.091640, loss_ce: 0.020326 loss_dice: 0.139182\n",
            "iteration 9241 : loss : 0.219589, loss_ce: 0.006689 loss_dice: 0.361523\n",
            "iteration 9242 : loss : 0.110236, loss_ce: 0.015862 loss_dice: 0.173151\n",
            "iteration 9243 : loss : 0.138605, loss_ce: 0.058165 loss_dice: 0.192232\n",
            "iteration 9244 : loss : 0.098409, loss_ce: 0.012388 loss_dice: 0.155756\n",
            "iteration 9245 : loss : 0.092071, loss_ce: 0.039525 loss_dice: 0.127102\n",
            "iteration 9246 : loss : 0.146982, loss_ce: 0.031828 loss_dice: 0.223751\n",
            "iteration 9247 : loss : 0.123478, loss_ce: 0.020880 loss_dice: 0.191876\n",
            "iteration 9248 : loss : 0.104447, loss_ce: 0.020664 loss_dice: 0.160303\n",
            "iteration 9249 : loss : 0.099676, loss_ce: 0.031736 loss_dice: 0.144970\n",
            "iteration 9250 : loss : 0.081388, loss_ce: 0.051879 loss_dice: 0.101061\n",
            "iteration 9251 : loss : 0.129382, loss_ce: 0.023901 loss_dice: 0.199703\n",
            "iteration 9252 : loss : 0.087491, loss_ce: 0.025192 loss_dice: 0.129023\n",
            "iteration 9253 : loss : 0.175521, loss_ce: 0.047931 loss_dice: 0.260581\n",
            "iteration 9254 : loss : 0.117161, loss_ce: 0.023562 loss_dice: 0.179561\n",
            "iteration 9255 : loss : 0.088362, loss_ce: 0.031892 loss_dice: 0.126009\n",
            "iteration 9256 : loss : 0.193664, loss_ce: 0.021424 loss_dice: 0.308491\n",
            "iteration 9257 : loss : 0.101135, loss_ce: 0.034425 loss_dice: 0.145608\n",
            "iteration 9258 : loss : 0.085028, loss_ce: 0.022638 loss_dice: 0.126621\n",
            "iteration 9259 : loss : 0.225555, loss_ce: 0.012411 loss_dice: 0.367652\n",
            "iteration 9260 : loss : 0.129032, loss_ce: 0.036433 loss_dice: 0.190765\n",
            "iteration 9261 : loss : 0.227554, loss_ce: 0.025894 loss_dice: 0.361994\n",
            "iteration 9262 : loss : 0.081063, loss_ce: 0.024315 loss_dice: 0.118896\n",
            "iteration 9263 : loss : 0.213695, loss_ce: 0.011709 loss_dice: 0.348353\n",
            "iteration 9264 : loss : 0.099539, loss_ce: 0.035230 loss_dice: 0.142411\n",
            "iteration 9265 : loss : 0.068017, loss_ce: 0.019407 loss_dice: 0.100423\n",
            "iteration 9266 : loss : 0.090153, loss_ce: 0.039802 loss_dice: 0.123720\n",
            "iteration 9267 : loss : 0.139046, loss_ce: 0.023637 loss_dice: 0.215986\n",
            "iteration 9268 : loss : 0.289044, loss_ce: 0.013641 loss_dice: 0.472645\n",
            "iteration 9269 : loss : 0.097019, loss_ce: 0.035792 loss_dice: 0.137838\n",
            "iteration 9270 : loss : 0.132828, loss_ce: 0.024080 loss_dice: 0.205327\n",
            "iteration 9271 : loss : 0.231953, loss_ce: 0.015831 loss_dice: 0.376035\n",
            "iteration 9272 : loss : 0.072863, loss_ce: 0.023270 loss_dice: 0.105925\n",
            "iteration 9273 : loss : 0.112269, loss_ce: 0.023964 loss_dice: 0.171139\n",
            "iteration 9274 : loss : 0.169845, loss_ce: 0.016298 loss_dice: 0.272209\n",
            "iteration 9275 : loss : 0.128321, loss_ce: 0.018140 loss_dice: 0.201775\n",
            "iteration 9276 : loss : 0.078871, loss_ce: 0.030171 loss_dice: 0.111337\n",
            "iteration 9277 : loss : 0.134431, loss_ce: 0.033046 loss_dice: 0.202021\n",
            "iteration 9278 : loss : 0.099256, loss_ce: 0.016098 loss_dice: 0.154694\n",
            "iteration 9279 : loss : 0.082478, loss_ce: 0.018751 loss_dice: 0.124962\n",
            "iteration 9280 : loss : 0.124535, loss_ce: 0.021376 loss_dice: 0.193308\n",
            "iteration 9281 : loss : 0.129285, loss_ce: 0.009930 loss_dice: 0.208855\n",
            "iteration 9282 : loss : 0.193719, loss_ce: 0.016913 loss_dice: 0.311590\n",
            "iteration 9283 : loss : 0.095406, loss_ce: 0.025813 loss_dice: 0.141802\n",
            "iteration 9284 : loss : 0.256494, loss_ce: 0.008058 loss_dice: 0.422118\n",
            "iteration 9285 : loss : 0.189453, loss_ce: 0.033917 loss_dice: 0.293144\n",
            "iteration 9286 : loss : 0.164945, loss_ce: 0.031147 loss_dice: 0.254143\n",
            "iteration 9287 : loss : 0.134717, loss_ce: 0.023731 loss_dice: 0.208707\n",
            "iteration 9288 : loss : 0.143962, loss_ce: 0.027106 loss_dice: 0.221866\n",
            "iteration 9289 : loss : 0.093210, loss_ce: 0.024305 loss_dice: 0.139147\n",
            "iteration 9290 : loss : 0.172753, loss_ce: 0.008699 loss_dice: 0.282123\n",
            "iteration 9291 : loss : 0.111765, loss_ce: 0.037375 loss_dice: 0.161358\n",
            "iteration 9292 : loss : 0.147729, loss_ce: 0.051564 loss_dice: 0.211839\n",
            "iteration 9293 : loss : 0.073815, loss_ce: 0.034815 loss_dice: 0.099814\n",
            "iteration 9294 : loss : 0.093409, loss_ce: 0.044187 loss_dice: 0.126223\n",
            "iteration 9295 : loss : 0.223375, loss_ce: 0.039622 loss_dice: 0.345877\n",
            "iteration 9296 : loss : 0.129399, loss_ce: 0.062815 loss_dice: 0.173788\n",
            "iteration 9297 : loss : 0.126950, loss_ce: 0.067628 loss_dice: 0.166497\n",
            "iteration 9298 : loss : 0.093119, loss_ce: 0.037613 loss_dice: 0.130123\n",
            "iteration 9299 : loss : 0.140030, loss_ce: 0.048750 loss_dice: 0.200884\n",
            "iteration 9300 : loss : 0.119353, loss_ce: 0.049797 loss_dice: 0.165724\n",
            "iteration 9301 : loss : 0.096501, loss_ce: 0.030060 loss_dice: 0.140794\n",
            "iteration 9302 : loss : 0.314029, loss_ce: 0.011343 loss_dice: 0.515819\n",
            "iteration 9303 : loss : 0.126244, loss_ce: 0.028345 loss_dice: 0.191510\n",
            "iteration 9304 : loss : 0.178998, loss_ce: 0.018455 loss_dice: 0.286027\n",
            "iteration 9305 : loss : 0.214170, loss_ce: 0.018555 loss_dice: 0.344579\n",
            "iteration 9306 : loss : 0.094993, loss_ce: 0.019577 loss_dice: 0.145270\n",
            "iteration 9307 : loss : 0.146322, loss_ce: 0.028226 loss_dice: 0.225053\n",
            "iteration 9308 : loss : 0.113321, loss_ce: 0.041623 loss_dice: 0.161119\n",
            "iteration 9309 : loss : 0.069048, loss_ce: 0.015774 loss_dice: 0.104565\n",
            "iteration 9310 : loss : 0.138456, loss_ce: 0.064701 loss_dice: 0.187626\n",
            "iteration 9311 : loss : 0.125928, loss_ce: 0.024685 loss_dice: 0.193424\n",
            "iteration 9312 : loss : 0.162601, loss_ce: 0.036404 loss_dice: 0.246732\n",
            "iteration 9313 : loss : 0.236203, loss_ce: 0.035821 loss_dice: 0.369790\n",
            "iteration 9314 : loss : 0.159794, loss_ce: 0.040511 loss_dice: 0.239316\n",
            "iteration 9315 : loss : 0.081669, loss_ce: 0.033965 loss_dice: 0.113471\n",
            "iteration 9316 : loss : 0.157418, loss_ce: 0.030876 loss_dice: 0.241779\n",
            "iteration 9317 : loss : 0.167450, loss_ce: 0.046304 loss_dice: 0.248214\n",
            "iteration 9318 : loss : 0.101742, loss_ce: 0.021045 loss_dice: 0.155539\n",
            "iteration 9319 : loss : 0.096480, loss_ce: 0.034927 loss_dice: 0.137516\n",
            "iteration 9320 : loss : 0.215973, loss_ce: 0.073439 loss_dice: 0.310996\n",
            "iteration 9321 : loss : 0.121102, loss_ce: 0.013859 loss_dice: 0.192598\n",
            "iteration 9322 : loss : 0.149678, loss_ce: 0.027058 loss_dice: 0.231425\n",
            "iteration 9323 : loss : 0.313260, loss_ce: 0.030293 loss_dice: 0.501905\n",
            "iteration 9324 : loss : 0.170349, loss_ce: 0.001379 loss_dice: 0.282995\n",
            "  8%|██▏                       | 42/500 [1:45:21<35:32:47, 279.41s/it]iteration 9325 : loss : 0.168958, loss_ce: 0.068930 loss_dice: 0.235643\n",
            "iteration 9326 : loss : 0.145816, loss_ce: 0.030244 loss_dice: 0.222864\n",
            "iteration 9327 : loss : 0.193483, loss_ce: 0.028337 loss_dice: 0.303580\n",
            "iteration 9328 : loss : 0.199001, loss_ce: 0.048006 loss_dice: 0.299665\n",
            "iteration 9329 : loss : 0.148888, loss_ce: 0.048710 loss_dice: 0.215673\n",
            "iteration 9330 : loss : 0.077004, loss_ce: 0.013431 loss_dice: 0.119385\n",
            "iteration 9331 : loss : 0.202623, loss_ce: 0.037971 loss_dice: 0.312391\n",
            "iteration 9332 : loss : 0.120253, loss_ce: 0.051080 loss_dice: 0.166368\n",
            "iteration 9333 : loss : 0.170912, loss_ce: 0.030905 loss_dice: 0.264251\n",
            "iteration 9334 : loss : 0.240563, loss_ce: 0.021219 loss_dice: 0.386793\n",
            "iteration 9335 : loss : 0.118453, loss_ce: 0.033168 loss_dice: 0.175310\n",
            "iteration 9336 : loss : 0.203229, loss_ce: 0.035855 loss_dice: 0.314812\n",
            "iteration 9337 : loss : 0.189617, loss_ce: 0.033978 loss_dice: 0.293375\n",
            "iteration 9338 : loss : 0.123808, loss_ce: 0.013920 loss_dice: 0.197066\n",
            "iteration 9339 : loss : 0.189316, loss_ce: 0.058083 loss_dice: 0.276805\n",
            "iteration 9340 : loss : 0.187372, loss_ce: 0.025480 loss_dice: 0.295301\n",
            "iteration 9341 : loss : 0.141390, loss_ce: 0.036386 loss_dice: 0.211393\n",
            "iteration 9342 : loss : 0.166269, loss_ce: 0.053447 loss_dice: 0.241483\n",
            "iteration 9343 : loss : 0.115109, loss_ce: 0.055485 loss_dice: 0.154858\n",
            "iteration 9344 : loss : 0.125504, loss_ce: 0.069280 loss_dice: 0.162987\n",
            "iteration 9345 : loss : 0.072446, loss_ce: 0.023508 loss_dice: 0.105071\n",
            "iteration 9346 : loss : 0.247875, loss_ce: 0.013691 loss_dice: 0.403997\n",
            "iteration 9347 : loss : 0.148994, loss_ce: 0.037444 loss_dice: 0.223360\n",
            "iteration 9348 : loss : 0.147941, loss_ce: 0.050620 loss_dice: 0.212821\n",
            "iteration 9349 : loss : 0.300024, loss_ce: 0.021801 loss_dice: 0.485506\n",
            "iteration 9350 : loss : 0.174741, loss_ce: 0.048756 loss_dice: 0.258731\n",
            "iteration 9351 : loss : 0.183525, loss_ce: 0.061014 loss_dice: 0.265198\n",
            "iteration 9352 : loss : 0.118797, loss_ce: 0.036711 loss_dice: 0.173522\n",
            "iteration 9353 : loss : 0.110741, loss_ce: 0.058276 loss_dice: 0.145717\n",
            "iteration 9354 : loss : 0.163584, loss_ce: 0.011584 loss_dice: 0.264918\n",
            "iteration 9355 : loss : 0.059744, loss_ce: 0.018470 loss_dice: 0.087260\n",
            "iteration 9356 : loss : 0.195467, loss_ce: 0.036478 loss_dice: 0.301460\n",
            "iteration 9357 : loss : 0.180680, loss_ce: 0.017630 loss_dice: 0.289380\n",
            "iteration 9358 : loss : 0.110939, loss_ce: 0.061955 loss_dice: 0.143595\n",
            "iteration 9359 : loss : 0.232473, loss_ce: 0.004055 loss_dice: 0.384751\n",
            "iteration 9360 : loss : 0.113161, loss_ce: 0.033225 loss_dice: 0.166452\n",
            "iteration 9361 : loss : 0.128743, loss_ce: 0.060946 loss_dice: 0.173942\n",
            "iteration 9362 : loss : 0.147620, loss_ce: 0.020184 loss_dice: 0.232578\n",
            "iteration 9363 : loss : 0.110081, loss_ce: 0.037466 loss_dice: 0.158491\n",
            "iteration 9364 : loss : 0.224539, loss_ce: 0.015574 loss_dice: 0.363849\n",
            "iteration 9365 : loss : 0.103774, loss_ce: 0.024404 loss_dice: 0.156687\n",
            "iteration 9366 : loss : 0.161582, loss_ce: 0.018203 loss_dice: 0.257168\n",
            "iteration 9367 : loss : 0.172648, loss_ce: 0.040852 loss_dice: 0.260512\n",
            "iteration 9368 : loss : 0.143252, loss_ce: 0.025721 loss_dice: 0.221606\n",
            "iteration 9369 : loss : 0.202688, loss_ce: 0.045152 loss_dice: 0.307713\n",
            "iteration 9370 : loss : 0.209840, loss_ce: 0.022426 loss_dice: 0.334783\n",
            "iteration 9371 : loss : 0.334456, loss_ce: 0.003482 loss_dice: 0.555106\n",
            "iteration 9372 : loss : 0.101716, loss_ce: 0.012209 loss_dice: 0.161387\n",
            "iteration 9373 : loss : 0.143768, loss_ce: 0.032361 loss_dice: 0.218040\n",
            "iteration 9374 : loss : 0.172391, loss_ce: 0.040124 loss_dice: 0.260569\n",
            "iteration 9375 : loss : 0.182140, loss_ce: 0.024072 loss_dice: 0.287518\n",
            "iteration 9376 : loss : 0.188558, loss_ce: 0.019373 loss_dice: 0.301348\n",
            "iteration 9377 : loss : 0.201128, loss_ce: 0.028548 loss_dice: 0.316182\n",
            "iteration 9378 : loss : 0.160336, loss_ce: 0.048299 loss_dice: 0.235027\n",
            "iteration 9379 : loss : 0.206005, loss_ce: 0.039950 loss_dice: 0.316708\n",
            "iteration 9380 : loss : 0.112746, loss_ce: 0.024593 loss_dice: 0.171515\n",
            "iteration 9381 : loss : 0.233524, loss_ce: 0.022317 loss_dice: 0.374328\n",
            "iteration 9382 : loss : 0.145415, loss_ce: 0.054678 loss_dice: 0.205907\n",
            "iteration 9383 : loss : 0.115801, loss_ce: 0.035900 loss_dice: 0.169068\n",
            "iteration 9384 : loss : 0.155347, loss_ce: 0.035652 loss_dice: 0.235144\n",
            "iteration 9385 : loss : 0.170229, loss_ce: 0.048865 loss_dice: 0.251138\n",
            "iteration 9386 : loss : 0.169879, loss_ce: 0.057994 loss_dice: 0.244469\n",
            "iteration 9387 : loss : 0.175298, loss_ce: 0.012260 loss_dice: 0.283990\n",
            "iteration 9388 : loss : 0.132923, loss_ce: 0.026268 loss_dice: 0.204026\n",
            "iteration 9389 : loss : 0.121568, loss_ce: 0.020302 loss_dice: 0.189078\n",
            "iteration 9390 : loss : 0.080321, loss_ce: 0.029884 loss_dice: 0.113945\n",
            "iteration 9391 : loss : 0.152615, loss_ce: 0.037225 loss_dice: 0.229542\n",
            "iteration 9392 : loss : 0.154827, loss_ce: 0.021036 loss_dice: 0.244022\n",
            "iteration 9393 : loss : 0.116431, loss_ce: 0.047245 loss_dice: 0.162556\n",
            "iteration 9394 : loss : 0.119351, loss_ce: 0.016907 loss_dice: 0.187647\n",
            "iteration 9395 : loss : 0.165111, loss_ce: 0.036998 loss_dice: 0.250520\n",
            "iteration 9396 : loss : 0.134873, loss_ce: 0.018676 loss_dice: 0.212337\n",
            "iteration 9397 : loss : 0.232536, loss_ce: 0.029788 loss_dice: 0.367701\n",
            "iteration 9398 : loss : 0.135433, loss_ce: 0.019629 loss_dice: 0.212635\n",
            "iteration 9399 : loss : 0.131719, loss_ce: 0.042665 loss_dice: 0.191088\n",
            "iteration 9400 : loss : 0.286741, loss_ce: 0.032675 loss_dice: 0.456118\n",
            "iteration 9401 : loss : 0.231940, loss_ce: 0.007205 loss_dice: 0.381764\n",
            "iteration 9402 : loss : 0.121134, loss_ce: 0.027101 loss_dice: 0.183822\n",
            "iteration 9403 : loss : 0.121317, loss_ce: 0.026084 loss_dice: 0.184806\n",
            "iteration 9404 : loss : 0.162524, loss_ce: 0.030919 loss_dice: 0.250261\n",
            "iteration 9405 : loss : 0.251005, loss_ce: 0.008338 loss_dice: 0.412783\n",
            "iteration 9406 : loss : 0.137674, loss_ce: 0.016622 loss_dice: 0.218376\n",
            "iteration 9407 : loss : 0.211717, loss_ce: 0.032518 loss_dice: 0.331183\n",
            "iteration 9408 : loss : 0.104841, loss_ce: 0.041633 loss_dice: 0.146980\n",
            "iteration 9409 : loss : 0.086003, loss_ce: 0.040012 loss_dice: 0.116663\n",
            "iteration 9410 : loss : 0.098447, loss_ce: 0.027514 loss_dice: 0.145735\n",
            "iteration 9411 : loss : 0.149067, loss_ce: 0.044027 loss_dice: 0.219093\n",
            "iteration 9412 : loss : 0.183133, loss_ce: 0.017601 loss_dice: 0.293488\n",
            "iteration 9413 : loss : 0.168134, loss_ce: 0.045301 loss_dice: 0.250022\n",
            "iteration 9414 : loss : 0.259957, loss_ce: 0.032753 loss_dice: 0.411426\n",
            "iteration 9415 : loss : 0.291742, loss_ce: 0.075364 loss_dice: 0.435994\n",
            "iteration 9416 : loss : 0.144333, loss_ce: 0.038493 loss_dice: 0.214892\n",
            "iteration 9417 : loss : 0.199712, loss_ce: 0.040773 loss_dice: 0.305671\n",
            "iteration 9418 : loss : 0.130228, loss_ce: 0.030779 loss_dice: 0.196528\n",
            "iteration 9419 : loss : 0.129969, loss_ce: 0.032015 loss_dice: 0.195271\n",
            "iteration 9420 : loss : 0.083287, loss_ce: 0.041343 loss_dice: 0.111250\n",
            "iteration 9421 : loss : 0.084703, loss_ce: 0.021688 loss_dice: 0.126712\n",
            "iteration 9422 : loss : 0.136763, loss_ce: 0.015197 loss_dice: 0.217808\n",
            "iteration 9423 : loss : 0.086834, loss_ce: 0.026910 loss_dice: 0.126784\n",
            "iteration 9424 : loss : 0.185464, loss_ce: 0.023213 loss_dice: 0.293631\n",
            "iteration 9425 : loss : 0.082893, loss_ce: 0.025073 loss_dice: 0.121439\n",
            "iteration 9426 : loss : 0.179063, loss_ce: 0.075192 loss_dice: 0.248310\n",
            "iteration 9427 : loss : 0.216724, loss_ce: 0.047734 loss_dice: 0.329384\n",
            "iteration 9428 : loss : 0.089666, loss_ce: 0.028454 loss_dice: 0.130474\n",
            "iteration 9429 : loss : 0.143942, loss_ce: 0.053196 loss_dice: 0.204440\n",
            "iteration 9430 : loss : 0.138880, loss_ce: 0.027363 loss_dice: 0.213225\n",
            "iteration 9431 : loss : 0.153273, loss_ce: 0.062618 loss_dice: 0.213710\n",
            "iteration 9432 : loss : 0.075421, loss_ce: 0.037052 loss_dice: 0.101000\n",
            "iteration 9433 : loss : 0.188709, loss_ce: 0.080746 loss_dice: 0.260684\n",
            "iteration 9434 : loss : 0.131864, loss_ce: 0.013137 loss_dice: 0.211016\n",
            "iteration 9435 : loss : 0.103549, loss_ce: 0.035991 loss_dice: 0.148588\n",
            "iteration 9436 : loss : 0.187504, loss_ce: 0.007403 loss_dice: 0.307572\n",
            "iteration 9437 : loss : 0.119082, loss_ce: 0.042505 loss_dice: 0.170133\n",
            "iteration 9438 : loss : 0.243360, loss_ce: 0.027519 loss_dice: 0.387253\n",
            "iteration 9439 : loss : 0.204489, loss_ce: 0.050404 loss_dice: 0.307212\n",
            "iteration 9440 : loss : 0.141505, loss_ce: 0.039838 loss_dice: 0.209283\n",
            "iteration 9441 : loss : 0.160460, loss_ce: 0.031854 loss_dice: 0.246197\n",
            "iteration 9442 : loss : 0.146171, loss_ce: 0.043717 loss_dice: 0.214473\n",
            "iteration 9443 : loss : 0.104184, loss_ce: 0.040947 loss_dice: 0.146343\n",
            "iteration 9444 : loss : 0.137818, loss_ce: 0.015878 loss_dice: 0.219111\n",
            "iteration 9445 : loss : 0.089950, loss_ce: 0.021838 loss_dice: 0.135359\n",
            "iteration 9446 : loss : 0.152767, loss_ce: 0.043169 loss_dice: 0.225832\n",
            "iteration 9447 : loss : 0.139011, loss_ce: 0.043282 loss_dice: 0.202831\n",
            "iteration 9448 : loss : 0.150028, loss_ce: 0.027603 loss_dice: 0.231644\n",
            "iteration 9449 : loss : 0.072905, loss_ce: 0.027380 loss_dice: 0.103255\n",
            "iteration 9450 : loss : 0.103809, loss_ce: 0.038326 loss_dice: 0.147465\n",
            "iteration 9451 : loss : 0.112549, loss_ce: 0.021386 loss_dice: 0.173325\n",
            "iteration 9452 : loss : 0.112734, loss_ce: 0.032744 loss_dice: 0.166060\n",
            "iteration 9453 : loss : 0.157337, loss_ce: 0.028688 loss_dice: 0.243103\n",
            "iteration 9454 : loss : 0.148290, loss_ce: 0.037822 loss_dice: 0.221935\n",
            "iteration 9455 : loss : 0.094633, loss_ce: 0.029415 loss_dice: 0.138112\n",
            "iteration 9456 : loss : 0.246800, loss_ce: 0.020826 loss_dice: 0.397449\n",
            "iteration 9457 : loss : 0.127560, loss_ce: 0.025476 loss_dice: 0.195617\n",
            "iteration 9458 : loss : 0.161932, loss_ce: 0.036186 loss_dice: 0.245763\n",
            "iteration 9459 : loss : 0.135514, loss_ce: 0.063060 loss_dice: 0.183817\n",
            "iteration 9460 : loss : 0.106115, loss_ce: 0.034191 loss_dice: 0.154065\n",
            "iteration 9461 : loss : 0.110294, loss_ce: 0.028262 loss_dice: 0.164983\n",
            "iteration 9462 : loss : 0.067185, loss_ce: 0.009255 loss_dice: 0.105805\n",
            "iteration 9463 : loss : 0.108934, loss_ce: 0.009587 loss_dice: 0.175164\n",
            "iteration 9464 : loss : 0.169206, loss_ce: 0.012627 loss_dice: 0.273593\n",
            "iteration 9465 : loss : 0.157941, loss_ce: 0.016435 loss_dice: 0.252278\n",
            "iteration 9466 : loss : 0.290784, loss_ce: 0.005870 loss_dice: 0.480727\n",
            "iteration 9467 : loss : 0.099191, loss_ce: 0.030549 loss_dice: 0.144953\n",
            "iteration 9468 : loss : 0.077722, loss_ce: 0.029493 loss_dice: 0.109875\n",
            "iteration 9469 : loss : 0.122410, loss_ce: 0.022165 loss_dice: 0.189240\n",
            "iteration 9470 : loss : 0.080810, loss_ce: 0.025764 loss_dice: 0.117508\n",
            "iteration 9471 : loss : 0.169964, loss_ce: 0.025943 loss_dice: 0.265978\n",
            "iteration 9472 : loss : 0.091264, loss_ce: 0.038015 loss_dice: 0.126762\n",
            "iteration 9473 : loss : 0.086416, loss_ce: 0.026616 loss_dice: 0.126283\n",
            "iteration 9474 : loss : 0.241963, loss_ce: 0.017820 loss_dice: 0.391392\n",
            "iteration 9475 : loss : 0.101867, loss_ce: 0.038971 loss_dice: 0.143797\n",
            "iteration 9476 : loss : 0.196443, loss_ce: 0.009755 loss_dice: 0.320902\n",
            "iteration 9477 : loss : 0.144357, loss_ce: 0.035035 loss_dice: 0.217239\n",
            "iteration 9478 : loss : 0.088506, loss_ce: 0.024325 loss_dice: 0.131292\n",
            "iteration 9479 : loss : 0.123035, loss_ce: 0.046729 loss_dice: 0.173905\n",
            "iteration 9480 : loss : 0.118186, loss_ce: 0.033347 loss_dice: 0.174745\n",
            "iteration 9481 : loss : 0.103247, loss_ce: 0.022615 loss_dice: 0.157001\n",
            "iteration 9482 : loss : 0.098245, loss_ce: 0.022254 loss_dice: 0.148906\n",
            "iteration 9483 : loss : 0.382715, loss_ce: 0.001944 loss_dice: 0.636562\n",
            "iteration 9484 : loss : 0.087923, loss_ce: 0.035378 loss_dice: 0.122953\n",
            "iteration 9485 : loss : 0.253610, loss_ce: 0.043019 loss_dice: 0.394004\n",
            "iteration 9486 : loss : 0.146475, loss_ce: 0.045265 loss_dice: 0.213949\n",
            "iteration 9487 : loss : 0.094060, loss_ce: 0.026328 loss_dice: 0.139215\n",
            "iteration 9488 : loss : 0.141520, loss_ce: 0.037551 loss_dice: 0.210832\n",
            "iteration 9489 : loss : 0.160148, loss_ce: 0.038335 loss_dice: 0.241356\n",
            "iteration 9490 : loss : 0.150252, loss_ce: 0.030382 loss_dice: 0.230165\n",
            "iteration 9491 : loss : 0.206056, loss_ce: 0.022338 loss_dice: 0.328534\n",
            "iteration 9492 : loss : 0.183395, loss_ce: 0.026043 loss_dice: 0.288296\n",
            "iteration 9493 : loss : 0.133019, loss_ce: 0.015934 loss_dice: 0.211076\n",
            "iteration 9494 : loss : 0.301160, loss_ce: 0.004631 loss_dice: 0.498846\n",
            "iteration 9495 : loss : 0.135227, loss_ce: 0.034160 loss_dice: 0.202605\n",
            "iteration 9496 : loss : 0.165448, loss_ce: 0.045943 loss_dice: 0.245118\n",
            "iteration 9497 : loss : 0.135558, loss_ce: 0.048664 loss_dice: 0.193487\n",
            "iteration 9498 : loss : 0.175374, loss_ce: 0.035721 loss_dice: 0.268476\n",
            "iteration 9499 : loss : 0.147141, loss_ce: 0.034427 loss_dice: 0.222285\n",
            "iteration 9500 : loss : 0.184932, loss_ce: 0.043653 loss_dice: 0.279118\n",
            "iteration 9501 : loss : 0.124592, loss_ce: 0.047582 loss_dice: 0.175933\n",
            "iteration 9502 : loss : 0.298362, loss_ce: 0.008478 loss_dice: 0.491618\n",
            "iteration 9503 : loss : 0.208240, loss_ce: 0.016030 loss_dice: 0.336380\n",
            "iteration 9504 : loss : 0.127993, loss_ce: 0.070745 loss_dice: 0.166158\n",
            "iteration 9505 : loss : 0.180843, loss_ce: 0.041217 loss_dice: 0.273928\n",
            "iteration 9506 : loss : 0.233518, loss_ce: 0.104849 loss_dice: 0.319298\n",
            "iteration 9507 : loss : 0.240413, loss_ce: 0.080190 loss_dice: 0.347228\n",
            "iteration 9508 : loss : 0.101473, loss_ce: 0.018010 loss_dice: 0.157115\n",
            "iteration 9509 : loss : 0.227833, loss_ce: 0.011771 loss_dice: 0.371874\n",
            "iteration 9510 : loss : 0.128442, loss_ce: 0.055786 loss_dice: 0.176879\n",
            "iteration 9511 : loss : 0.093762, loss_ce: 0.037001 loss_dice: 0.131603\n",
            "iteration 9512 : loss : 0.188659, loss_ce: 0.063452 loss_dice: 0.272130\n",
            "iteration 9513 : loss : 0.162406, loss_ce: 0.052155 loss_dice: 0.235906\n",
            "iteration 9514 : loss : 0.158327, loss_ce: 0.027785 loss_dice: 0.245355\n",
            "iteration 9515 : loss : 0.166017, loss_ce: 0.071683 loss_dice: 0.228906\n",
            "iteration 9516 : loss : 0.104996, loss_ce: 0.029595 loss_dice: 0.155263\n",
            "iteration 9517 : loss : 0.243607, loss_ce: 0.019984 loss_dice: 0.392689\n",
            "iteration 9518 : loss : 0.149417, loss_ce: 0.067175 loss_dice: 0.204245\n",
            "iteration 9519 : loss : 0.171879, loss_ce: 0.029437 loss_dice: 0.266840\n",
            "iteration 9520 : loss : 0.196498, loss_ce: 0.113355 loss_dice: 0.251926\n",
            "iteration 9521 : loss : 0.143894, loss_ce: 0.040019 loss_dice: 0.213144\n",
            "iteration 9522 : loss : 0.256822, loss_ce: 0.038036 loss_dice: 0.402679\n",
            "iteration 9523 : loss : 0.127631, loss_ce: 0.050150 loss_dice: 0.179286\n",
            "iteration 9524 : loss : 0.196047, loss_ce: 0.083686 loss_dice: 0.270954\n",
            "iteration 9525 : loss : 0.241137, loss_ce: 0.008578 loss_dice: 0.396176\n",
            "iteration 9526 : loss : 0.203815, loss_ce: 0.046117 loss_dice: 0.308947\n",
            "iteration 9527 : loss : 0.165961, loss_ce: 0.016001 loss_dice: 0.265935\n",
            "iteration 9528 : loss : 0.140302, loss_ce: 0.010128 loss_dice: 0.227084\n",
            "iteration 9529 : loss : 0.223852, loss_ce: 0.057214 loss_dice: 0.334944\n",
            "iteration 9530 : loss : 0.154855, loss_ce: 0.023429 loss_dice: 0.242472\n",
            "iteration 9531 : loss : 0.235998, loss_ce: 0.089664 loss_dice: 0.333554\n",
            "iteration 9532 : loss : 0.207591, loss_ce: 0.120868 loss_dice: 0.265407\n",
            "iteration 9533 : loss : 0.150725, loss_ce: 0.039696 loss_dice: 0.224744\n",
            "iteration 9534 : loss : 0.186387, loss_ce: 0.049307 loss_dice: 0.277774\n",
            "iteration 9535 : loss : 0.238888, loss_ce: 0.089487 loss_dice: 0.338488\n",
            "iteration 9536 : loss : 0.191126, loss_ce: 0.080843 loss_dice: 0.264648\n",
            "iteration 9537 : loss : 0.166264, loss_ce: 0.074290 loss_dice: 0.227581\n",
            "iteration 9538 : loss : 0.235743, loss_ce: 0.040423 loss_dice: 0.365957\n",
            "iteration 9539 : loss : 0.254734, loss_ce: 0.045216 loss_dice: 0.394412\n",
            "iteration 9540 : loss : 0.142086, loss_ce: 0.044067 loss_dice: 0.207432\n",
            "iteration 9541 : loss : 0.131700, loss_ce: 0.063005 loss_dice: 0.177497\n",
            "iteration 9542 : loss : 0.310944, loss_ce: 0.091060 loss_dice: 0.457533\n",
            "iteration 9543 : loss : 0.188230, loss_ce: 0.076328 loss_dice: 0.262832\n",
            "iteration 9544 : loss : 0.174824, loss_ce: 0.084018 loss_dice: 0.235362\n",
            "iteration 9545 : loss : 0.153681, loss_ce: 0.056036 loss_dice: 0.218777\n",
            "iteration 9546 : loss : 0.292339, loss_ce: 0.123621 loss_dice: 0.404817\n",
            "  9%|██▏                       | 43/500 [1:46:46<28:02:59, 220.96s/it]iteration 9547 : loss : 0.237253, loss_ce: 0.020936 loss_dice: 0.381465\n",
            "iteration 9548 : loss : 0.161279, loss_ce: 0.022533 loss_dice: 0.253777\n",
            "iteration 9549 : loss : 0.185088, loss_ce: 0.064586 loss_dice: 0.265423\n",
            "iteration 9550 : loss : 0.205059, loss_ce: 0.037967 loss_dice: 0.316453\n",
            "iteration 9551 : loss : 0.137476, loss_ce: 0.078557 loss_dice: 0.176755\n",
            "iteration 9552 : loss : 0.144755, loss_ce: 0.061636 loss_dice: 0.200168\n",
            "iteration 9553 : loss : 0.151921, loss_ce: 0.021079 loss_dice: 0.239149\n",
            "iteration 9554 : loss : 0.159528, loss_ce: 0.060355 loss_dice: 0.225643\n",
            "iteration 9555 : loss : 0.130693, loss_ce: 0.059241 loss_dice: 0.178328\n",
            "iteration 9556 : loss : 0.154038, loss_ce: 0.023575 loss_dice: 0.241014\n",
            "iteration 9557 : loss : 0.151943, loss_ce: 0.018478 loss_dice: 0.240920\n",
            "iteration 9558 : loss : 0.156794, loss_ce: 0.047953 loss_dice: 0.229354\n",
            "iteration 9559 : loss : 0.087024, loss_ce: 0.034616 loss_dice: 0.121963\n",
            "iteration 9560 : loss : 0.239400, loss_ce: 0.067921 loss_dice: 0.353720\n",
            "iteration 9561 : loss : 0.165099, loss_ce: 0.033030 loss_dice: 0.253145\n",
            "iteration 9562 : loss : 0.149952, loss_ce: 0.015970 loss_dice: 0.239273\n",
            "iteration 9563 : loss : 0.222478, loss_ce: 0.049874 loss_dice: 0.337548\n",
            "iteration 9564 : loss : 0.114437, loss_ce: 0.025086 loss_dice: 0.174004\n",
            "iteration 9565 : loss : 0.175227, loss_ce: 0.041866 loss_dice: 0.264134\n",
            "iteration 9566 : loss : 0.240471, loss_ce: 0.025300 loss_dice: 0.383919\n",
            "iteration 9567 : loss : 0.103743, loss_ce: 0.017542 loss_dice: 0.161210\n",
            "iteration 9568 : loss : 0.167371, loss_ce: 0.025201 loss_dice: 0.262151\n",
            "iteration 9569 : loss : 0.185813, loss_ce: 0.038947 loss_dice: 0.283724\n",
            "iteration 9570 : loss : 0.137025, loss_ce: 0.031023 loss_dice: 0.207692\n",
            "iteration 9571 : loss : 0.155893, loss_ce: 0.033627 loss_dice: 0.237404\n",
            "iteration 9572 : loss : 0.086454, loss_ce: 0.034013 loss_dice: 0.121415\n",
            "iteration 9573 : loss : 0.151513, loss_ce: 0.047050 loss_dice: 0.221155\n",
            "iteration 9574 : loss : 0.204478, loss_ce: 0.010200 loss_dice: 0.333996\n",
            "iteration 9575 : loss : 0.088744, loss_ce: 0.032724 loss_dice: 0.126091\n",
            "iteration 9576 : loss : 0.116506, loss_ce: 0.026995 loss_dice: 0.176180\n",
            "iteration 9577 : loss : 0.146916, loss_ce: 0.032964 loss_dice: 0.222885\n",
            "iteration 9578 : loss : 0.117533, loss_ce: 0.042515 loss_dice: 0.167544\n",
            "iteration 9579 : loss : 0.220151, loss_ce: 0.079745 loss_dice: 0.313755\n",
            "iteration 9580 : loss : 0.169715, loss_ce: 0.034165 loss_dice: 0.260081\n",
            "iteration 9581 : loss : 0.094517, loss_ce: 0.045663 loss_dice: 0.127086\n",
            "iteration 9582 : loss : 0.155011, loss_ce: 0.050131 loss_dice: 0.224930\n",
            "iteration 9583 : loss : 0.127185, loss_ce: 0.051646 loss_dice: 0.177545\n",
            "iteration 9584 : loss : 0.131840, loss_ce: 0.018171 loss_dice: 0.207620\n",
            "iteration 9585 : loss : 0.173454, loss_ce: 0.022399 loss_dice: 0.274157\n",
            "iteration 9586 : loss : 0.157549, loss_ce: 0.043186 loss_dice: 0.233790\n",
            "iteration 9587 : loss : 0.153459, loss_ce: 0.052615 loss_dice: 0.220689\n",
            "iteration 9588 : loss : 0.126598, loss_ce: 0.010633 loss_dice: 0.203908\n",
            "iteration 9589 : loss : 0.134588, loss_ce: 0.032392 loss_dice: 0.202719\n",
            "iteration 9590 : loss : 0.185368, loss_ce: 0.049958 loss_dice: 0.275641\n",
            "iteration 9591 : loss : 0.170999, loss_ce: 0.052182 loss_dice: 0.250210\n",
            "iteration 9592 : loss : 0.102829, loss_ce: 0.042525 loss_dice: 0.143033\n",
            "iteration 9593 : loss : 0.146187, loss_ce: 0.037084 loss_dice: 0.218922\n",
            "iteration 9594 : loss : 0.127156, loss_ce: 0.022767 loss_dice: 0.196748\n",
            "iteration 9595 : loss : 0.120809, loss_ce: 0.008628 loss_dice: 0.195597\n",
            "iteration 9596 : loss : 0.141136, loss_ce: 0.047016 loss_dice: 0.203883\n",
            "iteration 9597 : loss : 0.098651, loss_ce: 0.029838 loss_dice: 0.144525\n",
            "iteration 9598 : loss : 0.091522, loss_ce: 0.035055 loss_dice: 0.129166\n",
            "iteration 9599 : loss : 0.097916, loss_ce: 0.026930 loss_dice: 0.145240\n",
            "iteration 9600 : loss : 0.167840, loss_ce: 0.016474 loss_dice: 0.268751\n",
            "iteration 9601 : loss : 0.154052, loss_ce: 0.031253 loss_dice: 0.235917\n",
            "iteration 9602 : loss : 0.135163, loss_ce: 0.037576 loss_dice: 0.200221\n",
            "iteration 9603 : loss : 0.131048, loss_ce: 0.040016 loss_dice: 0.191735\n",
            "iteration 9604 : loss : 0.124414, loss_ce: 0.035516 loss_dice: 0.183679\n",
            "iteration 9605 : loss : 0.163750, loss_ce: 0.022693 loss_dice: 0.257788\n",
            "iteration 9606 : loss : 0.163288, loss_ce: 0.018130 loss_dice: 0.260060\n",
            "iteration 9607 : loss : 0.128914, loss_ce: 0.034421 loss_dice: 0.191910\n",
            "iteration 9608 : loss : 0.088520, loss_ce: 0.025164 loss_dice: 0.130757\n",
            "iteration 9609 : loss : 0.156117, loss_ce: 0.042634 loss_dice: 0.231773\n",
            "iteration 9610 : loss : 0.138419, loss_ce: 0.009249 loss_dice: 0.224533\n",
            "iteration 9611 : loss : 0.194489, loss_ce: 0.019095 loss_dice: 0.311418\n",
            "iteration 9612 : loss : 0.093134, loss_ce: 0.027418 loss_dice: 0.136945\n",
            "iteration 9613 : loss : 0.136356, loss_ce: 0.040344 loss_dice: 0.200363\n",
            "iteration 9614 : loss : 0.174099, loss_ce: 0.040991 loss_dice: 0.262838\n",
            "iteration 9615 : loss : 0.096184, loss_ce: 0.026544 loss_dice: 0.142611\n",
            "iteration 9616 : loss : 0.127647, loss_ce: 0.034218 loss_dice: 0.189933\n",
            "iteration 9617 : loss : 0.080306, loss_ce: 0.028615 loss_dice: 0.114767\n",
            "iteration 9618 : loss : 0.129488, loss_ce: 0.017803 loss_dice: 0.203945\n",
            "iteration 9619 : loss : 0.114471, loss_ce: 0.016204 loss_dice: 0.179983\n",
            "iteration 9620 : loss : 0.100312, loss_ce: 0.031619 loss_dice: 0.146107\n",
            "iteration 9621 : loss : 0.090374, loss_ce: 0.048449 loss_dice: 0.118325\n",
            "iteration 9622 : loss : 0.134370, loss_ce: 0.026619 loss_dice: 0.206204\n",
            "iteration 9623 : loss : 0.102239, loss_ce: 0.051367 loss_dice: 0.136153\n",
            "iteration 9624 : loss : 0.235722, loss_ce: 0.051094 loss_dice: 0.358808\n",
            "iteration 9625 : loss : 0.193170, loss_ce: 0.042319 loss_dice: 0.293737\n",
            "iteration 9626 : loss : 0.120580, loss_ce: 0.034070 loss_dice: 0.178254\n",
            "iteration 9627 : loss : 0.220812, loss_ce: 0.059432 loss_dice: 0.328399\n",
            "iteration 9628 : loss : 0.142897, loss_ce: 0.045486 loss_dice: 0.207838\n",
            "iteration 9629 : loss : 0.209826, loss_ce: 0.084250 loss_dice: 0.293544\n",
            "iteration 9630 : loss : 0.154508, loss_ce: 0.045098 loss_dice: 0.227447\n",
            "iteration 9631 : loss : 0.161110, loss_ce: 0.037037 loss_dice: 0.243824\n",
            "iteration 9632 : loss : 0.119926, loss_ce: 0.040275 loss_dice: 0.173027\n",
            "iteration 9633 : loss : 0.150799, loss_ce: 0.057462 loss_dice: 0.213023\n",
            "iteration 9634 : loss : 0.146113, loss_ce: 0.046851 loss_dice: 0.212287\n",
            "iteration 9635 : loss : 0.274838, loss_ce: 0.035604 loss_dice: 0.434327\n",
            "iteration 9636 : loss : 0.263575, loss_ce: 0.023833 loss_dice: 0.423403\n",
            "iteration 9637 : loss : 0.160485, loss_ce: 0.016584 loss_dice: 0.256420\n",
            "iteration 9638 : loss : 0.207902, loss_ce: 0.034584 loss_dice: 0.323448\n",
            "iteration 9639 : loss : 0.132729, loss_ce: 0.050499 loss_dice: 0.187549\n",
            "iteration 9640 : loss : 0.133473, loss_ce: 0.062627 loss_dice: 0.180704\n",
            "iteration 9641 : loss : 0.242956, loss_ce: 0.029047 loss_dice: 0.385563\n",
            "iteration 9642 : loss : 0.168329, loss_ce: 0.067533 loss_dice: 0.235527\n",
            "iteration 9643 : loss : 0.088071, loss_ce: 0.012676 loss_dice: 0.138333\n",
            "iteration 9644 : loss : 0.134706, loss_ce: 0.022054 loss_dice: 0.209808\n",
            "iteration 9645 : loss : 0.266223, loss_ce: 0.042855 loss_dice: 0.415135\n",
            "iteration 9646 : loss : 0.115967, loss_ce: 0.039658 loss_dice: 0.166840\n",
            "iteration 9647 : loss : 0.192282, loss_ce: 0.037266 loss_dice: 0.295626\n",
            "iteration 9648 : loss : 0.189645, loss_ce: 0.024705 loss_dice: 0.299606\n",
            "iteration 9649 : loss : 0.199432, loss_ce: 0.022383 loss_dice: 0.317465\n",
            "iteration 9650 : loss : 0.106608, loss_ce: 0.030875 loss_dice: 0.157096\n",
            "iteration 9651 : loss : 0.175033, loss_ce: 0.012261 loss_dice: 0.283547\n",
            "iteration 9652 : loss : 0.119480, loss_ce: 0.027605 loss_dice: 0.180729\n",
            "iteration 9653 : loss : 0.114661, loss_ce: 0.044343 loss_dice: 0.161539\n",
            "iteration 9654 : loss : 0.150192, loss_ce: 0.017108 loss_dice: 0.238914\n",
            "iteration 9655 : loss : 0.098988, loss_ce: 0.036586 loss_dice: 0.140590\n",
            "iteration 9656 : loss : 0.111593, loss_ce: 0.040177 loss_dice: 0.159204\n",
            "iteration 9657 : loss : 0.297259, loss_ce: 0.025510 loss_dice: 0.478425\n",
            "iteration 9658 : loss : 0.126197, loss_ce: 0.028401 loss_dice: 0.191395\n",
            "iteration 9659 : loss : 0.176185, loss_ce: 0.003688 loss_dice: 0.291182\n",
            "iteration 9660 : loss : 0.134433, loss_ce: 0.041359 loss_dice: 0.196482\n",
            "iteration 9661 : loss : 0.138777, loss_ce: 0.023231 loss_dice: 0.215808\n",
            "iteration 9662 : loss : 0.196779, loss_ce: 0.013920 loss_dice: 0.318686\n",
            "iteration 9663 : loss : 0.183727, loss_ce: 0.056835 loss_dice: 0.268321\n",
            "iteration 9664 : loss : 0.123998, loss_ce: 0.041078 loss_dice: 0.179278\n",
            "iteration 9665 : loss : 0.239932, loss_ce: 0.051192 loss_dice: 0.365758\n",
            "iteration 9666 : loss : 0.142466, loss_ce: 0.043140 loss_dice: 0.208684\n",
            "iteration 9667 : loss : 0.217269, loss_ce: 0.059037 loss_dice: 0.322756\n",
            "iteration 9668 : loss : 0.341168, loss_ce: 0.067879 loss_dice: 0.523361\n",
            "iteration 9669 : loss : 0.119771, loss_ce: 0.029073 loss_dice: 0.180237\n",
            "iteration 9670 : loss : 0.196417, loss_ce: 0.051103 loss_dice: 0.293293\n",
            "iteration 9671 : loss : 0.183681, loss_ce: 0.051350 loss_dice: 0.271901\n",
            "iteration 9672 : loss : 0.228462, loss_ce: 0.033124 loss_dice: 0.358687\n",
            "iteration 9673 : loss : 0.210469, loss_ce: 0.071970 loss_dice: 0.302802\n",
            "iteration 9674 : loss : 0.129353, loss_ce: 0.040808 loss_dice: 0.188383\n",
            "iteration 9675 : loss : 0.139267, loss_ce: 0.050414 loss_dice: 0.198503\n",
            "iteration 9676 : loss : 0.131077, loss_ce: 0.016907 loss_dice: 0.207191\n",
            "iteration 9677 : loss : 0.133819, loss_ce: 0.061247 loss_dice: 0.182200\n",
            "iteration 9678 : loss : 0.074893, loss_ce: 0.015250 loss_dice: 0.114655\n",
            "iteration 9679 : loss : 0.143230, loss_ce: 0.051520 loss_dice: 0.204371\n",
            "iteration 9680 : loss : 0.272360, loss_ce: 0.011392 loss_dice: 0.446339\n",
            "iteration 9681 : loss : 0.123061, loss_ce: 0.048023 loss_dice: 0.173086\n",
            "iteration 9682 : loss : 0.196782, loss_ce: 0.088792 loss_dice: 0.268775\n",
            "iteration 9683 : loss : 0.124561, loss_ce: 0.034055 loss_dice: 0.184898\n",
            "iteration 9684 : loss : 0.127915, loss_ce: 0.024156 loss_dice: 0.197088\n",
            "iteration 9685 : loss : 0.102028, loss_ce: 0.026681 loss_dice: 0.152259\n",
            "iteration 9686 : loss : 0.174403, loss_ce: 0.017059 loss_dice: 0.279299\n",
            "iteration 9687 : loss : 0.189127, loss_ce: 0.026337 loss_dice: 0.297654\n",
            "iteration 9688 : loss : 0.141837, loss_ce: 0.018868 loss_dice: 0.223816\n",
            "iteration 9689 : loss : 0.128795, loss_ce: 0.048307 loss_dice: 0.182455\n",
            "iteration 9690 : loss : 0.183384, loss_ce: 0.063017 loss_dice: 0.263628\n",
            "iteration 9691 : loss : 0.137428, loss_ce: 0.021317 loss_dice: 0.214836\n",
            "iteration 9692 : loss : 0.165505, loss_ce: 0.017982 loss_dice: 0.263853\n",
            "iteration 9693 : loss : 0.138061, loss_ce: 0.007878 loss_dice: 0.224849\n",
            "iteration 9694 : loss : 0.103554, loss_ce: 0.023416 loss_dice: 0.156979\n",
            "iteration 9695 : loss : 0.144434, loss_ce: 0.028253 loss_dice: 0.221888\n",
            "iteration 9696 : loss : 0.148532, loss_ce: 0.010814 loss_dice: 0.240343\n",
            "iteration 9697 : loss : 0.177746, loss_ce: 0.038519 loss_dice: 0.270564\n",
            "iteration 9698 : loss : 0.157212, loss_ce: 0.009459 loss_dice: 0.255715\n",
            "iteration 9699 : loss : 0.190580, loss_ce: 0.052177 loss_dice: 0.282848\n",
            "iteration 9700 : loss : 0.220472, loss_ce: 0.086208 loss_dice: 0.309982\n",
            "iteration 9701 : loss : 0.268225, loss_ce: 0.076285 loss_dice: 0.396186\n",
            "iteration 9702 : loss : 0.173223, loss_ce: 0.059469 loss_dice: 0.249058\n",
            "iteration 9703 : loss : 0.193154, loss_ce: 0.064394 loss_dice: 0.278994\n",
            "iteration 9704 : loss : 0.212646, loss_ce: 0.052377 loss_dice: 0.319492\n",
            "iteration 9705 : loss : 0.162930, loss_ce: 0.104820 loss_dice: 0.201670\n",
            "iteration 9706 : loss : 0.207043, loss_ce: 0.016341 loss_dice: 0.334178\n",
            "iteration 9707 : loss : 0.171635, loss_ce: 0.041247 loss_dice: 0.258561\n",
            "iteration 9708 : loss : 0.080594, loss_ce: 0.024560 loss_dice: 0.117951\n",
            "iteration 9709 : loss : 0.238490, loss_ce: 0.027254 loss_dice: 0.379314\n",
            "iteration 9710 : loss : 0.157618, loss_ce: 0.056600 loss_dice: 0.224963\n",
            "iteration 9711 : loss : 0.160428, loss_ce: 0.022273 loss_dice: 0.252531\n",
            "iteration 9712 : loss : 0.175571, loss_ce: 0.087279 loss_dice: 0.234433\n",
            "iteration 9713 : loss : 0.156673, loss_ce: 0.043579 loss_dice: 0.232070\n",
            "iteration 9714 : loss : 0.165366, loss_ce: 0.034330 loss_dice: 0.252723\n",
            "iteration 9715 : loss : 0.221104, loss_ce: 0.010727 loss_dice: 0.361355\n",
            "iteration 9716 : loss : 0.141460, loss_ce: 0.045888 loss_dice: 0.205175\n",
            "iteration 9717 : loss : 0.126422, loss_ce: 0.029599 loss_dice: 0.190970\n",
            "iteration 9718 : loss : 0.185769, loss_ce: 0.028627 loss_dice: 0.290531\n",
            "iteration 9719 : loss : 0.116722, loss_ce: 0.042595 loss_dice: 0.166140\n",
            "iteration 9720 : loss : 0.276443, loss_ce: 0.044541 loss_dice: 0.431045\n",
            "iteration 9721 : loss : 0.089664, loss_ce: 0.032534 loss_dice: 0.127750\n",
            "iteration 9722 : loss : 0.307669, loss_ce: 0.015170 loss_dice: 0.502669\n",
            "iteration 9723 : loss : 0.131424, loss_ce: 0.044254 loss_dice: 0.189538\n",
            "iteration 9724 : loss : 0.188786, loss_ce: 0.034239 loss_dice: 0.291817\n",
            "iteration 9725 : loss : 0.149662, loss_ce: 0.030104 loss_dice: 0.229367\n",
            "iteration 9726 : loss : 0.141636, loss_ce: 0.042278 loss_dice: 0.207874\n",
            "iteration 9727 : loss : 0.178356, loss_ce: 0.062011 loss_dice: 0.255920\n",
            "iteration 9728 : loss : 0.274817, loss_ce: 0.019885 loss_dice: 0.444772\n",
            "iteration 9729 : loss : 0.137284, loss_ce: 0.022184 loss_dice: 0.214018\n",
            "iteration 9730 : loss : 0.137051, loss_ce: 0.013750 loss_dice: 0.219252\n",
            "iteration 9731 : loss : 0.089670, loss_ce: 0.018692 loss_dice: 0.136989\n",
            "iteration 9732 : loss : 0.111176, loss_ce: 0.037857 loss_dice: 0.160055\n",
            "iteration 9733 : loss : 0.184464, loss_ce: 0.016348 loss_dice: 0.296542\n",
            "iteration 9734 : loss : 0.146932, loss_ce: 0.039431 loss_dice: 0.218599\n",
            "iteration 9735 : loss : 0.098233, loss_ce: 0.015836 loss_dice: 0.153164\n",
            "iteration 9736 : loss : 0.181348, loss_ce: 0.016358 loss_dice: 0.291341\n",
            "iteration 9737 : loss : 0.163605, loss_ce: 0.070265 loss_dice: 0.225831\n",
            "iteration 9738 : loss : 0.159020, loss_ce: 0.047622 loss_dice: 0.233284\n",
            "iteration 9739 : loss : 0.124920, loss_ce: 0.019585 loss_dice: 0.195143\n",
            "iteration 9740 : loss : 0.132811, loss_ce: 0.013710 loss_dice: 0.212211\n",
            "iteration 9741 : loss : 0.119143, loss_ce: 0.011665 loss_dice: 0.190794\n",
            "iteration 9742 : loss : 0.163231, loss_ce: 0.046253 loss_dice: 0.241216\n",
            "iteration 9743 : loss : 0.225836, loss_ce: 0.042619 loss_dice: 0.347980\n",
            "iteration 9744 : loss : 0.162301, loss_ce: 0.046332 loss_dice: 0.239614\n",
            "iteration 9745 : loss : 0.151890, loss_ce: 0.047309 loss_dice: 0.221610\n",
            "iteration 9746 : loss : 0.159377, loss_ce: 0.041609 loss_dice: 0.237889\n",
            "iteration 9747 : loss : 0.207699, loss_ce: 0.046757 loss_dice: 0.314994\n",
            "iteration 9748 : loss : 0.180791, loss_ce: 0.009675 loss_dice: 0.294868\n",
            "iteration 9749 : loss : 0.169027, loss_ce: 0.032675 loss_dice: 0.259928\n",
            "iteration 9750 : loss : 0.159108, loss_ce: 0.033315 loss_dice: 0.242971\n",
            "iteration 9751 : loss : 0.140863, loss_ce: 0.043959 loss_dice: 0.205466\n",
            "iteration 9752 : loss : 0.059935, loss_ce: 0.009118 loss_dice: 0.093813\n",
            "iteration 9753 : loss : 0.149305, loss_ce: 0.035115 loss_dice: 0.225431\n",
            "iteration 9754 : loss : 0.109301, loss_ce: 0.034446 loss_dice: 0.159204\n",
            "iteration 9755 : loss : 0.114427, loss_ce: 0.022546 loss_dice: 0.175681\n",
            "iteration 9756 : loss : 0.128525, loss_ce: 0.029771 loss_dice: 0.194362\n",
            "iteration 9757 : loss : 0.146267, loss_ce: 0.028867 loss_dice: 0.224534\n",
            "iteration 9758 : loss : 0.150303, loss_ce: 0.042074 loss_dice: 0.222456\n",
            "iteration 9759 : loss : 0.156020, loss_ce: 0.052330 loss_dice: 0.225146\n",
            "iteration 9760 : loss : 0.238357, loss_ce: 0.019413 loss_dice: 0.384319\n",
            "iteration 9761 : loss : 0.178124, loss_ce: 0.048818 loss_dice: 0.264328\n",
            "iteration 9762 : loss : 0.147434, loss_ce: 0.019977 loss_dice: 0.232406\n",
            "iteration 9763 : loss : 0.144235, loss_ce: 0.042815 loss_dice: 0.211849\n",
            "iteration 9764 : loss : 0.102112, loss_ce: 0.012321 loss_dice: 0.161973\n",
            "iteration 9765 : loss : 0.177456, loss_ce: 0.037744 loss_dice: 0.270598\n",
            "iteration 9766 : loss : 0.231517, loss_ce: 0.009763 loss_dice: 0.379353\n",
            "iteration 9767 : loss : 0.086183, loss_ce: 0.037925 loss_dice: 0.118355\n",
            "iteration 9768 : loss : 0.265065, loss_ce: 0.025289 loss_dice: 0.424916\n",
            "  9%|██▎                       | 44/500 [1:48:10<22:47:59, 180.00s/it]iteration 9769 : loss : 0.090967, loss_ce: 0.024358 loss_dice: 0.135373\n",
            "iteration 9770 : loss : 0.157135, loss_ce: 0.025441 loss_dice: 0.244931\n",
            "iteration 9771 : loss : 0.147790, loss_ce: 0.027646 loss_dice: 0.227886\n",
            "iteration 9772 : loss : 0.131073, loss_ce: 0.021153 loss_dice: 0.204354\n",
            "iteration 9773 : loss : 0.146522, loss_ce: 0.028889 loss_dice: 0.224944\n",
            "iteration 9774 : loss : 0.118434, loss_ce: 0.026166 loss_dice: 0.179946\n",
            "iteration 9775 : loss : 0.145557, loss_ce: 0.035853 loss_dice: 0.218693\n",
            "iteration 9776 : loss : 0.104432, loss_ce: 0.031843 loss_dice: 0.152825\n",
            "iteration 9777 : loss : 0.186903, loss_ce: 0.022999 loss_dice: 0.296173\n",
            "iteration 9778 : loss : 0.099017, loss_ce: 0.036599 loss_dice: 0.140629\n",
            "iteration 9779 : loss : 0.130262, loss_ce: 0.031523 loss_dice: 0.196088\n",
            "iteration 9780 : loss : 0.154437, loss_ce: 0.038637 loss_dice: 0.231637\n",
            "iteration 9781 : loss : 0.108829, loss_ce: 0.034359 loss_dice: 0.158475\n",
            "iteration 9782 : loss : 0.127950, loss_ce: 0.024404 loss_dice: 0.196981\n",
            "iteration 9783 : loss : 0.118681, loss_ce: 0.014264 loss_dice: 0.188292\n",
            "iteration 9784 : loss : 0.153957, loss_ce: 0.039514 loss_dice: 0.230252\n",
            "iteration 9785 : loss : 0.088852, loss_ce: 0.014073 loss_dice: 0.138705\n",
            "iteration 9786 : loss : 0.097684, loss_ce: 0.028284 loss_dice: 0.143950\n",
            "iteration 9787 : loss : 0.157310, loss_ce: 0.026035 loss_dice: 0.244826\n",
            "iteration 9788 : loss : 0.136488, loss_ce: 0.020648 loss_dice: 0.213714\n",
            "iteration 9789 : loss : 0.060782, loss_ce: 0.030455 loss_dice: 0.081000\n",
            "iteration 9790 : loss : 0.095621, loss_ce: 0.022385 loss_dice: 0.144445\n",
            "iteration 9791 : loss : 0.142656, loss_ce: 0.019789 loss_dice: 0.224567\n",
            "iteration 9792 : loss : 0.085834, loss_ce: 0.026897 loss_dice: 0.125125\n",
            "iteration 9793 : loss : 0.142279, loss_ce: 0.019204 loss_dice: 0.224328\n",
            "iteration 9794 : loss : 0.118729, loss_ce: 0.022846 loss_dice: 0.182651\n",
            "iteration 9795 : loss : 0.070911, loss_ce: 0.022209 loss_dice: 0.103378\n",
            "iteration 9796 : loss : 0.092730, loss_ce: 0.026847 loss_dice: 0.136653\n",
            "iteration 9797 : loss : 0.133912, loss_ce: 0.071276 loss_dice: 0.175670\n",
            "iteration 9798 : loss : 0.120738, loss_ce: 0.016223 loss_dice: 0.190414\n",
            "iteration 9799 : loss : 0.188847, loss_ce: 0.009365 loss_dice: 0.308501\n",
            "iteration 9800 : loss : 0.192678, loss_ce: 0.081587 loss_dice: 0.266738\n",
            "iteration 9801 : loss : 0.125725, loss_ce: 0.012301 loss_dice: 0.201341\n",
            "iteration 9802 : loss : 0.114772, loss_ce: 0.022327 loss_dice: 0.176402\n",
            "iteration 9803 : loss : 0.219056, loss_ce: 0.062679 loss_dice: 0.323307\n",
            "iteration 9804 : loss : 0.148898, loss_ce: 0.044864 loss_dice: 0.218255\n",
            "iteration 9805 : loss : 0.071983, loss_ce: 0.015954 loss_dice: 0.109335\n",
            "iteration 9806 : loss : 0.143113, loss_ce: 0.016134 loss_dice: 0.227766\n",
            "iteration 9807 : loss : 0.212235, loss_ce: 0.022041 loss_dice: 0.339032\n",
            "iteration 9808 : loss : 0.145585, loss_ce: 0.032635 loss_dice: 0.220885\n",
            "iteration 9809 : loss : 0.153948, loss_ce: 0.041825 loss_dice: 0.228697\n",
            "iteration 9810 : loss : 0.151594, loss_ce: 0.053969 loss_dice: 0.216678\n",
            "iteration 9811 : loss : 0.154902, loss_ce: 0.021493 loss_dice: 0.243842\n",
            "iteration 9812 : loss : 0.108202, loss_ce: 0.033001 loss_dice: 0.158336\n",
            "iteration 9813 : loss : 0.162789, loss_ce: 0.052441 loss_dice: 0.236354\n",
            "iteration 9814 : loss : 0.311736, loss_ce: 0.010972 loss_dice: 0.512245\n",
            "iteration 9815 : loss : 0.127478, loss_ce: 0.015402 loss_dice: 0.202195\n",
            "iteration 9816 : loss : 0.191452, loss_ce: 0.038363 loss_dice: 0.293512\n",
            "iteration 9817 : loss : 0.133901, loss_ce: 0.027737 loss_dice: 0.204677\n",
            "iteration 9818 : loss : 0.142594, loss_ce: 0.040560 loss_dice: 0.210617\n",
            "iteration 9819 : loss : 0.161737, loss_ce: 0.060788 loss_dice: 0.229036\n",
            "iteration 9820 : loss : 0.153706, loss_ce: 0.042151 loss_dice: 0.228077\n",
            "iteration 9821 : loss : 0.178883, loss_ce: 0.050976 loss_dice: 0.264155\n",
            "iteration 9822 : loss : 0.132866, loss_ce: 0.035160 loss_dice: 0.198004\n",
            "iteration 9823 : loss : 0.180597, loss_ce: 0.024732 loss_dice: 0.284506\n",
            "iteration 9824 : loss : 0.164554, loss_ce: 0.024214 loss_dice: 0.258114\n",
            "iteration 9825 : loss : 0.142454, loss_ce: 0.029559 loss_dice: 0.217718\n",
            "iteration 9826 : loss : 0.178960, loss_ce: 0.035160 loss_dice: 0.274827\n",
            "iteration 9827 : loss : 0.158940, loss_ce: 0.037710 loss_dice: 0.239759\n",
            "iteration 9828 : loss : 0.162085, loss_ce: 0.037034 loss_dice: 0.245453\n",
            "iteration 9829 : loss : 0.166240, loss_ce: 0.016617 loss_dice: 0.265988\n",
            "iteration 9830 : loss : 0.104058, loss_ce: 0.011644 loss_dice: 0.165667\n",
            "iteration 9831 : loss : 0.159686, loss_ce: 0.044165 loss_dice: 0.236700\n",
            "iteration 9832 : loss : 0.139036, loss_ce: 0.047297 loss_dice: 0.200195\n",
            "iteration 9833 : loss : 0.143218, loss_ce: 0.045113 loss_dice: 0.208622\n",
            "iteration 9834 : loss : 0.132751, loss_ce: 0.036426 loss_dice: 0.196968\n",
            "iteration 9835 : loss : 0.223889, loss_ce: 0.016628 loss_dice: 0.362063\n",
            "iteration 9836 : loss : 0.148767, loss_ce: 0.036758 loss_dice: 0.223440\n",
            "iteration 9837 : loss : 0.060334, loss_ce: 0.016213 loss_dice: 0.089748\n",
            "iteration 9838 : loss : 0.072079, loss_ce: 0.025598 loss_dice: 0.103067\n",
            "iteration 9839 : loss : 0.161668, loss_ce: 0.033350 loss_dice: 0.247213\n",
            "iteration 9840 : loss : 0.145951, loss_ce: 0.038174 loss_dice: 0.217803\n",
            "iteration 9841 : loss : 0.096959, loss_ce: 0.037592 loss_dice: 0.136537\n",
            "iteration 9842 : loss : 0.086486, loss_ce: 0.024160 loss_dice: 0.128037\n",
            "iteration 9843 : loss : 0.094245, loss_ce: 0.034574 loss_dice: 0.134026\n",
            "iteration 9844 : loss : 0.149078, loss_ce: 0.048959 loss_dice: 0.215824\n",
            "iteration 9845 : loss : 0.186351, loss_ce: 0.025539 loss_dice: 0.293558\n",
            "iteration 9846 : loss : 0.069796, loss_ce: 0.016860 loss_dice: 0.105087\n",
            "iteration 9847 : loss : 0.144088, loss_ce: 0.052089 loss_dice: 0.205421\n",
            "iteration 9848 : loss : 0.175906, loss_ce: 0.027971 loss_dice: 0.274529\n",
            "iteration 9849 : loss : 0.163265, loss_ce: 0.037922 loss_dice: 0.246826\n",
            "iteration 9850 : loss : 0.080384, loss_ce: 0.032100 loss_dice: 0.112574\n",
            "iteration 9851 : loss : 0.135108, loss_ce: 0.020305 loss_dice: 0.211644\n",
            "iteration 9852 : loss : 0.103798, loss_ce: 0.025021 loss_dice: 0.156315\n",
            "iteration 9853 : loss : 0.091144, loss_ce: 0.028496 loss_dice: 0.132910\n",
            "iteration 9854 : loss : 0.197719, loss_ce: 0.025953 loss_dice: 0.312229\n",
            "iteration 9855 : loss : 0.133641, loss_ce: 0.040180 loss_dice: 0.195948\n",
            "iteration 9856 : loss : 0.182177, loss_ce: 0.035542 loss_dice: 0.279934\n",
            "iteration 9857 : loss : 0.167351, loss_ce: 0.006981 loss_dice: 0.274265\n",
            "iteration 9858 : loss : 0.096428, loss_ce: 0.028794 loss_dice: 0.141518\n",
            "iteration 9859 : loss : 0.100771, loss_ce: 0.036698 loss_dice: 0.143486\n",
            "iteration 9860 : loss : 0.101268, loss_ce: 0.012061 loss_dice: 0.160740\n",
            "iteration 9861 : loss : 0.208381, loss_ce: 0.040186 loss_dice: 0.320510\n",
            "iteration 9862 : loss : 0.078657, loss_ce: 0.020715 loss_dice: 0.117286\n",
            "iteration 9863 : loss : 0.136595, loss_ce: 0.013139 loss_dice: 0.218900\n",
            "iteration 9864 : loss : 0.160265, loss_ce: 0.024261 loss_dice: 0.250934\n",
            "iteration 9865 : loss : 0.168792, loss_ce: 0.020988 loss_dice: 0.267328\n",
            "iteration 9866 : loss : 0.174559, loss_ce: 0.053592 loss_dice: 0.255205\n",
            "iteration 9867 : loss : 0.115611, loss_ce: 0.023982 loss_dice: 0.176697\n",
            "iteration 9868 : loss : 0.080632, loss_ce: 0.014398 loss_dice: 0.124788\n",
            "iteration 9869 : loss : 0.258871, loss_ce: 0.009886 loss_dice: 0.424860\n",
            "iteration 9870 : loss : 0.151575, loss_ce: 0.034216 loss_dice: 0.229815\n",
            "iteration 9871 : loss : 0.121467, loss_ce: 0.041549 loss_dice: 0.174746\n",
            "iteration 9872 : loss : 0.133854, loss_ce: 0.036446 loss_dice: 0.198793\n",
            "iteration 9873 : loss : 0.146610, loss_ce: 0.016447 loss_dice: 0.233386\n",
            "iteration 9874 : loss : 0.094454, loss_ce: 0.035836 loss_dice: 0.133533\n",
            "iteration 9875 : loss : 0.071666, loss_ce: 0.030059 loss_dice: 0.099404\n",
            "iteration 9876 : loss : 0.158156, loss_ce: 0.025208 loss_dice: 0.246788\n",
            "iteration 9877 : loss : 0.182521, loss_ce: 0.056445 loss_dice: 0.266572\n",
            "iteration 9878 : loss : 0.094247, loss_ce: 0.029834 loss_dice: 0.137190\n",
            "iteration 9879 : loss : 0.142333, loss_ce: 0.035793 loss_dice: 0.213359\n",
            "iteration 9880 : loss : 0.133620, loss_ce: 0.018597 loss_dice: 0.210302\n",
            "iteration 9881 : loss : 0.108921, loss_ce: 0.046852 loss_dice: 0.150300\n",
            "iteration 9882 : loss : 0.101141, loss_ce: 0.037740 loss_dice: 0.143409\n",
            "iteration 9883 : loss : 0.104239, loss_ce: 0.009383 loss_dice: 0.167476\n",
            "iteration 9884 : loss : 0.122033, loss_ce: 0.034434 loss_dice: 0.180431\n",
            "iteration 9885 : loss : 0.088971, loss_ce: 0.027037 loss_dice: 0.130260\n",
            "iteration 9886 : loss : 0.145428, loss_ce: 0.011497 loss_dice: 0.234716\n",
            "iteration 9887 : loss : 0.090432, loss_ce: 0.025020 loss_dice: 0.134040\n",
            "iteration 9888 : loss : 0.115876, loss_ce: 0.024541 loss_dice: 0.176766\n",
            "iteration 9889 : loss : 0.106123, loss_ce: 0.027137 loss_dice: 0.158780\n",
            "iteration 9890 : loss : 0.137733, loss_ce: 0.020964 loss_dice: 0.215579\n",
            "iteration 9891 : loss : 0.069232, loss_ce: 0.016195 loss_dice: 0.104590\n",
            "iteration 9892 : loss : 0.094398, loss_ce: 0.033515 loss_dice: 0.134986\n",
            "iteration 9893 : loss : 0.113028, loss_ce: 0.039728 loss_dice: 0.161894\n",
            "iteration 9894 : loss : 0.093563, loss_ce: 0.015635 loss_dice: 0.145516\n",
            "iteration 9895 : loss : 0.236843, loss_ce: 0.027658 loss_dice: 0.376299\n",
            "iteration 9896 : loss : 0.102784, loss_ce: 0.013998 loss_dice: 0.161974\n",
            "iteration 9897 : loss : 0.085520, loss_ce: 0.027791 loss_dice: 0.124005\n",
            "iteration 9898 : loss : 0.128658, loss_ce: 0.027009 loss_dice: 0.196423\n",
            "iteration 9899 : loss : 0.133981, loss_ce: 0.023055 loss_dice: 0.207932\n",
            "iteration 9900 : loss : 0.157498, loss_ce: 0.028517 loss_dice: 0.243485\n",
            "iteration 9901 : loss : 0.096209, loss_ce: 0.037764 loss_dice: 0.135173\n",
            "iteration 9902 : loss : 0.105942, loss_ce: 0.016583 loss_dice: 0.165515\n",
            "iteration 9903 : loss : 0.106439, loss_ce: 0.039626 loss_dice: 0.150981\n",
            "iteration 9904 : loss : 0.084013, loss_ce: 0.042289 loss_dice: 0.111829\n",
            "iteration 9905 : loss : 0.074130, loss_ce: 0.022949 loss_dice: 0.108251\n",
            "iteration 9906 : loss : 0.115152, loss_ce: 0.025664 loss_dice: 0.174811\n",
            "iteration 9907 : loss : 0.087212, loss_ce: 0.027462 loss_dice: 0.127045\n",
            "iteration 9908 : loss : 0.133064, loss_ce: 0.041849 loss_dice: 0.193874\n",
            "iteration 9909 : loss : 0.122716, loss_ce: 0.011620 loss_dice: 0.196781\n",
            "iteration 9910 : loss : 0.191031, loss_ce: 0.017793 loss_dice: 0.306524\n",
            "iteration 9911 : loss : 0.092160, loss_ce: 0.040425 loss_dice: 0.126650\n",
            "iteration 9912 : loss : 0.134209, loss_ce: 0.053163 loss_dice: 0.188240\n",
            "iteration 9913 : loss : 0.070858, loss_ce: 0.026515 loss_dice: 0.100420\n",
            "iteration 9914 : loss : 0.092248, loss_ce: 0.019369 loss_dice: 0.140834\n",
            "iteration 9915 : loss : 0.233996, loss_ce: 0.013193 loss_dice: 0.381198\n",
            "iteration 9916 : loss : 0.165697, loss_ce: 0.006098 loss_dice: 0.272097\n",
            "iteration 9917 : loss : 0.148660, loss_ce: 0.051072 loss_dice: 0.213718\n",
            "iteration 9918 : loss : 0.108979, loss_ce: 0.042994 loss_dice: 0.152969\n",
            "iteration 9919 : loss : 0.171198, loss_ce: 0.035529 loss_dice: 0.261644\n",
            "iteration 9920 : loss : 0.111528, loss_ce: 0.019482 loss_dice: 0.172892\n",
            "iteration 9921 : loss : 0.171809, loss_ce: 0.025743 loss_dice: 0.269186\n",
            "iteration 9922 : loss : 0.213308, loss_ce: 0.052651 loss_dice: 0.320413\n",
            "iteration 9923 : loss : 0.174906, loss_ce: 0.067918 loss_dice: 0.246231\n",
            "iteration 9924 : loss : 0.056067, loss_ce: 0.013842 loss_dice: 0.084218\n",
            "iteration 9925 : loss : 0.260273, loss_ce: 0.051448 loss_dice: 0.399490\n",
            "iteration 9926 : loss : 0.105166, loss_ce: 0.020437 loss_dice: 0.161652\n",
            "iteration 9927 : loss : 0.176333, loss_ce: 0.013379 loss_dice: 0.284970\n",
            "iteration 9928 : loss : 0.169998, loss_ce: 0.033201 loss_dice: 0.261196\n",
            "iteration 9929 : loss : 0.163348, loss_ce: 0.018684 loss_dice: 0.259790\n",
            "iteration 9930 : loss : 0.111293, loss_ce: 0.051212 loss_dice: 0.151347\n",
            "iteration 9931 : loss : 0.144042, loss_ce: 0.033401 loss_dice: 0.217802\n",
            "iteration 9932 : loss : 0.178349, loss_ce: 0.019221 loss_dice: 0.284435\n",
            "iteration 9933 : loss : 0.077329, loss_ce: 0.023645 loss_dice: 0.113117\n",
            "iteration 9934 : loss : 0.145058, loss_ce: 0.018406 loss_dice: 0.229493\n",
            "iteration 9935 : loss : 0.233806, loss_ce: 0.104736 loss_dice: 0.319853\n",
            "iteration 9936 : loss : 0.414102, loss_ce: 0.062129 loss_dice: 0.648750\n",
            "iteration 9937 : loss : 0.306149, loss_ce: 0.059239 loss_dice: 0.470756\n",
            "iteration 9938 : loss : 0.270526, loss_ce: 0.034623 loss_dice: 0.427795\n",
            "iteration 9939 : loss : 0.283247, loss_ce: 0.061880 loss_dice: 0.430825\n",
            "iteration 9940 : loss : 0.258270, loss_ce: 0.042531 loss_dice: 0.402096\n",
            "iteration 9941 : loss : 0.218760, loss_ce: 0.059703 loss_dice: 0.324798\n",
            "iteration 9942 : loss : 0.119007, loss_ce: 0.032597 loss_dice: 0.176614\n",
            "iteration 9943 : loss : 0.226635, loss_ce: 0.080081 loss_dice: 0.324337\n",
            "iteration 9944 : loss : 0.186855, loss_ce: 0.053868 loss_dice: 0.275512\n",
            "iteration 9945 : loss : 0.162617, loss_ce: 0.037409 loss_dice: 0.246089\n",
            "iteration 9946 : loss : 0.121387, loss_ce: 0.041737 loss_dice: 0.174487\n",
            "iteration 9947 : loss : 0.127286, loss_ce: 0.048185 loss_dice: 0.180020\n",
            "iteration 9948 : loss : 0.109068, loss_ce: 0.050127 loss_dice: 0.148362\n",
            "iteration 9949 : loss : 0.271296, loss_ce: 0.068194 loss_dice: 0.406696\n",
            "iteration 9950 : loss : 0.102783, loss_ce: 0.027901 loss_dice: 0.152703\n",
            "iteration 9951 : loss : 0.192299, loss_ce: 0.012886 loss_dice: 0.311908\n",
            "iteration 9952 : loss : 0.142881, loss_ce: 0.042994 loss_dice: 0.209472\n",
            "iteration 9953 : loss : 0.196117, loss_ce: 0.046472 loss_dice: 0.295881\n",
            "iteration 9954 : loss : 0.123443, loss_ce: 0.025290 loss_dice: 0.188879\n",
            "iteration 9955 : loss : 0.104342, loss_ce: 0.025504 loss_dice: 0.156901\n",
            "iteration 9956 : loss : 0.160931, loss_ce: 0.031446 loss_dice: 0.247254\n",
            "iteration 9957 : loss : 0.190258, loss_ce: 0.050470 loss_dice: 0.283450\n",
            "iteration 9958 : loss : 0.176974, loss_ce: 0.038955 loss_dice: 0.268986\n",
            "iteration 9959 : loss : 0.261287, loss_ce: 0.029081 loss_dice: 0.416090\n",
            "iteration 9960 : loss : 0.155080, loss_ce: 0.017472 loss_dice: 0.246819\n",
            "iteration 9961 : loss : 0.153080, loss_ce: 0.030544 loss_dice: 0.234771\n",
            "iteration 9962 : loss : 0.113782, loss_ce: 0.042559 loss_dice: 0.161263\n",
            "iteration 9963 : loss : 0.180666, loss_ce: 0.008225 loss_dice: 0.295627\n",
            "iteration 9964 : loss : 0.224841, loss_ce: 0.107458 loss_dice: 0.303096\n",
            "iteration 9965 : loss : 0.275346, loss_ce: 0.100163 loss_dice: 0.392135\n",
            "iteration 9966 : loss : 0.220033, loss_ce: 0.022481 loss_dice: 0.351735\n",
            "iteration 9967 : loss : 0.133566, loss_ce: 0.047769 loss_dice: 0.190763\n",
            "iteration 9968 : loss : 0.131901, loss_ce: 0.024445 loss_dice: 0.203538\n",
            "iteration 9969 : loss : 0.185360, loss_ce: 0.036159 loss_dice: 0.284827\n",
            "iteration 9970 : loss : 0.181552, loss_ce: 0.033689 loss_dice: 0.280127\n",
            "iteration 9971 : loss : 0.190637, loss_ce: 0.057136 loss_dice: 0.279637\n",
            "iteration 9972 : loss : 0.154980, loss_ce: 0.070276 loss_dice: 0.211450\n",
            "iteration 9973 : loss : 0.287847, loss_ce: 0.027708 loss_dice: 0.461274\n",
            "iteration 9974 : loss : 0.161531, loss_ce: 0.048904 loss_dice: 0.236616\n",
            "iteration 9975 : loss : 0.112362, loss_ce: 0.046884 loss_dice: 0.156015\n",
            "iteration 9976 : loss : 0.277760, loss_ce: 0.011104 loss_dice: 0.455531\n",
            "iteration 9977 : loss : 0.141799, loss_ce: 0.053787 loss_dice: 0.200474\n",
            "iteration 9978 : loss : 0.155112, loss_ce: 0.034811 loss_dice: 0.235313\n",
            "iteration 9979 : loss : 0.239803, loss_ce: 0.052956 loss_dice: 0.364367\n",
            "iteration 9980 : loss : 0.137061, loss_ce: 0.022984 loss_dice: 0.213112\n",
            "iteration 9981 : loss : 0.142251, loss_ce: 0.010964 loss_dice: 0.229775\n",
            "iteration 9982 : loss : 0.101139, loss_ce: 0.043889 loss_dice: 0.139306\n",
            "iteration 9983 : loss : 0.162244, loss_ce: 0.068165 loss_dice: 0.224963\n",
            "iteration 9984 : loss : 0.086253, loss_ce: 0.015601 loss_dice: 0.133355\n",
            "iteration 9985 : loss : 0.117605, loss_ce: 0.034513 loss_dice: 0.172999\n",
            "iteration 9986 : loss : 0.198785, loss_ce: 0.023261 loss_dice: 0.315801\n",
            "iteration 9987 : loss : 0.110486, loss_ce: 0.039997 loss_dice: 0.157479\n",
            "iteration 9988 : loss : 0.149407, loss_ce: 0.027352 loss_dice: 0.230777\n",
            "iteration 9989 : loss : 0.130828, loss_ce: 0.013790 loss_dice: 0.208853\n",
            "iteration 9990 : loss : 0.283340, loss_ce: 0.093696 loss_dice: 0.409769\n",
            "  9%|██▎                       | 45/500 [1:49:35<19:07:56, 151.38s/it]iteration 9991 : loss : 0.190554, loss_ce: 0.029598 loss_dice: 0.297858\n",
            "iteration 9992 : loss : 0.144306, loss_ce: 0.044097 loss_dice: 0.211112\n",
            "iteration 9993 : loss : 0.196013, loss_ce: 0.035086 loss_dice: 0.303298\n",
            "iteration 9994 : loss : 0.105095, loss_ce: 0.051757 loss_dice: 0.140654\n",
            "iteration 9995 : loss : 0.192976, loss_ce: 0.024390 loss_dice: 0.305367\n",
            "iteration 9996 : loss : 0.094730, loss_ce: 0.026941 loss_dice: 0.139922\n",
            "iteration 9997 : loss : 0.236991, loss_ce: 0.023777 loss_dice: 0.379134\n",
            "iteration 9998 : loss : 0.163463, loss_ce: 0.046026 loss_dice: 0.241754\n",
            "iteration 9999 : loss : 0.195350, loss_ce: 0.038543 loss_dice: 0.299887\n",
            "iteration 10000 : loss : 0.093072, loss_ce: 0.025169 loss_dice: 0.138340\n",
            "iteration 10001 : loss : 0.192894, loss_ce: 0.026838 loss_dice: 0.303598\n",
            "iteration 10002 : loss : 0.159805, loss_ce: 0.030339 loss_dice: 0.246116\n",
            "iteration 10003 : loss : 0.097968, loss_ce: 0.035954 loss_dice: 0.139310\n",
            "iteration 10004 : loss : 0.150167, loss_ce: 0.036428 loss_dice: 0.225992\n",
            "iteration 10005 : loss : 0.082601, loss_ce: 0.024104 loss_dice: 0.121599\n",
            "iteration 10006 : loss : 0.100611, loss_ce: 0.026884 loss_dice: 0.149762\n",
            "iteration 10007 : loss : 0.089511, loss_ce: 0.032906 loss_dice: 0.127247\n",
            "iteration 10008 : loss : 0.061661, loss_ce: 0.022009 loss_dice: 0.088096\n",
            "iteration 10009 : loss : 0.077805, loss_ce: 0.023415 loss_dice: 0.114064\n",
            "iteration 10010 : loss : 0.123672, loss_ce: 0.059612 loss_dice: 0.166378\n",
            "iteration 10011 : loss : 0.113042, loss_ce: 0.031936 loss_dice: 0.167112\n",
            "iteration 10012 : loss : 0.157455, loss_ce: 0.026534 loss_dice: 0.244736\n",
            "iteration 10013 : loss : 0.118686, loss_ce: 0.022299 loss_dice: 0.182944\n",
            "iteration 10014 : loss : 0.060092, loss_ce: 0.019713 loss_dice: 0.087012\n",
            "iteration 10015 : loss : 0.104086, loss_ce: 0.026578 loss_dice: 0.155758\n",
            "iteration 10016 : loss : 0.126930, loss_ce: 0.008862 loss_dice: 0.205641\n",
            "iteration 10017 : loss : 0.121974, loss_ce: 0.045666 loss_dice: 0.172846\n",
            "iteration 10018 : loss : 0.182071, loss_ce: 0.040874 loss_dice: 0.276202\n",
            "iteration 10019 : loss : 0.135096, loss_ce: 0.025060 loss_dice: 0.208453\n",
            "iteration 10020 : loss : 0.175406, loss_ce: 0.018210 loss_dice: 0.280203\n",
            "iteration 10021 : loss : 0.170292, loss_ce: 0.033414 loss_dice: 0.261543\n",
            "iteration 10022 : loss : 0.130535, loss_ce: 0.027084 loss_dice: 0.199502\n",
            "iteration 10023 : loss : 0.118567, loss_ce: 0.019976 loss_dice: 0.184293\n",
            "iteration 10024 : loss : 0.249384, loss_ce: 0.018317 loss_dice: 0.403429\n",
            "iteration 10025 : loss : 0.203071, loss_ce: 0.011523 loss_dice: 0.330770\n",
            "iteration 10026 : loss : 0.165310, loss_ce: 0.005781 loss_dice: 0.271662\n",
            "iteration 10027 : loss : 0.231993, loss_ce: 0.016247 loss_dice: 0.375824\n",
            "iteration 10028 : loss : 0.136550, loss_ce: 0.018970 loss_dice: 0.214937\n",
            "iteration 10029 : loss : 0.114118, loss_ce: 0.017783 loss_dice: 0.178342\n",
            "iteration 10030 : loss : 0.085220, loss_ce: 0.035481 loss_dice: 0.118380\n",
            "iteration 10031 : loss : 0.159331, loss_ce: 0.039297 loss_dice: 0.239354\n",
            "iteration 10032 : loss : 0.129886, loss_ce: 0.019414 loss_dice: 0.203534\n",
            "iteration 10033 : loss : 0.143336, loss_ce: 0.026982 loss_dice: 0.220906\n",
            "iteration 10034 : loss : 0.161546, loss_ce: 0.013637 loss_dice: 0.260152\n",
            "iteration 10035 : loss : 0.131973, loss_ce: 0.035200 loss_dice: 0.196488\n",
            "iteration 10036 : loss : 0.088536, loss_ce: 0.037136 loss_dice: 0.122803\n",
            "iteration 10037 : loss : 0.137180, loss_ce: 0.019571 loss_dice: 0.215587\n",
            "iteration 10038 : loss : 0.136899, loss_ce: 0.022515 loss_dice: 0.213156\n",
            "iteration 10039 : loss : 0.114346, loss_ce: 0.025602 loss_dice: 0.173508\n",
            "iteration 10040 : loss : 0.167928, loss_ce: 0.039033 loss_dice: 0.253859\n",
            "iteration 10041 : loss : 0.066771, loss_ce: 0.032310 loss_dice: 0.089745\n",
            "iteration 10042 : loss : 0.080670, loss_ce: 0.018403 loss_dice: 0.122181\n",
            "iteration 10043 : loss : 0.068749, loss_ce: 0.031537 loss_dice: 0.093557\n",
            "iteration 10044 : loss : 0.050455, loss_ce: 0.023067 loss_dice: 0.068714\n",
            "iteration 10045 : loss : 0.123684, loss_ce: 0.014489 loss_dice: 0.196481\n",
            "iteration 10046 : loss : 0.172053, loss_ce: 0.015961 loss_dice: 0.276114\n",
            "iteration 10047 : loss : 0.128344, loss_ce: 0.029682 loss_dice: 0.194118\n",
            "iteration 10048 : loss : 0.114357, loss_ce: 0.038573 loss_dice: 0.164880\n",
            "iteration 10049 : loss : 0.091411, loss_ce: 0.034426 loss_dice: 0.129402\n",
            "iteration 10050 : loss : 0.150699, loss_ce: 0.036970 loss_dice: 0.226517\n",
            "iteration 10051 : loss : 0.124362, loss_ce: 0.028376 loss_dice: 0.188353\n",
            "iteration 10052 : loss : 0.084652, loss_ce: 0.026375 loss_dice: 0.123503\n",
            "iteration 10053 : loss : 0.113537, loss_ce: 0.041221 loss_dice: 0.161748\n",
            "iteration 10054 : loss : 0.142546, loss_ce: 0.019765 loss_dice: 0.224400\n",
            "iteration 10055 : loss : 0.085254, loss_ce: 0.024317 loss_dice: 0.125879\n",
            "iteration 10056 : loss : 0.072102, loss_ce: 0.033654 loss_dice: 0.097734\n",
            "iteration 10057 : loss : 0.254209, loss_ce: 0.028879 loss_dice: 0.404429\n",
            "iteration 10058 : loss : 0.142409, loss_ce: 0.037037 loss_dice: 0.212656\n",
            "iteration 10059 : loss : 0.203131, loss_ce: 0.016118 loss_dice: 0.327807\n",
            "iteration 10060 : loss : 0.093143, loss_ce: 0.023915 loss_dice: 0.139296\n",
            "iteration 10061 : loss : 0.109772, loss_ce: 0.037654 loss_dice: 0.157851\n",
            "iteration 10062 : loss : 0.090925, loss_ce: 0.036304 loss_dice: 0.127340\n",
            "iteration 10063 : loss : 0.124318, loss_ce: 0.011159 loss_dice: 0.199757\n",
            "iteration 10064 : loss : 0.149947, loss_ce: 0.029197 loss_dice: 0.230446\n",
            "iteration 10065 : loss : 0.085862, loss_ce: 0.021693 loss_dice: 0.128641\n",
            "iteration 10066 : loss : 0.128886, loss_ce: 0.028656 loss_dice: 0.195706\n",
            "iteration 10067 : loss : 0.134333, loss_ce: 0.028980 loss_dice: 0.204568\n",
            "iteration 10068 : loss : 0.131228, loss_ce: 0.023142 loss_dice: 0.203285\n",
            "iteration 10069 : loss : 0.126759, loss_ce: 0.008114 loss_dice: 0.205855\n",
            "iteration 10070 : loss : 0.213166, loss_ce: 0.031303 loss_dice: 0.334409\n",
            "iteration 10071 : loss : 0.127421, loss_ce: 0.031437 loss_dice: 0.191410\n",
            "iteration 10072 : loss : 0.147158, loss_ce: 0.030300 loss_dice: 0.225063\n",
            "iteration 10073 : loss : 0.155786, loss_ce: 0.024801 loss_dice: 0.243110\n",
            "iteration 10074 : loss : 0.091825, loss_ce: 0.022082 loss_dice: 0.138320\n",
            "iteration 10075 : loss : 0.068382, loss_ce: 0.011120 loss_dice: 0.106556\n",
            "iteration 10076 : loss : 0.108345, loss_ce: 0.008299 loss_dice: 0.175042\n",
            "iteration 10077 : loss : 0.080711, loss_ce: 0.023783 loss_dice: 0.118664\n",
            "iteration 10078 : loss : 0.144320, loss_ce: 0.033136 loss_dice: 0.218443\n",
            "iteration 10079 : loss : 0.255843, loss_ce: 0.025776 loss_dice: 0.409220\n",
            "iteration 10080 : loss : 0.133301, loss_ce: 0.017376 loss_dice: 0.210583\n",
            "iteration 10081 : loss : 0.119305, loss_ce: 0.018580 loss_dice: 0.186455\n",
            "iteration 10082 : loss : 0.069821, loss_ce: 0.023511 loss_dice: 0.100695\n",
            "iteration 10083 : loss : 0.096850, loss_ce: 0.027337 loss_dice: 0.143193\n",
            "iteration 10084 : loss : 0.143028, loss_ce: 0.045768 loss_dice: 0.207867\n",
            "iteration 10085 : loss : 0.106514, loss_ce: 0.030034 loss_dice: 0.157501\n",
            "iteration 10086 : loss : 0.068250, loss_ce: 0.025223 loss_dice: 0.096935\n",
            "iteration 10087 : loss : 0.128834, loss_ce: 0.054290 loss_dice: 0.178531\n",
            "iteration 10088 : loss : 0.193376, loss_ce: 0.014532 loss_dice: 0.312606\n",
            "iteration 10089 : loss : 0.130895, loss_ce: 0.021522 loss_dice: 0.203810\n",
            "iteration 10090 : loss : 0.134137, loss_ce: 0.029537 loss_dice: 0.203870\n",
            "iteration 10091 : loss : 0.129788, loss_ce: 0.039943 loss_dice: 0.189685\n",
            "iteration 10092 : loss : 0.132659, loss_ce: 0.024638 loss_dice: 0.204673\n",
            "iteration 10093 : loss : 0.169807, loss_ce: 0.037453 loss_dice: 0.258043\n",
            "iteration 10094 : loss : 0.093354, loss_ce: 0.032387 loss_dice: 0.133998\n",
            "iteration 10095 : loss : 0.045601, loss_ce: 0.005766 loss_dice: 0.072158\n",
            "iteration 10096 : loss : 0.134009, loss_ce: 0.028092 loss_dice: 0.204619\n",
            "iteration 10097 : loss : 0.102910, loss_ce: 0.033555 loss_dice: 0.149146\n",
            "iteration 10098 : loss : 0.082464, loss_ce: 0.015060 loss_dice: 0.127401\n",
            "iteration 10099 : loss : 0.141240, loss_ce: 0.023239 loss_dice: 0.219907\n",
            "iteration 10100 : loss : 0.111009, loss_ce: 0.015090 loss_dice: 0.174956\n",
            "iteration 10101 : loss : 0.216188, loss_ce: 0.027785 loss_dice: 0.341790\n",
            "iteration 10102 : loss : 0.130079, loss_ce: 0.028808 loss_dice: 0.197592\n",
            "iteration 10103 : loss : 0.065663, loss_ce: 0.035214 loss_dice: 0.085963\n",
            "iteration 10104 : loss : 0.170020, loss_ce: 0.071085 loss_dice: 0.235976\n",
            "iteration 10105 : loss : 0.161406, loss_ce: 0.033887 loss_dice: 0.246419\n",
            "iteration 10106 : loss : 0.252469, loss_ce: 0.022244 loss_dice: 0.405952\n",
            "iteration 10107 : loss : 0.165263, loss_ce: 0.042365 loss_dice: 0.247194\n",
            "iteration 10108 : loss : 0.220002, loss_ce: 0.029785 loss_dice: 0.346813\n",
            "iteration 10109 : loss : 0.174928, loss_ce: 0.070555 loss_dice: 0.244510\n",
            "iteration 10110 : loss : 0.121286, loss_ce: 0.059416 loss_dice: 0.162533\n",
            "iteration 10111 : loss : 0.326343, loss_ce: 0.040563 loss_dice: 0.516862\n",
            "iteration 10112 : loss : 0.167340, loss_ce: 0.019617 loss_dice: 0.265822\n",
            "iteration 10113 : loss : 0.097619, loss_ce: 0.028849 loss_dice: 0.143466\n",
            "iteration 10114 : loss : 0.186226, loss_ce: 0.048141 loss_dice: 0.278282\n",
            "iteration 10115 : loss : 0.111222, loss_ce: 0.018035 loss_dice: 0.173347\n",
            "iteration 10116 : loss : 0.151498, loss_ce: 0.031023 loss_dice: 0.231814\n",
            "iteration 10117 : loss : 0.117517, loss_ce: 0.048157 loss_dice: 0.163757\n",
            "iteration 10118 : loss : 0.119330, loss_ce: 0.021458 loss_dice: 0.184578\n",
            "iteration 10119 : loss : 0.129783, loss_ce: 0.061270 loss_dice: 0.175458\n",
            "iteration 10120 : loss : 0.076272, loss_ce: 0.024410 loss_dice: 0.110847\n",
            "iteration 10121 : loss : 0.090541, loss_ce: 0.019928 loss_dice: 0.137616\n",
            "iteration 10122 : loss : 0.109672, loss_ce: 0.044637 loss_dice: 0.153029\n",
            "iteration 10123 : loss : 0.116419, loss_ce: 0.040464 loss_dice: 0.167056\n",
            "iteration 10124 : loss : 0.202945, loss_ce: 0.015054 loss_dice: 0.328205\n",
            "iteration 10125 : loss : 0.143622, loss_ce: 0.048153 loss_dice: 0.207267\n",
            "iteration 10126 : loss : 0.147678, loss_ce: 0.015082 loss_dice: 0.236075\n",
            "iteration 10127 : loss : 0.104906, loss_ce: 0.028952 loss_dice: 0.155542\n",
            "iteration 10128 : loss : 0.168896, loss_ce: 0.023042 loss_dice: 0.266131\n",
            "iteration 10129 : loss : 0.076072, loss_ce: 0.018427 loss_dice: 0.114501\n",
            "iteration 10130 : loss : 0.071549, loss_ce: 0.014012 loss_dice: 0.109908\n",
            "iteration 10131 : loss : 0.118480, loss_ce: 0.013265 loss_dice: 0.188623\n",
            "iteration 10132 : loss : 0.117463, loss_ce: 0.025929 loss_dice: 0.178486\n",
            "iteration 10133 : loss : 0.111320, loss_ce: 0.023326 loss_dice: 0.169983\n",
            "iteration 10134 : loss : 0.132537, loss_ce: 0.015957 loss_dice: 0.210256\n",
            "iteration 10135 : loss : 0.144206, loss_ce: 0.033281 loss_dice: 0.218155\n",
            "iteration 10136 : loss : 0.161386, loss_ce: 0.025057 loss_dice: 0.252272\n",
            "iteration 10137 : loss : 0.125346, loss_ce: 0.010869 loss_dice: 0.201664\n",
            "iteration 10138 : loss : 0.130900, loss_ce: 0.034922 loss_dice: 0.194885\n",
            "iteration 10139 : loss : 0.150116, loss_ce: 0.023217 loss_dice: 0.234715\n",
            "iteration 10140 : loss : 0.181844, loss_ce: 0.042016 loss_dice: 0.275062\n",
            "iteration 10141 : loss : 0.167953, loss_ce: 0.050409 loss_dice: 0.246316\n",
            "iteration 10142 : loss : 0.107203, loss_ce: 0.015473 loss_dice: 0.168357\n",
            "iteration 10143 : loss : 0.118330, loss_ce: 0.035455 loss_dice: 0.173581\n",
            "iteration 10144 : loss : 0.107385, loss_ce: 0.043512 loss_dice: 0.149968\n",
            "iteration 10145 : loss : 0.190252, loss_ce: 0.015489 loss_dice: 0.306761\n",
            "iteration 10146 : loss : 0.123801, loss_ce: 0.014217 loss_dice: 0.196856\n",
            "iteration 10147 : loss : 0.196789, loss_ce: 0.013580 loss_dice: 0.318928\n",
            "iteration 10148 : loss : 0.151887, loss_ce: 0.023726 loss_dice: 0.237327\n",
            "iteration 10149 : loss : 0.148318, loss_ce: 0.053414 loss_dice: 0.211588\n",
            "iteration 10150 : loss : 0.130653, loss_ce: 0.034829 loss_dice: 0.194535\n",
            "iteration 10151 : loss : 0.137024, loss_ce: 0.030401 loss_dice: 0.208107\n",
            "iteration 10152 : loss : 0.151820, loss_ce: 0.031242 loss_dice: 0.232205\n",
            "iteration 10153 : loss : 0.120862, loss_ce: 0.023453 loss_dice: 0.185801\n",
            "iteration 10154 : loss : 0.120375, loss_ce: 0.036216 loss_dice: 0.176480\n",
            "iteration 10155 : loss : 0.141806, loss_ce: 0.032411 loss_dice: 0.214737\n",
            "iteration 10156 : loss : 0.105364, loss_ce: 0.025612 loss_dice: 0.158531\n",
            "iteration 10157 : loss : 0.090617, loss_ce: 0.033264 loss_dice: 0.128853\n",
            "iteration 10158 : loss : 0.193314, loss_ce: 0.027116 loss_dice: 0.304112\n",
            "iteration 10159 : loss : 0.087940, loss_ce: 0.022439 loss_dice: 0.131608\n",
            "iteration 10160 : loss : 0.248394, loss_ce: 0.023455 loss_dice: 0.398353\n",
            "iteration 10161 : loss : 0.234757, loss_ce: 0.004460 loss_dice: 0.388289\n",
            "iteration 10162 : loss : 0.219219, loss_ce: 0.048919 loss_dice: 0.332751\n",
            "iteration 10163 : loss : 0.166689, loss_ce: 0.039988 loss_dice: 0.251156\n",
            "iteration 10164 : loss : 0.196689, loss_ce: 0.071265 loss_dice: 0.280305\n",
            "iteration 10165 : loss : 0.135087, loss_ce: 0.032942 loss_dice: 0.203183\n",
            "iteration 10166 : loss : 0.143492, loss_ce: 0.027008 loss_dice: 0.221147\n",
            "iteration 10167 : loss : 0.225021, loss_ce: 0.056397 loss_dice: 0.337437\n",
            "iteration 10168 : loss : 0.122149, loss_ce: 0.025071 loss_dice: 0.186868\n",
            "iteration 10169 : loss : 0.097611, loss_ce: 0.021261 loss_dice: 0.148510\n",
            "iteration 10170 : loss : 0.176372, loss_ce: 0.051394 loss_dice: 0.259691\n",
            "iteration 10171 : loss : 0.128874, loss_ce: 0.037079 loss_dice: 0.190070\n",
            "iteration 10172 : loss : 0.073685, loss_ce: 0.036360 loss_dice: 0.098569\n",
            "iteration 10173 : loss : 0.155481, loss_ce: 0.028608 loss_dice: 0.240063\n",
            "iteration 10174 : loss : 0.147487, loss_ce: 0.049751 loss_dice: 0.212644\n",
            "iteration 10175 : loss : 0.227311, loss_ce: 0.012592 loss_dice: 0.370457\n",
            "iteration 10176 : loss : 0.163720, loss_ce: 0.064501 loss_dice: 0.229866\n",
            "iteration 10177 : loss : 0.207590, loss_ce: 0.028602 loss_dice: 0.326916\n",
            "iteration 10178 : loss : 0.169901, loss_ce: 0.030351 loss_dice: 0.262934\n",
            "iteration 10179 : loss : 0.078337, loss_ce: 0.009346 loss_dice: 0.124331\n",
            "iteration 10180 : loss : 0.145496, loss_ce: 0.039465 loss_dice: 0.216184\n",
            "iteration 10181 : loss : 0.148563, loss_ce: 0.043129 loss_dice: 0.218852\n",
            "iteration 10182 : loss : 0.086222, loss_ce: 0.033663 loss_dice: 0.121262\n",
            "iteration 10183 : loss : 0.079829, loss_ce: 0.029586 loss_dice: 0.113325\n",
            "iteration 10184 : loss : 0.147680, loss_ce: 0.034618 loss_dice: 0.223055\n",
            "iteration 10185 : loss : 0.113766, loss_ce: 0.032545 loss_dice: 0.167913\n",
            "iteration 10186 : loss : 0.184977, loss_ce: 0.027892 loss_dice: 0.289700\n",
            "iteration 10187 : loss : 0.161009, loss_ce: 0.040700 loss_dice: 0.241215\n",
            "iteration 10188 : loss : 0.147181, loss_ce: 0.022000 loss_dice: 0.230635\n",
            "iteration 10189 : loss : 0.118993, loss_ce: 0.042956 loss_dice: 0.169684\n",
            "iteration 10190 : loss : 0.090391, loss_ce: 0.019118 loss_dice: 0.137907\n",
            "iteration 10191 : loss : 0.088285, loss_ce: 0.014242 loss_dice: 0.137646\n",
            "iteration 10192 : loss : 0.158779, loss_ce: 0.019733 loss_dice: 0.251477\n",
            "iteration 10193 : loss : 0.129780, loss_ce: 0.040361 loss_dice: 0.189392\n",
            "iteration 10194 : loss : 0.148581, loss_ce: 0.025318 loss_dice: 0.230755\n",
            "iteration 10195 : loss : 0.085123, loss_ce: 0.009478 loss_dice: 0.135553\n",
            "iteration 10196 : loss : 0.059598, loss_ce: 0.014383 loss_dice: 0.089741\n",
            "iteration 10197 : loss : 0.086892, loss_ce: 0.036017 loss_dice: 0.120809\n",
            "iteration 10198 : loss : 0.138968, loss_ce: 0.019306 loss_dice: 0.218743\n",
            "iteration 10199 : loss : 0.168825, loss_ce: 0.013498 loss_dice: 0.272376\n",
            "iteration 10200 : loss : 0.103245, loss_ce: 0.053337 loss_dice: 0.136516\n",
            "iteration 10201 : loss : 0.072309, loss_ce: 0.012969 loss_dice: 0.111868\n",
            "iteration 10202 : loss : 0.133394, loss_ce: 0.030231 loss_dice: 0.202169\n",
            "iteration 10203 : loss : 0.108688, loss_ce: 0.011412 loss_dice: 0.173539\n",
            "iteration 10204 : loss : 0.177781, loss_ce: 0.011393 loss_dice: 0.288706\n",
            "iteration 10205 : loss : 0.092969, loss_ce: 0.050186 loss_dice: 0.121491\n",
            "iteration 10206 : loss : 0.112157, loss_ce: 0.032619 loss_dice: 0.165182\n",
            "iteration 10207 : loss : 0.141681, loss_ce: 0.020625 loss_dice: 0.222385\n",
            "iteration 10208 : loss : 0.125691, loss_ce: 0.075223 loss_dice: 0.159337\n",
            "iteration 10209 : loss : 0.181637, loss_ce: 0.036831 loss_dice: 0.278174\n",
            "iteration 10210 : loss : 0.159525, loss_ce: 0.042997 loss_dice: 0.237211\n",
            "iteration 10211 : loss : 0.236377, loss_ce: 0.057305 loss_dice: 0.355758\n",
            "iteration 10212 : loss : 0.122057, loss_ce: 0.000027 loss_dice: 0.203411\n",
            "  9%|██▍                       | 46/500 [1:50:59<16:32:35, 131.18s/it]iteration 10213 : loss : 0.107292, loss_ce: 0.035320 loss_dice: 0.155273\n",
            "iteration 10214 : loss : 0.162645, loss_ce: 0.037811 loss_dice: 0.245867\n",
            "iteration 10215 : loss : 0.117193, loss_ce: 0.011554 loss_dice: 0.187618\n",
            "iteration 10216 : loss : 0.135179, loss_ce: 0.021801 loss_dice: 0.210764\n",
            "iteration 10217 : loss : 0.141529, loss_ce: 0.030389 loss_dice: 0.215623\n",
            "iteration 10218 : loss : 0.039951, loss_ce: 0.015293 loss_dice: 0.056389\n",
            "iteration 10219 : loss : 0.151678, loss_ce: 0.026043 loss_dice: 0.235434\n",
            "iteration 10220 : loss : 0.170930, loss_ce: 0.032210 loss_dice: 0.263410\n",
            "iteration 10221 : loss : 0.175219, loss_ce: 0.030228 loss_dice: 0.271880\n",
            "iteration 10222 : loss : 0.148615, loss_ce: 0.026546 loss_dice: 0.229995\n",
            "iteration 10223 : loss : 0.182205, loss_ce: 0.029166 loss_dice: 0.284230\n",
            "iteration 10224 : loss : 0.214160, loss_ce: 0.043036 loss_dice: 0.328243\n",
            "iteration 10225 : loss : 0.175406, loss_ce: 0.061075 loss_dice: 0.251627\n",
            "iteration 10226 : loss : 0.291102, loss_ce: 0.024809 loss_dice: 0.468631\n",
            "iteration 10227 : loss : 0.155168, loss_ce: 0.051186 loss_dice: 0.224490\n",
            "iteration 10228 : loss : 0.156298, loss_ce: 0.048586 loss_dice: 0.228106\n",
            "iteration 10229 : loss : 0.176155, loss_ce: 0.063488 loss_dice: 0.251266\n",
            "iteration 10230 : loss : 0.149909, loss_ce: 0.043573 loss_dice: 0.220800\n",
            "iteration 10231 : loss : 0.118645, loss_ce: 0.035688 loss_dice: 0.173949\n",
            "iteration 10232 : loss : 0.179665, loss_ce: 0.039740 loss_dice: 0.272949\n",
            "iteration 10233 : loss : 0.137723, loss_ce: 0.024874 loss_dice: 0.212956\n",
            "iteration 10234 : loss : 0.142929, loss_ce: 0.033864 loss_dice: 0.215640\n",
            "iteration 10235 : loss : 0.120163, loss_ce: 0.026604 loss_dice: 0.182536\n",
            "iteration 10236 : loss : 0.158091, loss_ce: 0.044311 loss_dice: 0.233944\n",
            "iteration 10237 : loss : 0.162464, loss_ce: 0.044531 loss_dice: 0.241085\n",
            "iteration 10238 : loss : 0.171124, loss_ce: 0.035567 loss_dice: 0.261496\n",
            "iteration 10239 : loss : 0.122865, loss_ce: 0.045773 loss_dice: 0.174259\n",
            "iteration 10240 : loss : 0.064299, loss_ce: 0.016715 loss_dice: 0.096022\n",
            "iteration 10241 : loss : 0.215467, loss_ce: 0.022003 loss_dice: 0.344444\n",
            "iteration 10242 : loss : 0.136146, loss_ce: 0.012356 loss_dice: 0.218674\n",
            "iteration 10243 : loss : 0.080993, loss_ce: 0.032003 loss_dice: 0.113653\n",
            "iteration 10244 : loss : 0.163959, loss_ce: 0.093453 loss_dice: 0.210963\n",
            "iteration 10245 : loss : 0.161194, loss_ce: 0.042629 loss_dice: 0.240237\n",
            "iteration 10246 : loss : 0.151420, loss_ce: 0.042031 loss_dice: 0.224346\n",
            "iteration 10247 : loss : 0.160203, loss_ce: 0.041822 loss_dice: 0.239123\n",
            "iteration 10248 : loss : 0.119802, loss_ce: 0.019223 loss_dice: 0.186856\n",
            "iteration 10249 : loss : 0.065921, loss_ce: 0.017606 loss_dice: 0.098132\n",
            "iteration 10250 : loss : 0.184017, loss_ce: 0.032832 loss_dice: 0.284806\n",
            "iteration 10251 : loss : 0.092521, loss_ce: 0.030097 loss_dice: 0.134137\n",
            "iteration 10252 : loss : 0.110944, loss_ce: 0.012562 loss_dice: 0.176532\n",
            "iteration 10253 : loss : 0.131437, loss_ce: 0.068847 loss_dice: 0.173164\n",
            "iteration 10254 : loss : 0.151251, loss_ce: 0.049624 loss_dice: 0.219002\n",
            "iteration 10255 : loss : 0.092483, loss_ce: 0.033817 loss_dice: 0.131593\n",
            "iteration 10256 : loss : 0.144938, loss_ce: 0.029721 loss_dice: 0.221750\n",
            "iteration 10257 : loss : 0.116555, loss_ce: 0.026583 loss_dice: 0.176536\n",
            "iteration 10258 : loss : 0.176051, loss_ce: 0.036651 loss_dice: 0.268984\n",
            "iteration 10259 : loss : 0.099425, loss_ce: 0.030647 loss_dice: 0.145277\n",
            "iteration 10260 : loss : 0.125001, loss_ce: 0.029142 loss_dice: 0.188906\n",
            "iteration 10261 : loss : 0.135902, loss_ce: 0.044931 loss_dice: 0.196549\n",
            "iteration 10262 : loss : 0.163091, loss_ce: 0.021551 loss_dice: 0.257451\n",
            "iteration 10263 : loss : 0.195487, loss_ce: 0.039428 loss_dice: 0.299526\n",
            "iteration 10264 : loss : 0.148159, loss_ce: 0.031068 loss_dice: 0.226219\n",
            "iteration 10265 : loss : 0.272851, loss_ce: 0.015245 loss_dice: 0.444588\n",
            "iteration 10266 : loss : 0.144596, loss_ce: 0.029088 loss_dice: 0.221600\n",
            "iteration 10267 : loss : 0.111331, loss_ce: 0.028898 loss_dice: 0.166287\n",
            "iteration 10268 : loss : 0.115771, loss_ce: 0.039053 loss_dice: 0.166916\n",
            "iteration 10269 : loss : 0.155328, loss_ce: 0.045125 loss_dice: 0.228797\n",
            "iteration 10270 : loss : 0.168196, loss_ce: 0.067829 loss_dice: 0.235107\n",
            "iteration 10271 : loss : 0.137599, loss_ce: 0.038505 loss_dice: 0.203661\n",
            "iteration 10272 : loss : 0.181765, loss_ce: 0.050147 loss_dice: 0.269510\n",
            "iteration 10273 : loss : 0.061337, loss_ce: 0.013559 loss_dice: 0.093189\n",
            "iteration 10274 : loss : 0.193483, loss_ce: 0.013235 loss_dice: 0.313648\n",
            "iteration 10275 : loss : 0.186072, loss_ce: 0.017465 loss_dice: 0.298478\n",
            "iteration 10276 : loss : 0.152416, loss_ce: 0.045284 loss_dice: 0.223838\n",
            "iteration 10277 : loss : 0.164788, loss_ce: 0.007337 loss_dice: 0.269755\n",
            "iteration 10278 : loss : 0.075471, loss_ce: 0.023140 loss_dice: 0.110358\n",
            "iteration 10279 : loss : 0.115422, loss_ce: 0.041456 loss_dice: 0.164732\n",
            "iteration 10280 : loss : 0.158184, loss_ce: 0.019401 loss_dice: 0.250707\n",
            "iteration 10281 : loss : 0.211528, loss_ce: 0.014699 loss_dice: 0.342747\n",
            "iteration 10282 : loss : 0.077542, loss_ce: 0.026686 loss_dice: 0.111447\n",
            "iteration 10283 : loss : 0.278775, loss_ce: 0.093195 loss_dice: 0.402494\n",
            "iteration 10284 : loss : 0.099261, loss_ce: 0.010316 loss_dice: 0.158557\n",
            "iteration 10285 : loss : 0.248323, loss_ce: 0.112820 loss_dice: 0.338658\n",
            "iteration 10286 : loss : 0.268136, loss_ce: 0.019290 loss_dice: 0.434033\n",
            "iteration 10287 : loss : 0.137080, loss_ce: 0.046617 loss_dice: 0.197390\n",
            "iteration 10288 : loss : 0.075896, loss_ce: 0.026406 loss_dice: 0.108889\n",
            "iteration 10289 : loss : 0.158007, loss_ce: 0.067131 loss_dice: 0.218590\n",
            "iteration 10290 : loss : 0.119275, loss_ce: 0.023593 loss_dice: 0.183063\n",
            "iteration 10291 : loss : 0.104218, loss_ce: 0.027004 loss_dice: 0.155694\n",
            "iteration 10292 : loss : 0.199829, loss_ce: 0.102620 loss_dice: 0.264635\n",
            "iteration 10293 : loss : 0.190728, loss_ce: 0.065755 loss_dice: 0.274043\n",
            "iteration 10294 : loss : 0.121625, loss_ce: 0.033578 loss_dice: 0.180324\n",
            "iteration 10295 : loss : 0.110490, loss_ce: 0.037265 loss_dice: 0.159306\n",
            "iteration 10296 : loss : 0.193434, loss_ce: 0.022332 loss_dice: 0.307501\n",
            "iteration 10297 : loss : 0.158674, loss_ce: 0.068724 loss_dice: 0.218641\n",
            "iteration 10298 : loss : 0.157179, loss_ce: 0.039541 loss_dice: 0.235605\n",
            "iteration 10299 : loss : 0.149693, loss_ce: 0.039415 loss_dice: 0.223212\n",
            "iteration 10300 : loss : 0.178348, loss_ce: 0.048247 loss_dice: 0.265083\n",
            "iteration 10301 : loss : 0.160448, loss_ce: 0.018010 loss_dice: 0.255407\n",
            "iteration 10302 : loss : 0.141286, loss_ce: 0.030187 loss_dice: 0.215351\n",
            "iteration 10303 : loss : 0.110015, loss_ce: 0.048723 loss_dice: 0.150876\n",
            "iteration 10304 : loss : 0.091848, loss_ce: 0.039005 loss_dice: 0.127076\n",
            "iteration 10305 : loss : 0.181000, loss_ce: 0.060228 loss_dice: 0.261514\n",
            "iteration 10306 : loss : 0.137693, loss_ce: 0.030208 loss_dice: 0.209349\n",
            "iteration 10307 : loss : 0.181715, loss_ce: 0.056751 loss_dice: 0.265024\n",
            "iteration 10308 : loss : 0.191872, loss_ce: 0.018741 loss_dice: 0.307293\n",
            "iteration 10309 : loss : 0.157315, loss_ce: 0.021240 loss_dice: 0.248031\n",
            "iteration 10310 : loss : 0.153369, loss_ce: 0.049953 loss_dice: 0.222313\n",
            "iteration 10311 : loss : 0.227429, loss_ce: 0.017897 loss_dice: 0.367117\n",
            "iteration 10312 : loss : 0.125030, loss_ce: 0.031491 loss_dice: 0.187389\n",
            "iteration 10313 : loss : 0.145399, loss_ce: 0.033885 loss_dice: 0.219742\n",
            "iteration 10314 : loss : 0.095485, loss_ce: 0.029907 loss_dice: 0.139204\n",
            "iteration 10315 : loss : 0.096769, loss_ce: 0.018921 loss_dice: 0.148668\n",
            "iteration 10316 : loss : 0.110114, loss_ce: 0.043485 loss_dice: 0.154533\n",
            "iteration 10317 : loss : 0.107924, loss_ce: 0.022170 loss_dice: 0.165094\n",
            "iteration 10318 : loss : 0.168575, loss_ce: 0.057769 loss_dice: 0.242446\n",
            "iteration 10319 : loss : 0.080277, loss_ce: 0.018458 loss_dice: 0.121489\n",
            "iteration 10320 : loss : 0.213421, loss_ce: 0.015312 loss_dice: 0.345494\n",
            "iteration 10321 : loss : 0.188721, loss_ce: 0.031588 loss_dice: 0.293476\n",
            "iteration 10322 : loss : 0.129223, loss_ce: 0.016720 loss_dice: 0.204225\n",
            "iteration 10323 : loss : 0.158089, loss_ce: 0.050124 loss_dice: 0.230066\n",
            "iteration 10324 : loss : 0.239362, loss_ce: 0.033704 loss_dice: 0.376467\n",
            "iteration 10325 : loss : 0.176441, loss_ce: 0.025278 loss_dice: 0.277217\n",
            "iteration 10326 : loss : 0.235443, loss_ce: 0.010322 loss_dice: 0.385523\n",
            "iteration 10327 : loss : 0.138470, loss_ce: 0.032239 loss_dice: 0.209290\n",
            "iteration 10328 : loss : 0.135210, loss_ce: 0.042605 loss_dice: 0.196946\n",
            "iteration 10329 : loss : 0.129649, loss_ce: 0.019383 loss_dice: 0.203160\n",
            "iteration 10330 : loss : 0.152069, loss_ce: 0.041433 loss_dice: 0.225827\n",
            "iteration 10331 : loss : 0.124860, loss_ce: 0.032356 loss_dice: 0.186530\n",
            "iteration 10332 : loss : 0.184996, loss_ce: 0.009944 loss_dice: 0.301697\n",
            "iteration 10333 : loss : 0.194681, loss_ce: 0.030315 loss_dice: 0.304259\n",
            "iteration 10334 : loss : 0.066159, loss_ce: 0.035883 loss_dice: 0.086343\n",
            "iteration 10335 : loss : 0.147127, loss_ce: 0.058078 loss_dice: 0.206493\n",
            "iteration 10336 : loss : 0.176048, loss_ce: 0.024120 loss_dice: 0.277334\n",
            "iteration 10337 : loss : 0.146757, loss_ce: 0.033803 loss_dice: 0.222060\n",
            "iteration 10338 : loss : 0.154751, loss_ce: 0.043805 loss_dice: 0.228715\n",
            "iteration 10339 : loss : 0.174387, loss_ce: 0.051005 loss_dice: 0.256641\n",
            "iteration 10340 : loss : 0.152966, loss_ce: 0.042665 loss_dice: 0.226500\n",
            "iteration 10341 : loss : 0.081683, loss_ce: 0.021271 loss_dice: 0.121958\n",
            "iteration 10342 : loss : 0.093332, loss_ce: 0.026342 loss_dice: 0.137992\n",
            "iteration 10343 : loss : 0.130416, loss_ce: 0.030962 loss_dice: 0.196718\n",
            "iteration 10344 : loss : 0.116287, loss_ce: 0.024673 loss_dice: 0.177364\n",
            "iteration 10345 : loss : 0.140331, loss_ce: 0.035407 loss_dice: 0.210280\n",
            "iteration 10346 : loss : 0.148849, loss_ce: 0.045032 loss_dice: 0.218060\n",
            "iteration 10347 : loss : 0.142846, loss_ce: 0.027893 loss_dice: 0.219481\n",
            "iteration 10348 : loss : 0.086840, loss_ce: 0.021477 loss_dice: 0.130416\n",
            "iteration 10349 : loss : 0.133616, loss_ce: 0.021217 loss_dice: 0.208549\n",
            "iteration 10350 : loss : 0.126240, loss_ce: 0.069612 loss_dice: 0.163991\n",
            "iteration 10351 : loss : 0.201423, loss_ce: 0.014650 loss_dice: 0.325938\n",
            "iteration 10352 : loss : 0.088811, loss_ce: 0.020847 loss_dice: 0.134120\n",
            "iteration 10353 : loss : 0.134641, loss_ce: 0.055279 loss_dice: 0.187549\n",
            "iteration 10354 : loss : 0.094243, loss_ce: 0.022768 loss_dice: 0.141893\n",
            "iteration 10355 : loss : 0.143603, loss_ce: 0.031192 loss_dice: 0.218544\n",
            "iteration 10356 : loss : 0.136663, loss_ce: 0.025046 loss_dice: 0.211074\n",
            "iteration 10357 : loss : 0.118441, loss_ce: 0.025614 loss_dice: 0.180325\n",
            "iteration 10358 : loss : 0.171954, loss_ce: 0.061604 loss_dice: 0.245520\n",
            "iteration 10359 : loss : 0.084810, loss_ce: 0.025902 loss_dice: 0.124082\n",
            "iteration 10360 : loss : 0.092532, loss_ce: 0.019730 loss_dice: 0.141067\n",
            "iteration 10361 : loss : 0.082425, loss_ce: 0.026882 loss_dice: 0.119453\n",
            "iteration 10362 : loss : 0.094256, loss_ce: 0.037632 loss_dice: 0.132005\n",
            "iteration 10363 : loss : 0.099876, loss_ce: 0.035148 loss_dice: 0.143029\n",
            "iteration 10364 : loss : 0.094885, loss_ce: 0.028598 loss_dice: 0.139077\n",
            "iteration 10365 : loss : 0.093483, loss_ce: 0.018962 loss_dice: 0.143163\n",
            "iteration 10366 : loss : 0.134855, loss_ce: 0.027352 loss_dice: 0.206524\n",
            "iteration 10367 : loss : 0.298910, loss_ce: 0.010244 loss_dice: 0.491353\n",
            "iteration 10368 : loss : 0.139292, loss_ce: 0.035138 loss_dice: 0.208728\n",
            "iteration 10369 : loss : 0.170814, loss_ce: 0.040758 loss_dice: 0.257518\n",
            "iteration 10370 : loss : 0.152339, loss_ce: 0.035280 loss_dice: 0.230379\n",
            "iteration 10371 : loss : 0.187039, loss_ce: 0.010548 loss_dice: 0.304699\n",
            "iteration 10372 : loss : 0.143296, loss_ce: 0.012557 loss_dice: 0.230455\n",
            "iteration 10373 : loss : 0.156726, loss_ce: 0.046445 loss_dice: 0.230246\n",
            "iteration 10374 : loss : 0.144845, loss_ce: 0.023658 loss_dice: 0.225636\n",
            "iteration 10375 : loss : 0.178239, loss_ce: 0.042688 loss_dice: 0.268606\n",
            "iteration 10376 : loss : 0.074281, loss_ce: 0.010724 loss_dice: 0.116653\n",
            "iteration 10377 : loss : 0.197190, loss_ce: 0.025530 loss_dice: 0.311630\n",
            "iteration 10378 : loss : 0.074032, loss_ce: 0.015820 loss_dice: 0.112840\n",
            "iteration 10379 : loss : 0.086846, loss_ce: 0.031124 loss_dice: 0.123995\n",
            "iteration 10380 : loss : 0.155508, loss_ce: 0.031356 loss_dice: 0.238276\n",
            "iteration 10381 : loss : 0.105889, loss_ce: 0.028094 loss_dice: 0.157752\n",
            "iteration 10382 : loss : 0.175615, loss_ce: 0.028455 loss_dice: 0.273721\n",
            "iteration 10383 : loss : 0.151121, loss_ce: 0.045422 loss_dice: 0.221587\n",
            "iteration 10384 : loss : 0.150979, loss_ce: 0.033550 loss_dice: 0.229264\n",
            "iteration 10385 : loss : 0.202167, loss_ce: 0.016449 loss_dice: 0.325979\n",
            "iteration 10386 : loss : 0.123221, loss_ce: 0.041691 loss_dice: 0.177574\n",
            "iteration 10387 : loss : 0.133692, loss_ce: 0.017557 loss_dice: 0.211116\n",
            "iteration 10388 : loss : 0.086991, loss_ce: 0.007941 loss_dice: 0.139691\n",
            "iteration 10389 : loss : 0.105082, loss_ce: 0.015722 loss_dice: 0.164656\n",
            "iteration 10390 : loss : 0.152109, loss_ce: 0.027334 loss_dice: 0.235293\n",
            "iteration 10391 : loss : 0.160562, loss_ce: 0.028151 loss_dice: 0.248837\n",
            "iteration 10392 : loss : 0.196086, loss_ce: 0.072105 loss_dice: 0.278741\n",
            "iteration 10393 : loss : 0.088943, loss_ce: 0.031253 loss_dice: 0.127403\n",
            "iteration 10394 : loss : 0.109160, loss_ce: 0.019142 loss_dice: 0.169173\n",
            "iteration 10395 : loss : 0.201169, loss_ce: 0.024419 loss_dice: 0.319002\n",
            "iteration 10396 : loss : 0.144615, loss_ce: 0.044303 loss_dice: 0.211489\n",
            "iteration 10397 : loss : 0.102463, loss_ce: 0.031357 loss_dice: 0.149867\n",
            "iteration 10398 : loss : 0.127871, loss_ce: 0.026167 loss_dice: 0.195673\n",
            "iteration 10399 : loss : 0.149040, loss_ce: 0.032894 loss_dice: 0.226471\n",
            "iteration 10400 : loss : 0.153581, loss_ce: 0.025106 loss_dice: 0.239231\n",
            "iteration 10401 : loss : 0.183186, loss_ce: 0.031069 loss_dice: 0.284597\n",
            "iteration 10402 : loss : 0.145908, loss_ce: 0.033678 loss_dice: 0.220729\n",
            "iteration 10403 : loss : 0.137536, loss_ce: 0.056170 loss_dice: 0.191779\n",
            "iteration 10404 : loss : 0.151783, loss_ce: 0.053305 loss_dice: 0.217435\n",
            "iteration 10405 : loss : 0.092782, loss_ce: 0.016268 loss_dice: 0.143792\n",
            "iteration 10406 : loss : 0.151036, loss_ce: 0.024304 loss_dice: 0.235524\n",
            "iteration 10407 : loss : 0.127039, loss_ce: 0.033056 loss_dice: 0.189694\n",
            "iteration 10408 : loss : 0.114390, loss_ce: 0.020054 loss_dice: 0.177281\n",
            "iteration 10409 : loss : 0.101811, loss_ce: 0.027540 loss_dice: 0.151326\n",
            "iteration 10410 : loss : 0.205771, loss_ce: 0.016992 loss_dice: 0.331623\n",
            "iteration 10411 : loss : 0.169767, loss_ce: 0.025475 loss_dice: 0.265963\n",
            "iteration 10412 : loss : 0.216238, loss_ce: 0.014295 loss_dice: 0.350868\n",
            "iteration 10413 : loss : 0.128311, loss_ce: 0.039807 loss_dice: 0.187313\n",
            "iteration 10414 : loss : 0.193924, loss_ce: 0.031151 loss_dice: 0.302439\n",
            "iteration 10415 : loss : 0.135420, loss_ce: 0.030153 loss_dice: 0.205597\n",
            "iteration 10416 : loss : 0.300092, loss_ce: 0.003252 loss_dice: 0.497985\n",
            "iteration 10417 : loss : 0.152130, loss_ce: 0.029455 loss_dice: 0.233914\n",
            "iteration 10418 : loss : 0.062614, loss_ce: 0.027156 loss_dice: 0.086253\n",
            "iteration 10419 : loss : 0.195170, loss_ce: 0.063863 loss_dice: 0.282708\n",
            "iteration 10420 : loss : 0.071040, loss_ce: 0.028378 loss_dice: 0.099482\n",
            "iteration 10421 : loss : 0.167517, loss_ce: 0.056380 loss_dice: 0.241608\n",
            "iteration 10422 : loss : 0.068063, loss_ce: 0.018948 loss_dice: 0.100807\n",
            "iteration 10423 : loss : 0.148833, loss_ce: 0.074338 loss_dice: 0.198496\n",
            "iteration 10424 : loss : 0.133577, loss_ce: 0.044473 loss_dice: 0.192980\n",
            "iteration 10425 : loss : 0.130979, loss_ce: 0.020840 loss_dice: 0.204404\n",
            "iteration 10426 : loss : 0.119213, loss_ce: 0.016138 loss_dice: 0.187929\n",
            "iteration 10427 : loss : 0.142695, loss_ce: 0.063401 loss_dice: 0.195559\n",
            "iteration 10428 : loss : 0.150926, loss_ce: 0.043516 loss_dice: 0.222532\n",
            "iteration 10429 : loss : 0.139232, loss_ce: 0.039609 loss_dice: 0.205647\n",
            "iteration 10430 : loss : 0.143529, loss_ce: 0.040838 loss_dice: 0.211990\n",
            "iteration 10431 : loss : 0.116103, loss_ce: 0.028834 loss_dice: 0.174282\n",
            "iteration 10432 : loss : 0.183812, loss_ce: 0.033342 loss_dice: 0.284125\n",
            "iteration 10433 : loss : 0.083077, loss_ce: 0.018697 loss_dice: 0.125997\n",
            "iteration 10434 : loss : 0.351623, loss_ce: 0.000187 loss_dice: 0.585914\n",
            "  9%|██▍                       | 47/500 [1:52:23<14:42:22, 116.87s/it]iteration 10435 : loss : 0.144278, loss_ce: 0.028926 loss_dice: 0.221180\n",
            "iteration 10436 : loss : 0.069048, loss_ce: 0.026383 loss_dice: 0.097492\n",
            "iteration 10437 : loss : 0.217688, loss_ce: 0.005425 loss_dice: 0.359197\n",
            "iteration 10438 : loss : 0.260327, loss_ce: 0.057706 loss_dice: 0.395408\n",
            "iteration 10439 : loss : 0.160751, loss_ce: 0.060578 loss_dice: 0.227533\n",
            "iteration 10440 : loss : 0.266319, loss_ce: 0.087193 loss_dice: 0.385737\n",
            "iteration 10441 : loss : 0.153980, loss_ce: 0.019549 loss_dice: 0.243601\n",
            "iteration 10442 : loss : 0.171665, loss_ce: 0.032915 loss_dice: 0.264165\n",
            "iteration 10443 : loss : 0.129490, loss_ce: 0.029830 loss_dice: 0.195930\n",
            "iteration 10444 : loss : 0.124056, loss_ce: 0.051407 loss_dice: 0.172489\n",
            "iteration 10445 : loss : 0.286155, loss_ce: 0.030654 loss_dice: 0.456490\n",
            "iteration 10446 : loss : 0.206969, loss_ce: 0.040006 loss_dice: 0.318277\n",
            "iteration 10447 : loss : 0.207441, loss_ce: 0.034228 loss_dice: 0.322916\n",
            "iteration 10448 : loss : 0.177418, loss_ce: 0.047742 loss_dice: 0.263869\n",
            "iteration 10449 : loss : 0.214762, loss_ce: 0.077575 loss_dice: 0.306220\n",
            "iteration 10450 : loss : 0.256537, loss_ce: 0.036701 loss_dice: 0.403095\n",
            "iteration 10451 : loss : 0.220067, loss_ce: 0.038757 loss_dice: 0.340941\n",
            "iteration 10452 : loss : 0.256044, loss_ce: 0.073557 loss_dice: 0.377701\n",
            "iteration 10453 : loss : 0.255704, loss_ce: 0.028669 loss_dice: 0.407061\n",
            "iteration 10454 : loss : 0.128067, loss_ce: 0.055564 loss_dice: 0.176402\n",
            "iteration 10455 : loss : 0.067558, loss_ce: 0.030142 loss_dice: 0.092503\n",
            "iteration 10456 : loss : 0.164756, loss_ce: 0.027869 loss_dice: 0.256013\n",
            "iteration 10457 : loss : 0.186108, loss_ce: 0.053314 loss_dice: 0.274637\n",
            "iteration 10458 : loss : 0.079855, loss_ce: 0.017486 loss_dice: 0.121434\n",
            "iteration 10459 : loss : 0.164155, loss_ce: 0.044582 loss_dice: 0.243871\n",
            "iteration 10460 : loss : 0.115431, loss_ce: 0.058557 loss_dice: 0.153346\n",
            "iteration 10461 : loss : 0.233525, loss_ce: 0.033347 loss_dice: 0.366978\n",
            "iteration 10462 : loss : 0.239989, loss_ce: 0.016004 loss_dice: 0.389312\n",
            "iteration 10463 : loss : 0.176531, loss_ce: 0.047259 loss_dice: 0.262713\n",
            "iteration 10464 : loss : 0.180855, loss_ce: 0.060580 loss_dice: 0.261039\n",
            "iteration 10465 : loss : 0.145464, loss_ce: 0.065096 loss_dice: 0.199042\n",
            "iteration 10466 : loss : 0.122999, loss_ce: 0.050597 loss_dice: 0.171267\n",
            "iteration 10467 : loss : 0.196982, loss_ce: 0.075823 loss_dice: 0.277755\n",
            "iteration 10468 : loss : 0.166314, loss_ce: 0.036019 loss_dice: 0.253177\n",
            "iteration 10469 : loss : 0.138978, loss_ce: 0.052754 loss_dice: 0.196460\n",
            "iteration 10470 : loss : 0.201417, loss_ce: 0.010608 loss_dice: 0.328624\n",
            "iteration 10471 : loss : 0.179967, loss_ce: 0.027228 loss_dice: 0.281793\n",
            "iteration 10472 : loss : 0.106539, loss_ce: 0.039893 loss_dice: 0.150970\n",
            "iteration 10473 : loss : 0.214073, loss_ce: 0.031422 loss_dice: 0.335841\n",
            "iteration 10474 : loss : 0.118390, loss_ce: 0.035542 loss_dice: 0.173623\n",
            "iteration 10475 : loss : 0.130674, loss_ce: 0.015829 loss_dice: 0.207237\n",
            "iteration 10476 : loss : 0.139340, loss_ce: 0.039652 loss_dice: 0.205799\n",
            "iteration 10477 : loss : 0.231627, loss_ce: 0.008292 loss_dice: 0.380517\n",
            "iteration 10478 : loss : 0.126967, loss_ce: 0.030040 loss_dice: 0.191585\n",
            "iteration 10479 : loss : 0.113486, loss_ce: 0.047342 loss_dice: 0.157581\n",
            "iteration 10480 : loss : 0.091658, loss_ce: 0.035963 loss_dice: 0.128788\n",
            "iteration 10481 : loss : 0.306874, loss_ce: 0.007689 loss_dice: 0.506331\n",
            "iteration 10482 : loss : 0.250609, loss_ce: 0.033536 loss_dice: 0.395324\n",
            "iteration 10483 : loss : 0.149388, loss_ce: 0.026167 loss_dice: 0.231536\n",
            "iteration 10484 : loss : 0.114975, loss_ce: 0.053309 loss_dice: 0.156086\n",
            "iteration 10485 : loss : 0.129330, loss_ce: 0.060494 loss_dice: 0.175221\n",
            "iteration 10486 : loss : 0.144042, loss_ce: 0.016141 loss_dice: 0.229310\n",
            "iteration 10487 : loss : 0.112348, loss_ce: 0.026407 loss_dice: 0.169642\n",
            "iteration 10488 : loss : 0.083146, loss_ce: 0.029252 loss_dice: 0.119075\n",
            "iteration 10489 : loss : 0.146634, loss_ce: 0.021061 loss_dice: 0.230350\n",
            "iteration 10490 : loss : 0.195547, loss_ce: 0.018332 loss_dice: 0.313690\n",
            "iteration 10491 : loss : 0.185247, loss_ce: 0.034199 loss_dice: 0.285946\n",
            "iteration 10492 : loss : 0.255927, loss_ce: 0.010620 loss_dice: 0.419465\n",
            "iteration 10493 : loss : 0.080529, loss_ce: 0.031756 loss_dice: 0.113045\n",
            "iteration 10494 : loss : 0.192915, loss_ce: 0.038346 loss_dice: 0.295960\n",
            "iteration 10495 : loss : 0.186782, loss_ce: 0.025753 loss_dice: 0.294134\n",
            "iteration 10496 : loss : 0.101124, loss_ce: 0.031984 loss_dice: 0.147218\n",
            "iteration 10497 : loss : 0.168121, loss_ce: 0.017829 loss_dice: 0.268317\n",
            "iteration 10498 : loss : 0.166467, loss_ce: 0.050292 loss_dice: 0.243917\n",
            "iteration 10499 : loss : 0.102033, loss_ce: 0.045934 loss_dice: 0.139432\n",
            "iteration 10500 : loss : 0.149508, loss_ce: 0.060770 loss_dice: 0.208666\n",
            "iteration 10501 : loss : 0.095360, loss_ce: 0.022024 loss_dice: 0.144250\n",
            "iteration 10502 : loss : 0.116622, loss_ce: 0.033683 loss_dice: 0.171915\n",
            "iteration 10503 : loss : 0.219913, loss_ce: 0.022622 loss_dice: 0.351440\n",
            "iteration 10504 : loss : 0.123640, loss_ce: 0.038293 loss_dice: 0.180538\n",
            "iteration 10505 : loss : 0.152621, loss_ce: 0.066004 loss_dice: 0.210367\n",
            "iteration 10506 : loss : 0.299028, loss_ce: 0.080349 loss_dice: 0.444815\n",
            "iteration 10507 : loss : 0.344322, loss_ce: 0.048455 loss_dice: 0.541567\n",
            "iteration 10508 : loss : 0.210912, loss_ce: 0.037312 loss_dice: 0.326645\n",
            "iteration 10509 : loss : 0.159792, loss_ce: 0.030165 loss_dice: 0.246211\n",
            "iteration 10510 : loss : 0.190805, loss_ce: 0.065132 loss_dice: 0.274586\n",
            "iteration 10511 : loss : 0.155037, loss_ce: 0.022990 loss_dice: 0.243068\n",
            "iteration 10512 : loss : 0.174392, loss_ce: 0.048045 loss_dice: 0.258624\n",
            "iteration 10513 : loss : 0.207625, loss_ce: 0.042427 loss_dice: 0.317757\n",
            "iteration 10514 : loss : 0.204564, loss_ce: 0.107757 loss_dice: 0.269102\n",
            "iteration 10515 : loss : 0.137732, loss_ce: 0.060985 loss_dice: 0.188897\n",
            "iteration 10516 : loss : 0.112629, loss_ce: 0.043385 loss_dice: 0.158792\n",
            "iteration 10517 : loss : 0.077411, loss_ce: 0.015477 loss_dice: 0.118701\n",
            "iteration 10518 : loss : 0.109244, loss_ce: 0.024509 loss_dice: 0.165733\n",
            "iteration 10519 : loss : 0.088508, loss_ce: 0.024516 loss_dice: 0.131170\n",
            "iteration 10520 : loss : 0.160740, loss_ce: 0.049719 loss_dice: 0.234754\n",
            "iteration 10521 : loss : 0.144254, loss_ce: 0.013288 loss_dice: 0.231565\n",
            "iteration 10522 : loss : 0.102202, loss_ce: 0.023346 loss_dice: 0.154773\n",
            "iteration 10523 : loss : 0.176029, loss_ce: 0.038188 loss_dice: 0.267924\n",
            "iteration 10524 : loss : 0.072870, loss_ce: 0.025859 loss_dice: 0.104210\n",
            "iteration 10525 : loss : 0.103233, loss_ce: 0.021785 loss_dice: 0.157532\n",
            "iteration 10526 : loss : 0.121491, loss_ce: 0.021527 loss_dice: 0.188134\n",
            "iteration 10527 : loss : 0.147183, loss_ce: 0.052256 loss_dice: 0.210467\n",
            "iteration 10528 : loss : 0.257942, loss_ce: 0.021206 loss_dice: 0.415766\n",
            "iteration 10529 : loss : 0.202782, loss_ce: 0.011396 loss_dice: 0.330373\n",
            "iteration 10530 : loss : 0.174596, loss_ce: 0.042269 loss_dice: 0.262814\n",
            "iteration 10531 : loss : 0.163421, loss_ce: 0.051749 loss_dice: 0.237869\n",
            "iteration 10532 : loss : 0.187265, loss_ce: 0.067184 loss_dice: 0.267319\n",
            "iteration 10533 : loss : 0.198531, loss_ce: 0.044922 loss_dice: 0.300937\n",
            "iteration 10534 : loss : 0.151458, loss_ce: 0.065251 loss_dice: 0.208930\n",
            "iteration 10535 : loss : 0.183138, loss_ce: 0.017238 loss_dice: 0.293737\n",
            "iteration 10536 : loss : 0.185902, loss_ce: 0.046244 loss_dice: 0.279007\n",
            "iteration 10537 : loss : 0.163148, loss_ce: 0.029063 loss_dice: 0.252539\n",
            "iteration 10538 : loss : 0.154054, loss_ce: 0.046339 loss_dice: 0.225865\n",
            "iteration 10539 : loss : 0.293917, loss_ce: 0.015821 loss_dice: 0.479315\n",
            "iteration 10540 : loss : 0.122196, loss_ce: 0.042572 loss_dice: 0.175279\n",
            "iteration 10541 : loss : 0.221283, loss_ce: 0.021661 loss_dice: 0.354364\n",
            "iteration 10542 : loss : 0.119706, loss_ce: 0.050166 loss_dice: 0.166066\n",
            "iteration 10543 : loss : 0.087257, loss_ce: 0.024097 loss_dice: 0.129364\n",
            "iteration 10544 : loss : 0.182782, loss_ce: 0.013387 loss_dice: 0.295712\n",
            "iteration 10545 : loss : 0.138798, loss_ce: 0.029572 loss_dice: 0.211615\n",
            "iteration 10546 : loss : 0.158765, loss_ce: 0.040077 loss_dice: 0.237890\n",
            "iteration 10547 : loss : 0.143272, loss_ce: 0.036901 loss_dice: 0.214186\n",
            "iteration 10548 : loss : 0.181213, loss_ce: 0.057056 loss_dice: 0.263985\n",
            "iteration 10549 : loss : 0.116725, loss_ce: 0.052718 loss_dice: 0.159397\n",
            "iteration 10550 : loss : 0.233183, loss_ce: 0.024343 loss_dice: 0.372409\n",
            "iteration 10551 : loss : 0.152640, loss_ce: 0.037065 loss_dice: 0.229690\n",
            "iteration 10552 : loss : 0.159715, loss_ce: 0.028146 loss_dice: 0.247427\n",
            "iteration 10553 : loss : 0.169111, loss_ce: 0.072984 loss_dice: 0.233196\n",
            "iteration 10554 : loss : 0.127015, loss_ce: 0.032850 loss_dice: 0.189791\n",
            "iteration 10555 : loss : 0.194359, loss_ce: 0.041072 loss_dice: 0.296551\n",
            "iteration 10556 : loss : 0.094870, loss_ce: 0.018436 loss_dice: 0.145827\n",
            "iteration 10557 : loss : 0.115609, loss_ce: 0.033340 loss_dice: 0.170455\n",
            "iteration 10558 : loss : 0.177905, loss_ce: 0.039759 loss_dice: 0.270001\n",
            "iteration 10559 : loss : 0.210324, loss_ce: 0.021175 loss_dice: 0.336423\n",
            "iteration 10560 : loss : 0.099418, loss_ce: 0.028952 loss_dice: 0.146396\n",
            "iteration 10561 : loss : 0.124033, loss_ce: 0.023231 loss_dice: 0.191235\n",
            "iteration 10562 : loss : 0.151834, loss_ce: 0.048435 loss_dice: 0.220766\n",
            "iteration 10563 : loss : 0.084422, loss_ce: 0.025575 loss_dice: 0.123653\n",
            "iteration 10564 : loss : 0.264423, loss_ce: 0.004918 loss_dice: 0.437427\n",
            "iteration 10565 : loss : 0.197086, loss_ce: 0.024440 loss_dice: 0.312184\n",
            "iteration 10566 : loss : 0.150195, loss_ce: 0.055669 loss_dice: 0.213213\n",
            "iteration 10567 : loss : 0.261646, loss_ce: 0.011944 loss_dice: 0.428114\n",
            "iteration 10568 : loss : 0.161424, loss_ce: 0.062341 loss_dice: 0.227479\n",
            "iteration 10569 : loss : 0.152833, loss_ce: 0.038662 loss_dice: 0.228946\n",
            "iteration 10570 : loss : 0.069507, loss_ce: 0.015257 loss_dice: 0.105673\n",
            "iteration 10571 : loss : 0.064200, loss_ce: 0.020747 loss_dice: 0.093169\n",
            "iteration 10572 : loss : 0.065754, loss_ce: 0.016762 loss_dice: 0.098416\n",
            "iteration 10573 : loss : 0.148585, loss_ce: 0.036143 loss_dice: 0.223547\n",
            "iteration 10574 : loss : 0.070434, loss_ce: 0.021506 loss_dice: 0.103052\n",
            "iteration 10575 : loss : 0.109950, loss_ce: 0.039910 loss_dice: 0.156644\n",
            "iteration 10576 : loss : 0.247211, loss_ce: 0.009309 loss_dice: 0.405813\n",
            "iteration 10577 : loss : 0.092708, loss_ce: 0.034332 loss_dice: 0.131626\n",
            "iteration 10578 : loss : 0.204824, loss_ce: 0.009841 loss_dice: 0.334812\n",
            "iteration 10579 : loss : 0.165981, loss_ce: 0.054124 loss_dice: 0.240552\n",
            "iteration 10580 : loss : 0.104099, loss_ce: 0.049014 loss_dice: 0.140822\n",
            "iteration 10581 : loss : 0.143750, loss_ce: 0.056058 loss_dice: 0.202212\n",
            "iteration 10582 : loss : 0.164858, loss_ce: 0.055414 loss_dice: 0.237821\n",
            "iteration 10583 : loss : 0.141027, loss_ce: 0.083159 loss_dice: 0.179606\n",
            "iteration 10584 : loss : 0.132168, loss_ce: 0.037993 loss_dice: 0.194951\n",
            "iteration 10585 : loss : 0.157919, loss_ce: 0.044433 loss_dice: 0.233577\n",
            "iteration 10586 : loss : 0.157142, loss_ce: 0.030817 loss_dice: 0.241358\n",
            "iteration 10587 : loss : 0.113971, loss_ce: 0.031888 loss_dice: 0.168693\n",
            "iteration 10588 : loss : 0.181734, loss_ce: 0.016526 loss_dice: 0.291872\n",
            "iteration 10589 : loss : 0.100003, loss_ce: 0.052780 loss_dice: 0.131484\n",
            "iteration 10590 : loss : 0.164967, loss_ce: 0.020966 loss_dice: 0.260968\n",
            "iteration 10591 : loss : 0.145700, loss_ce: 0.028927 loss_dice: 0.223549\n",
            "iteration 10592 : loss : 0.181189, loss_ce: 0.026614 loss_dice: 0.284240\n",
            "iteration 10593 : loss : 0.101731, loss_ce: 0.038886 loss_dice: 0.143628\n",
            "iteration 10594 : loss : 0.145318, loss_ce: 0.030324 loss_dice: 0.221980\n",
            "iteration 10595 : loss : 0.156219, loss_ce: 0.043837 loss_dice: 0.231140\n",
            "iteration 10596 : loss : 0.165091, loss_ce: 0.048243 loss_dice: 0.242990\n",
            "iteration 10597 : loss : 0.135581, loss_ce: 0.018101 loss_dice: 0.213901\n",
            "iteration 10598 : loss : 0.258636, loss_ce: 0.013962 loss_dice: 0.421753\n",
            "iteration 10599 : loss : 0.094836, loss_ce: 0.045940 loss_dice: 0.127433\n",
            "iteration 10600 : loss : 0.201687, loss_ce: 0.018464 loss_dice: 0.323836\n",
            "iteration 10601 : loss : 0.210852, loss_ce: 0.017560 loss_dice: 0.339713\n",
            "iteration 10602 : loss : 0.148740, loss_ce: 0.024487 loss_dice: 0.231576\n",
            "iteration 10603 : loss : 0.135962, loss_ce: 0.017538 loss_dice: 0.214911\n",
            "iteration 10604 : loss : 0.104950, loss_ce: 0.048437 loss_dice: 0.142625\n",
            "iteration 10605 : loss : 0.123794, loss_ce: 0.016525 loss_dice: 0.195306\n",
            "iteration 10606 : loss : 0.184926, loss_ce: 0.039023 loss_dice: 0.282195\n",
            "iteration 10607 : loss : 0.047625, loss_ce: 0.012763 loss_dice: 0.070866\n",
            "iteration 10608 : loss : 0.143262, loss_ce: 0.026549 loss_dice: 0.221071\n",
            "iteration 10609 : loss : 0.161597, loss_ce: 0.006576 loss_dice: 0.264945\n",
            "iteration 10610 : loss : 0.125734, loss_ce: 0.012537 loss_dice: 0.201199\n",
            "iteration 10611 : loss : 0.104813, loss_ce: 0.021403 loss_dice: 0.160420\n",
            "iteration 10612 : loss : 0.101061, loss_ce: 0.031546 loss_dice: 0.147405\n",
            "iteration 10613 : loss : 0.098076, loss_ce: 0.025126 loss_dice: 0.146710\n",
            "iteration 10614 : loss : 0.138888, loss_ce: 0.020927 loss_dice: 0.217529\n",
            "iteration 10615 : loss : 0.169850, loss_ce: 0.049491 loss_dice: 0.250088\n",
            "iteration 10616 : loss : 0.163496, loss_ce: 0.030620 loss_dice: 0.252080\n",
            "iteration 10617 : loss : 0.124619, loss_ce: 0.021537 loss_dice: 0.193340\n",
            "iteration 10618 : loss : 0.136194, loss_ce: 0.018258 loss_dice: 0.214818\n",
            "iteration 10619 : loss : 0.108769, loss_ce: 0.033697 loss_dice: 0.158817\n",
            "iteration 10620 : loss : 0.178654, loss_ce: 0.059738 loss_dice: 0.257931\n",
            "iteration 10621 : loss : 0.153872, loss_ce: 0.038077 loss_dice: 0.231068\n",
            "iteration 10622 : loss : 0.121949, loss_ce: 0.057934 loss_dice: 0.164626\n",
            "iteration 10623 : loss : 0.145596, loss_ce: 0.013533 loss_dice: 0.233638\n",
            "iteration 10624 : loss : 0.136989, loss_ce: 0.012958 loss_dice: 0.219677\n",
            "iteration 10625 : loss : 0.126890, loss_ce: 0.034652 loss_dice: 0.188383\n",
            "iteration 10626 : loss : 0.051388, loss_ce: 0.022572 loss_dice: 0.070598\n",
            "iteration 10627 : loss : 0.155219, loss_ce: 0.034531 loss_dice: 0.235678\n",
            "iteration 10628 : loss : 0.153514, loss_ce: 0.049044 loss_dice: 0.223160\n",
            "iteration 10629 : loss : 0.131860, loss_ce: 0.011826 loss_dice: 0.211882\n",
            "iteration 10630 : loss : 0.157158, loss_ce: 0.075748 loss_dice: 0.211432\n",
            "iteration 10631 : loss : 0.150802, loss_ce: 0.057517 loss_dice: 0.212991\n",
            "iteration 10632 : loss : 0.232692, loss_ce: 0.013621 loss_dice: 0.378740\n",
            "iteration 10633 : loss : 0.169072, loss_ce: 0.064519 loss_dice: 0.238774\n",
            "iteration 10634 : loss : 0.298673, loss_ce: 0.029852 loss_dice: 0.477888\n",
            "iteration 10635 : loss : 0.098802, loss_ce: 0.021836 loss_dice: 0.150112\n",
            "iteration 10636 : loss : 0.162807, loss_ce: 0.066443 loss_dice: 0.227049\n",
            "iteration 10637 : loss : 0.128162, loss_ce: 0.070681 loss_dice: 0.166482\n",
            "iteration 10638 : loss : 0.227338, loss_ce: 0.045047 loss_dice: 0.348864\n",
            "iteration 10639 : loss : 0.152099, loss_ce: 0.064843 loss_dice: 0.210269\n",
            "iteration 10640 : loss : 0.125420, loss_ce: 0.011798 loss_dice: 0.201168\n",
            "iteration 10641 : loss : 0.170258, loss_ce: 0.004553 loss_dice: 0.280728\n",
            "iteration 10642 : loss : 0.066148, loss_ce: 0.027035 loss_dice: 0.092223\n",
            "iteration 10643 : loss : 0.199382, loss_ce: 0.041652 loss_dice: 0.304535\n",
            "iteration 10644 : loss : 0.173295, loss_ce: 0.015003 loss_dice: 0.278823\n",
            "iteration 10645 : loss : 0.124408, loss_ce: 0.038507 loss_dice: 0.181676\n",
            "iteration 10646 : loss : 0.088295, loss_ce: 0.019304 loss_dice: 0.134289\n",
            "iteration 10647 : loss : 0.164678, loss_ce: 0.029267 loss_dice: 0.254952\n",
            "iteration 10648 : loss : 0.120247, loss_ce: 0.038742 loss_dice: 0.174584\n",
            "iteration 10649 : loss : 0.091177, loss_ce: 0.025472 loss_dice: 0.134981\n",
            "iteration 10650 : loss : 0.088484, loss_ce: 0.031067 loss_dice: 0.126762\n",
            "iteration 10651 : loss : 0.071983, loss_ce: 0.014614 loss_dice: 0.110228\n",
            "iteration 10652 : loss : 0.083056, loss_ce: 0.023195 loss_dice: 0.122964\n",
            "iteration 10653 : loss : 0.106963, loss_ce: 0.024264 loss_dice: 0.162095\n",
            "iteration 10654 : loss : 0.136025, loss_ce: 0.031191 loss_dice: 0.205914\n",
            "iteration 10655 : loss : 0.122918, loss_ce: 0.014688 loss_dice: 0.195071\n",
            "iteration 10656 : loss : 0.222889, loss_ce: 0.020322 loss_dice: 0.357934\n",
            " 10%|██▍                       | 48/500 [1:53:46<13:24:16, 106.76s/it]iteration 10657 : loss : 0.229492, loss_ce: 0.011120 loss_dice: 0.375073\n",
            "iteration 10658 : loss : 0.177898, loss_ce: 0.040020 loss_dice: 0.269817\n",
            "iteration 10659 : loss : 0.144822, loss_ce: 0.059124 loss_dice: 0.201954\n",
            "iteration 10660 : loss : 0.146111, loss_ce: 0.054783 loss_dice: 0.206996\n",
            "iteration 10661 : loss : 0.091161, loss_ce: 0.035859 loss_dice: 0.128029\n",
            "iteration 10662 : loss : 0.130361, loss_ce: 0.036190 loss_dice: 0.193141\n",
            "iteration 10663 : loss : 0.145665, loss_ce: 0.034491 loss_dice: 0.219781\n",
            "iteration 10664 : loss : 0.182257, loss_ce: 0.012720 loss_dice: 0.295281\n",
            "iteration 10665 : loss : 0.112197, loss_ce: 0.067167 loss_dice: 0.142216\n",
            "iteration 10666 : loss : 0.146678, loss_ce: 0.025356 loss_dice: 0.227559\n",
            "iteration 10667 : loss : 0.191760, loss_ce: 0.020468 loss_dice: 0.305955\n",
            "iteration 10668 : loss : 0.145030, loss_ce: 0.028672 loss_dice: 0.222603\n",
            "iteration 10669 : loss : 0.095655, loss_ce: 0.050640 loss_dice: 0.125665\n",
            "iteration 10670 : loss : 0.121501, loss_ce: 0.040677 loss_dice: 0.175384\n",
            "iteration 10671 : loss : 0.118110, loss_ce: 0.043536 loss_dice: 0.167826\n",
            "iteration 10672 : loss : 0.127926, loss_ce: 0.025233 loss_dice: 0.196388\n",
            "iteration 10673 : loss : 0.239327, loss_ce: 0.025911 loss_dice: 0.381605\n",
            "iteration 10674 : loss : 0.123963, loss_ce: 0.021635 loss_dice: 0.192181\n",
            "iteration 10675 : loss : 0.284490, loss_ce: 0.005893 loss_dice: 0.470222\n",
            "iteration 10676 : loss : 0.157058, loss_ce: 0.046515 loss_dice: 0.230754\n",
            "iteration 10677 : loss : 0.144232, loss_ce: 0.014976 loss_dice: 0.230403\n",
            "iteration 10678 : loss : 0.115315, loss_ce: 0.010836 loss_dice: 0.184968\n",
            "iteration 10679 : loss : 0.110340, loss_ce: 0.060794 loss_dice: 0.143371\n",
            "iteration 10680 : loss : 0.070769, loss_ce: 0.025237 loss_dice: 0.101124\n",
            "iteration 10681 : loss : 0.119726, loss_ce: 0.017167 loss_dice: 0.188098\n",
            "iteration 10682 : loss : 0.129489, loss_ce: 0.033204 loss_dice: 0.193679\n",
            "iteration 10683 : loss : 0.133443, loss_ce: 0.031221 loss_dice: 0.201590\n",
            "iteration 10684 : loss : 0.085346, loss_ce: 0.021839 loss_dice: 0.127684\n",
            "iteration 10685 : loss : 0.180014, loss_ce: 0.058893 loss_dice: 0.260761\n",
            "iteration 10686 : loss : 0.075462, loss_ce: 0.040644 loss_dice: 0.098675\n",
            "iteration 10687 : loss : 0.142190, loss_ce: 0.037454 loss_dice: 0.212015\n",
            "iteration 10688 : loss : 0.149961, loss_ce: 0.047197 loss_dice: 0.218471\n",
            "iteration 10689 : loss : 0.113176, loss_ce: 0.028027 loss_dice: 0.169943\n",
            "iteration 10690 : loss : 0.111654, loss_ce: 0.019966 loss_dice: 0.172780\n",
            "iteration 10691 : loss : 0.127523, loss_ce: 0.031427 loss_dice: 0.191587\n",
            "iteration 10692 : loss : 0.137414, loss_ce: 0.024019 loss_dice: 0.213011\n",
            "iteration 10693 : loss : 0.128696, loss_ce: 0.004588 loss_dice: 0.211435\n",
            "iteration 10694 : loss : 0.037550, loss_ce: 0.007103 loss_dice: 0.057847\n",
            "iteration 10695 : loss : 0.141641, loss_ce: 0.017606 loss_dice: 0.224331\n",
            "iteration 10696 : loss : 0.107211, loss_ce: 0.035479 loss_dice: 0.155032\n",
            "iteration 10697 : loss : 0.243901, loss_ce: 0.016388 loss_dice: 0.395577\n",
            "iteration 10698 : loss : 0.065327, loss_ce: 0.013490 loss_dice: 0.099885\n",
            "iteration 10699 : loss : 0.072600, loss_ce: 0.025434 loss_dice: 0.104044\n",
            "iteration 10700 : loss : 0.084717, loss_ce: 0.019166 loss_dice: 0.128417\n",
            "iteration 10701 : loss : 0.151166, loss_ce: 0.030341 loss_dice: 0.231716\n",
            "iteration 10702 : loss : 0.121102, loss_ce: 0.025338 loss_dice: 0.184944\n",
            "iteration 10703 : loss : 0.148346, loss_ce: 0.023081 loss_dice: 0.231856\n",
            "iteration 10704 : loss : 0.116476, loss_ce: 0.011032 loss_dice: 0.186772\n",
            "iteration 10705 : loss : 0.198604, loss_ce: 0.007309 loss_dice: 0.326135\n",
            "iteration 10706 : loss : 0.225783, loss_ce: 0.032439 loss_dice: 0.354680\n",
            "iteration 10707 : loss : 0.094998, loss_ce: 0.032672 loss_dice: 0.136549\n",
            "iteration 10708 : loss : 0.161929, loss_ce: 0.040405 loss_dice: 0.242945\n",
            "iteration 10709 : loss : 0.118181, loss_ce: 0.029465 loss_dice: 0.177324\n",
            "iteration 10710 : loss : 0.189029, loss_ce: 0.027918 loss_dice: 0.296437\n",
            "iteration 10711 : loss : 0.175068, loss_ce: 0.041485 loss_dice: 0.264123\n",
            "iteration 10712 : loss : 0.057104, loss_ce: 0.023787 loss_dice: 0.079315\n",
            "iteration 10713 : loss : 0.118793, loss_ce: 0.039133 loss_dice: 0.171899\n",
            "iteration 10714 : loss : 0.168271, loss_ce: 0.044962 loss_dice: 0.250477\n",
            "iteration 10715 : loss : 0.179686, loss_ce: 0.046275 loss_dice: 0.268627\n",
            "iteration 10716 : loss : 0.144727, loss_ce: 0.022867 loss_dice: 0.225968\n",
            "iteration 10717 : loss : 0.149319, loss_ce: 0.069307 loss_dice: 0.202661\n",
            "iteration 10718 : loss : 0.145341, loss_ce: 0.018895 loss_dice: 0.229638\n",
            "iteration 10719 : loss : 0.186774, loss_ce: 0.008647 loss_dice: 0.305526\n",
            "iteration 10720 : loss : 0.187973, loss_ce: 0.022150 loss_dice: 0.298521\n",
            "iteration 10721 : loss : 0.270091, loss_ce: 0.019366 loss_dice: 0.437242\n",
            "iteration 10722 : loss : 0.121514, loss_ce: 0.025379 loss_dice: 0.185604\n",
            "iteration 10723 : loss : 0.098326, loss_ce: 0.025590 loss_dice: 0.146816\n",
            "iteration 10724 : loss : 0.162390, loss_ce: 0.016163 loss_dice: 0.259875\n",
            "iteration 10725 : loss : 0.122127, loss_ce: 0.022974 loss_dice: 0.188228\n",
            "iteration 10726 : loss : 0.154814, loss_ce: 0.068021 loss_dice: 0.212675\n",
            "iteration 10727 : loss : 0.142134, loss_ce: 0.037512 loss_dice: 0.211883\n",
            "iteration 10728 : loss : 0.138261, loss_ce: 0.027932 loss_dice: 0.211814\n",
            "iteration 10729 : loss : 0.152128, loss_ce: 0.055024 loss_dice: 0.216864\n",
            "iteration 10730 : loss : 0.163153, loss_ce: 0.050935 loss_dice: 0.237966\n",
            "iteration 10731 : loss : 0.134268, loss_ce: 0.020979 loss_dice: 0.209794\n",
            "iteration 10732 : loss : 0.228183, loss_ce: 0.008575 loss_dice: 0.374588\n",
            "iteration 10733 : loss : 0.126215, loss_ce: 0.025669 loss_dice: 0.193246\n",
            "iteration 10734 : loss : 0.230789, loss_ce: 0.048408 loss_dice: 0.352377\n",
            "iteration 10735 : loss : 0.233838, loss_ce: 0.009325 loss_dice: 0.383513\n",
            "iteration 10736 : loss : 0.077573, loss_ce: 0.013847 loss_dice: 0.120057\n",
            "iteration 10737 : loss : 0.134320, loss_ce: 0.038140 loss_dice: 0.198440\n",
            "iteration 10738 : loss : 0.117241, loss_ce: 0.039809 loss_dice: 0.168862\n",
            "iteration 10739 : loss : 0.163970, loss_ce: 0.060331 loss_dice: 0.233062\n",
            "iteration 10740 : loss : 0.106921, loss_ce: 0.019784 loss_dice: 0.165013\n",
            "iteration 10741 : loss : 0.096436, loss_ce: 0.035618 loss_dice: 0.136981\n",
            "iteration 10742 : loss : 0.129817, loss_ce: 0.038230 loss_dice: 0.190875\n",
            "iteration 10743 : loss : 0.104255, loss_ce: 0.025688 loss_dice: 0.156633\n",
            "iteration 10744 : loss : 0.203076, loss_ce: 0.018821 loss_dice: 0.325912\n",
            "iteration 10745 : loss : 0.132539, loss_ce: 0.016504 loss_dice: 0.209896\n",
            "iteration 10746 : loss : 0.168183, loss_ce: 0.045414 loss_dice: 0.250029\n",
            "iteration 10747 : loss : 0.107906, loss_ce: 0.010035 loss_dice: 0.173154\n",
            "iteration 10748 : loss : 0.080831, loss_ce: 0.027027 loss_dice: 0.116700\n",
            "iteration 10749 : loss : 0.193147, loss_ce: 0.046043 loss_dice: 0.291217\n",
            "iteration 10750 : loss : 0.301388, loss_ce: 0.059530 loss_dice: 0.462626\n",
            "iteration 10751 : loss : 0.108847, loss_ce: 0.004255 loss_dice: 0.178574\n",
            "iteration 10752 : loss : 0.173300, loss_ce: 0.065900 loss_dice: 0.244900\n",
            "iteration 10753 : loss : 0.128442, loss_ce: 0.065546 loss_dice: 0.170372\n",
            "iteration 10754 : loss : 0.152571, loss_ce: 0.061190 loss_dice: 0.213491\n",
            "iteration 10755 : loss : 0.119055, loss_ce: 0.030541 loss_dice: 0.178065\n",
            "iteration 10756 : loss : 0.123722, loss_ce: 0.057827 loss_dice: 0.167652\n",
            "iteration 10757 : loss : 0.154323, loss_ce: 0.041913 loss_dice: 0.229263\n",
            "iteration 10758 : loss : 0.146209, loss_ce: 0.065505 loss_dice: 0.200012\n",
            "iteration 10759 : loss : 0.133891, loss_ce: 0.038622 loss_dice: 0.197403\n",
            "iteration 10760 : loss : 0.160328, loss_ce: 0.030717 loss_dice: 0.246735\n",
            "iteration 10761 : loss : 0.087580, loss_ce: 0.033766 loss_dice: 0.123455\n",
            "iteration 10762 : loss : 0.144711, loss_ce: 0.022400 loss_dice: 0.226251\n",
            "iteration 10763 : loss : 0.258254, loss_ce: 0.017100 loss_dice: 0.419023\n",
            "iteration 10764 : loss : 0.167296, loss_ce: 0.008719 loss_dice: 0.273015\n",
            "iteration 10765 : loss : 0.185625, loss_ce: 0.079971 loss_dice: 0.256060\n",
            "iteration 10766 : loss : 0.113845, loss_ce: 0.030251 loss_dice: 0.169574\n",
            "iteration 10767 : loss : 0.130328, loss_ce: 0.034531 loss_dice: 0.194192\n",
            "iteration 10768 : loss : 0.190079, loss_ce: 0.031120 loss_dice: 0.296051\n",
            "iteration 10769 : loss : 0.162596, loss_ce: 0.039042 loss_dice: 0.244966\n",
            "iteration 10770 : loss : 0.152088, loss_ce: 0.023642 loss_dice: 0.237718\n",
            "iteration 10771 : loss : 0.100863, loss_ce: 0.022870 loss_dice: 0.152858\n",
            "iteration 10772 : loss : 0.171568, loss_ce: 0.023223 loss_dice: 0.270465\n",
            "iteration 10773 : loss : 0.056965, loss_ce: 0.026861 loss_dice: 0.077035\n",
            "iteration 10774 : loss : 0.119335, loss_ce: 0.051442 loss_dice: 0.164598\n",
            "iteration 10775 : loss : 0.072482, loss_ce: 0.022758 loss_dice: 0.105631\n",
            "iteration 10776 : loss : 0.077138, loss_ce: 0.037786 loss_dice: 0.103373\n",
            "iteration 10777 : loss : 0.166634, loss_ce: 0.012471 loss_dice: 0.269410\n",
            "iteration 10778 : loss : 0.045778, loss_ce: 0.015838 loss_dice: 0.065738\n",
            "iteration 10779 : loss : 0.202219, loss_ce: 0.034936 loss_dice: 0.313742\n",
            "iteration 10780 : loss : 0.138210, loss_ce: 0.037056 loss_dice: 0.205646\n",
            "iteration 10781 : loss : 0.143479, loss_ce: 0.029586 loss_dice: 0.219407\n",
            "iteration 10782 : loss : 0.220365, loss_ce: 0.021098 loss_dice: 0.353209\n",
            "iteration 10783 : loss : 0.126521, loss_ce: 0.043713 loss_dice: 0.181726\n",
            "iteration 10784 : loss : 0.104647, loss_ce: 0.018902 loss_dice: 0.161811\n",
            "iteration 10785 : loss : 0.142523, loss_ce: 0.042534 loss_dice: 0.209182\n",
            "iteration 10786 : loss : 0.093545, loss_ce: 0.015059 loss_dice: 0.145869\n",
            "iteration 10787 : loss : 0.111715, loss_ce: 0.017620 loss_dice: 0.174445\n",
            "iteration 10788 : loss : 0.180177, loss_ce: 0.006133 loss_dice: 0.296207\n",
            "iteration 10789 : loss : 0.089835, loss_ce: 0.025915 loss_dice: 0.132448\n",
            "iteration 10790 : loss : 0.181728, loss_ce: 0.007729 loss_dice: 0.297727\n",
            "iteration 10791 : loss : 0.114795, loss_ce: 0.040758 loss_dice: 0.164153\n",
            "iteration 10792 : loss : 0.138719, loss_ce: 0.039479 loss_dice: 0.204880\n",
            "iteration 10793 : loss : 0.087530, loss_ce: 0.034294 loss_dice: 0.123020\n",
            "iteration 10794 : loss : 0.143991, loss_ce: 0.032386 loss_dice: 0.218394\n",
            "iteration 10795 : loss : 0.126678, loss_ce: 0.049095 loss_dice: 0.178399\n",
            "iteration 10796 : loss : 0.107794, loss_ce: 0.022747 loss_dice: 0.164492\n",
            "iteration 10797 : loss : 0.144013, loss_ce: 0.008942 loss_dice: 0.234061\n",
            "iteration 10798 : loss : 0.047884, loss_ce: 0.015596 loss_dice: 0.069409\n",
            "iteration 10799 : loss : 0.152150, loss_ce: 0.037963 loss_dice: 0.228274\n",
            "iteration 10800 : loss : 0.219947, loss_ce: 0.004083 loss_dice: 0.363856\n",
            "iteration 10801 : loss : 0.131255, loss_ce: 0.024848 loss_dice: 0.202194\n",
            "iteration 10802 : loss : 0.104227, loss_ce: 0.041066 loss_dice: 0.146334\n",
            "iteration 10803 : loss : 0.088189, loss_ce: 0.027409 loss_dice: 0.128710\n",
            "iteration 10804 : loss : 0.177381, loss_ce: 0.055974 loss_dice: 0.258319\n",
            "iteration 10805 : loss : 0.205261, loss_ce: 0.014983 loss_dice: 0.332113\n",
            "iteration 10806 : loss : 0.162058, loss_ce: 0.048178 loss_dice: 0.237978\n",
            "iteration 10807 : loss : 0.114103, loss_ce: 0.026001 loss_dice: 0.172838\n",
            "iteration 10808 : loss : 0.075967, loss_ce: 0.017045 loss_dice: 0.115248\n",
            "iteration 10809 : loss : 0.099994, loss_ce: 0.019861 loss_dice: 0.153415\n",
            "iteration 10810 : loss : 0.079250, loss_ce: 0.032383 loss_dice: 0.110494\n",
            "iteration 10811 : loss : 0.117844, loss_ce: 0.064409 loss_dice: 0.153468\n",
            "iteration 10812 : loss : 0.115535, loss_ce: 0.017536 loss_dice: 0.180867\n",
            "iteration 10813 : loss : 0.090450, loss_ce: 0.028510 loss_dice: 0.131744\n",
            "iteration 10814 : loss : 0.121780, loss_ce: 0.016348 loss_dice: 0.192067\n",
            "iteration 10815 : loss : 0.141733, loss_ce: 0.015902 loss_dice: 0.225621\n",
            "iteration 10816 : loss : 0.083667, loss_ce: 0.024522 loss_dice: 0.123097\n",
            "iteration 10817 : loss : 0.112932, loss_ce: 0.015782 loss_dice: 0.177698\n",
            "iteration 10818 : loss : 0.063773, loss_ce: 0.023097 loss_dice: 0.090891\n",
            "iteration 10819 : loss : 0.302377, loss_ce: 0.006082 loss_dice: 0.499907\n",
            "iteration 10820 : loss : 0.106617, loss_ce: 0.026166 loss_dice: 0.160251\n",
            "iteration 10821 : loss : 0.150683, loss_ce: 0.026915 loss_dice: 0.233195\n",
            "iteration 10822 : loss : 0.113202, loss_ce: 0.010889 loss_dice: 0.181411\n",
            "iteration 10823 : loss : 0.093980, loss_ce: 0.015844 loss_dice: 0.146070\n",
            "iteration 10824 : loss : 0.128388, loss_ce: 0.012566 loss_dice: 0.205602\n",
            "iteration 10825 : loss : 0.115324, loss_ce: 0.019728 loss_dice: 0.179054\n",
            "iteration 10826 : loss : 0.072544, loss_ce: 0.023939 loss_dice: 0.104947\n",
            "iteration 10827 : loss : 0.067136, loss_ce: 0.018050 loss_dice: 0.099859\n",
            "iteration 10828 : loss : 0.171406, loss_ce: 0.013301 loss_dice: 0.276810\n",
            "iteration 10829 : loss : 0.073267, loss_ce: 0.020429 loss_dice: 0.108493\n",
            "iteration 10830 : loss : 0.086631, loss_ce: 0.029993 loss_dice: 0.124390\n",
            "iteration 10831 : loss : 0.048957, loss_ce: 0.009872 loss_dice: 0.075013\n",
            "iteration 10832 : loss : 0.141497, loss_ce: 0.025225 loss_dice: 0.219012\n",
            "iteration 10833 : loss : 0.070008, loss_ce: 0.025511 loss_dice: 0.099673\n",
            "iteration 10834 : loss : 0.113906, loss_ce: 0.045957 loss_dice: 0.159206\n",
            "iteration 10835 : loss : 0.166271, loss_ce: 0.017350 loss_dice: 0.265552\n",
            "iteration 10836 : loss : 0.154171, loss_ce: 0.043792 loss_dice: 0.227758\n",
            "iteration 10837 : loss : 0.108593, loss_ce: 0.051098 loss_dice: 0.146923\n",
            "iteration 10838 : loss : 0.112295, loss_ce: 0.037899 loss_dice: 0.161892\n",
            "iteration 10839 : loss : 0.084087, loss_ce: 0.029297 loss_dice: 0.120613\n",
            "iteration 10840 : loss : 0.103936, loss_ce: 0.031270 loss_dice: 0.152381\n",
            "iteration 10841 : loss : 0.235081, loss_ce: 0.009153 loss_dice: 0.385699\n",
            "iteration 10842 : loss : 0.212961, loss_ce: 0.026680 loss_dice: 0.337149\n",
            "iteration 10843 : loss : 0.099417, loss_ce: 0.047099 loss_dice: 0.134296\n",
            "iteration 10844 : loss : 0.147080, loss_ce: 0.027418 loss_dice: 0.226854\n",
            "iteration 10845 : loss : 0.214160, loss_ce: 0.011396 loss_dice: 0.349335\n",
            "iteration 10846 : loss : 0.078824, loss_ce: 0.032312 loss_dice: 0.109831\n",
            "iteration 10847 : loss : 0.110033, loss_ce: 0.031155 loss_dice: 0.162619\n",
            "iteration 10848 : loss : 0.081729, loss_ce: 0.038539 loss_dice: 0.110522\n",
            "iteration 10849 : loss : 0.178641, loss_ce: 0.021165 loss_dice: 0.283625\n",
            "iteration 10850 : loss : 0.151431, loss_ce: 0.011025 loss_dice: 0.245035\n",
            "iteration 10851 : loss : 0.082510, loss_ce: 0.014668 loss_dice: 0.127737\n",
            "iteration 10852 : loss : 0.070330, loss_ce: 0.023439 loss_dice: 0.101591\n",
            "iteration 10853 : loss : 0.078473, loss_ce: 0.022295 loss_dice: 0.115925\n",
            "iteration 10854 : loss : 0.215806, loss_ce: 0.010014 loss_dice: 0.353000\n",
            "iteration 10855 : loss : 0.076977, loss_ce: 0.024630 loss_dice: 0.111875\n",
            "iteration 10856 : loss : 0.116011, loss_ce: 0.027905 loss_dice: 0.174748\n",
            "iteration 10857 : loss : 0.122138, loss_ce: 0.019891 loss_dice: 0.190302\n",
            "iteration 10858 : loss : 0.145379, loss_ce: 0.040702 loss_dice: 0.215164\n",
            "iteration 10859 : loss : 0.078058, loss_ce: 0.019405 loss_dice: 0.117160\n",
            "iteration 10860 : loss : 0.103272, loss_ce: 0.029046 loss_dice: 0.152756\n",
            "iteration 10861 : loss : 0.127067, loss_ce: 0.005576 loss_dice: 0.208062\n",
            "iteration 10862 : loss : 0.152011, loss_ce: 0.020519 loss_dice: 0.239672\n",
            "iteration 10863 : loss : 0.080998, loss_ce: 0.021238 loss_dice: 0.120838\n",
            "iteration 10864 : loss : 0.141856, loss_ce: 0.034891 loss_dice: 0.213166\n",
            "iteration 10865 : loss : 0.186233, loss_ce: 0.063971 loss_dice: 0.267741\n",
            "iteration 10866 : loss : 0.098196, loss_ce: 0.032114 loss_dice: 0.142251\n",
            "iteration 10867 : loss : 0.184167, loss_ce: 0.090543 loss_dice: 0.246583\n",
            "iteration 10868 : loss : 0.185512, loss_ce: 0.021767 loss_dice: 0.294676\n",
            "iteration 10869 : loss : 0.138532, loss_ce: 0.025317 loss_dice: 0.214008\n",
            "iteration 10870 : loss : 0.122375, loss_ce: 0.028941 loss_dice: 0.184664\n",
            "iteration 10871 : loss : 0.231131, loss_ce: 0.008729 loss_dice: 0.379399\n",
            "iteration 10872 : loss : 0.182316, loss_ce: 0.066141 loss_dice: 0.259766\n",
            "iteration 10873 : loss : 0.131988, loss_ce: 0.060573 loss_dice: 0.179598\n",
            "iteration 10874 : loss : 0.202365, loss_ce: 0.051569 loss_dice: 0.302896\n",
            "iteration 10875 : loss : 0.181939, loss_ce: 0.076127 loss_dice: 0.252480\n",
            "iteration 10876 : loss : 0.140691, loss_ce: 0.026800 loss_dice: 0.216619\n",
            "iteration 10877 : loss : 0.141920, loss_ce: 0.028188 loss_dice: 0.217741\n",
            "iteration 10878 : loss : 0.274465, loss_ce: 0.098678 loss_dice: 0.391656\n",
            " 10%|██▋                        | 49/500 [1:55:10<12:30:40, 99.87s/it]iteration 10879 : loss : 0.089610, loss_ce: 0.028926 loss_dice: 0.130065\n",
            "iteration 10880 : loss : 0.068044, loss_ce: 0.018381 loss_dice: 0.101153\n",
            "iteration 10881 : loss : 0.173991, loss_ce: 0.062547 loss_dice: 0.248286\n",
            "iteration 10882 : loss : 0.221316, loss_ce: 0.061076 loss_dice: 0.328142\n",
            "iteration 10883 : loss : 0.199653, loss_ce: 0.018399 loss_dice: 0.320490\n",
            "iteration 10884 : loss : 0.121697, loss_ce: 0.019838 loss_dice: 0.189603\n",
            "iteration 10885 : loss : 0.068415, loss_ce: 0.025542 loss_dice: 0.096997\n",
            "iteration 10886 : loss : 0.101912, loss_ce: 0.017498 loss_dice: 0.158189\n",
            "iteration 10887 : loss : 0.253364, loss_ce: 0.025164 loss_dice: 0.405496\n",
            "iteration 10888 : loss : 0.093715, loss_ce: 0.035958 loss_dice: 0.132220\n",
            "iteration 10889 : loss : 0.136876, loss_ce: 0.025389 loss_dice: 0.211201\n",
            "iteration 10890 : loss : 0.137996, loss_ce: 0.026329 loss_dice: 0.212440\n",
            "iteration 10891 : loss : 0.133927, loss_ce: 0.042724 loss_dice: 0.194729\n",
            "iteration 10892 : loss : 0.242271, loss_ce: 0.040892 loss_dice: 0.376523\n",
            "iteration 10893 : loss : 0.194784, loss_ce: 0.021745 loss_dice: 0.310144\n",
            "iteration 10894 : loss : 0.122308, loss_ce: 0.025787 loss_dice: 0.186655\n",
            "iteration 10895 : loss : 0.100532, loss_ce: 0.053885 loss_dice: 0.131630\n",
            "iteration 10896 : loss : 0.144480, loss_ce: 0.010149 loss_dice: 0.234035\n",
            "iteration 10897 : loss : 0.163251, loss_ce: 0.038392 loss_dice: 0.246491\n",
            "iteration 10898 : loss : 0.084595, loss_ce: 0.030173 loss_dice: 0.120876\n",
            "iteration 10899 : loss : 0.159605, loss_ce: 0.064094 loss_dice: 0.223280\n",
            "iteration 10900 : loss : 0.173275, loss_ce: 0.057023 loss_dice: 0.250776\n",
            "iteration 10901 : loss : 0.120197, loss_ce: 0.035753 loss_dice: 0.176493\n",
            "iteration 10902 : loss : 0.139644, loss_ce: 0.035836 loss_dice: 0.208850\n",
            "iteration 10903 : loss : 0.178864, loss_ce: 0.024790 loss_dice: 0.281581\n",
            "iteration 10904 : loss : 0.076102, loss_ce: 0.016745 loss_dice: 0.115674\n",
            "iteration 10905 : loss : 0.101312, loss_ce: 0.040576 loss_dice: 0.141802\n",
            "iteration 10906 : loss : 0.083851, loss_ce: 0.019790 loss_dice: 0.126559\n",
            "iteration 10907 : loss : 0.131006, loss_ce: 0.028209 loss_dice: 0.199537\n",
            "iteration 10908 : loss : 0.092946, loss_ce: 0.033102 loss_dice: 0.132842\n",
            "iteration 10909 : loss : 0.316539, loss_ce: 0.016270 loss_dice: 0.516719\n",
            "iteration 10910 : loss : 0.166242, loss_ce: 0.038247 loss_dice: 0.251572\n",
            "iteration 10911 : loss : 0.153907, loss_ce: 0.028796 loss_dice: 0.237314\n",
            "iteration 10912 : loss : 0.148240, loss_ce: 0.054390 loss_dice: 0.210806\n",
            "iteration 10913 : loss : 0.152501, loss_ce: 0.017953 loss_dice: 0.242200\n",
            "iteration 10914 : loss : 0.082240, loss_ce: 0.036542 loss_dice: 0.112706\n",
            "iteration 10915 : loss : 0.122530, loss_ce: 0.030668 loss_dice: 0.183771\n",
            "iteration 10916 : loss : 0.153290, loss_ce: 0.039779 loss_dice: 0.228963\n",
            "iteration 10917 : loss : 0.137462, loss_ce: 0.032624 loss_dice: 0.207353\n",
            "iteration 10918 : loss : 0.096981, loss_ce: 0.030001 loss_dice: 0.141634\n",
            "iteration 10919 : loss : 0.206225, loss_ce: 0.010637 loss_dice: 0.336616\n",
            "iteration 10920 : loss : 0.098954, loss_ce: 0.033769 loss_dice: 0.142410\n",
            "iteration 10921 : loss : 0.082907, loss_ce: 0.028428 loss_dice: 0.119227\n",
            "iteration 10922 : loss : 0.101365, loss_ce: 0.008972 loss_dice: 0.162961\n",
            "iteration 10923 : loss : 0.088979, loss_ce: 0.018043 loss_dice: 0.136269\n",
            "iteration 10924 : loss : 0.139248, loss_ce: 0.032287 loss_dice: 0.210555\n",
            "iteration 10925 : loss : 0.078172, loss_ce: 0.016984 loss_dice: 0.118964\n",
            "iteration 10926 : loss : 0.074807, loss_ce: 0.030761 loss_dice: 0.104172\n",
            "iteration 10927 : loss : 0.070522, loss_ce: 0.026219 loss_dice: 0.100058\n",
            "iteration 10928 : loss : 0.088080, loss_ce: 0.023789 loss_dice: 0.130941\n",
            "iteration 10929 : loss : 0.162416, loss_ce: 0.023176 loss_dice: 0.255242\n",
            "iteration 10930 : loss : 0.068492, loss_ce: 0.022506 loss_dice: 0.099150\n",
            "iteration 10931 : loss : 0.067547, loss_ce: 0.012959 loss_dice: 0.103939\n",
            "iteration 10932 : loss : 0.072176, loss_ce: 0.013651 loss_dice: 0.111192\n",
            "iteration 10933 : loss : 0.090657, loss_ce: 0.037695 loss_dice: 0.125964\n",
            "iteration 10934 : loss : 0.070470, loss_ce: 0.020504 loss_dice: 0.103781\n",
            "iteration 10935 : loss : 0.186555, loss_ce: 0.023627 loss_dice: 0.295173\n",
            "iteration 10936 : loss : 0.097206, loss_ce: 0.029900 loss_dice: 0.142077\n",
            "iteration 10937 : loss : 0.070810, loss_ce: 0.021037 loss_dice: 0.103993\n",
            "iteration 10938 : loss : 0.117905, loss_ce: 0.030673 loss_dice: 0.176060\n",
            "iteration 10939 : loss : 0.055617, loss_ce: 0.013945 loss_dice: 0.083398\n",
            "iteration 10940 : loss : 0.209539, loss_ce: 0.025184 loss_dice: 0.332443\n",
            "iteration 10941 : loss : 0.149053, loss_ce: 0.033748 loss_dice: 0.225922\n",
            "iteration 10942 : loss : 0.143004, loss_ce: 0.026653 loss_dice: 0.220571\n",
            "iteration 10943 : loss : 0.131464, loss_ce: 0.019082 loss_dice: 0.206386\n",
            "iteration 10944 : loss : 0.202567, loss_ce: 0.016334 loss_dice: 0.326723\n",
            "iteration 10945 : loss : 0.213517, loss_ce: 0.009603 loss_dice: 0.349460\n",
            "iteration 10946 : loss : 0.073171, loss_ce: 0.031755 loss_dice: 0.100782\n",
            "iteration 10947 : loss : 0.161393, loss_ce: 0.028825 loss_dice: 0.249771\n",
            "iteration 10948 : loss : 0.154330, loss_ce: 0.035731 loss_dice: 0.233395\n",
            "iteration 10949 : loss : 0.158655, loss_ce: 0.085174 loss_dice: 0.207642\n",
            "iteration 10950 : loss : 0.163062, loss_ce: 0.034070 loss_dice: 0.249057\n",
            "iteration 10951 : loss : 0.186356, loss_ce: 0.060615 loss_dice: 0.270183\n",
            "iteration 10952 : loss : 0.151450, loss_ce: 0.035845 loss_dice: 0.228520\n",
            "iteration 10953 : loss : 0.208437, loss_ce: 0.062418 loss_dice: 0.305783\n",
            "iteration 10954 : loss : 0.163457, loss_ce: 0.018821 loss_dice: 0.259881\n",
            "iteration 10955 : loss : 0.147623, loss_ce: 0.041312 loss_dice: 0.218498\n",
            "iteration 10956 : loss : 0.351087, loss_ce: 0.005728 loss_dice: 0.581326\n",
            "iteration 10957 : loss : 0.151640, loss_ce: 0.019727 loss_dice: 0.239583\n",
            "iteration 10958 : loss : 0.107762, loss_ce: 0.016877 loss_dice: 0.168352\n",
            "iteration 10959 : loss : 0.162759, loss_ce: 0.010583 loss_dice: 0.264210\n",
            "iteration 10960 : loss : 0.064195, loss_ce: 0.015722 loss_dice: 0.096511\n",
            "iteration 10961 : loss : 0.123041, loss_ce: 0.055944 loss_dice: 0.167772\n",
            "iteration 10962 : loss : 0.129693, loss_ce: 0.011757 loss_dice: 0.208317\n",
            "iteration 10963 : loss : 0.201057, loss_ce: 0.020363 loss_dice: 0.321519\n",
            "iteration 10964 : loss : 0.062834, loss_ce: 0.023815 loss_dice: 0.088846\n",
            "iteration 10965 : loss : 0.064006, loss_ce: 0.021957 loss_dice: 0.092039\n",
            "iteration 10966 : loss : 0.274027, loss_ce: 0.017837 loss_dice: 0.444821\n",
            "iteration 10967 : loss : 0.309532, loss_ce: 0.005250 loss_dice: 0.512387\n",
            "iteration 10968 : loss : 0.131587, loss_ce: 0.029452 loss_dice: 0.199678\n",
            "iteration 10969 : loss : 0.141313, loss_ce: 0.030679 loss_dice: 0.215069\n",
            "iteration 10970 : loss : 0.100826, loss_ce: 0.027253 loss_dice: 0.149875\n",
            "iteration 10971 : loss : 0.079021, loss_ce: 0.040351 loss_dice: 0.104802\n",
            "iteration 10972 : loss : 0.120290, loss_ce: 0.011482 loss_dice: 0.192829\n",
            "iteration 10973 : loss : 0.149042, loss_ce: 0.017077 loss_dice: 0.237018\n",
            "iteration 10974 : loss : 0.273182, loss_ce: 0.007751 loss_dice: 0.450137\n",
            "iteration 10975 : loss : 0.129844, loss_ce: 0.016473 loss_dice: 0.205425\n",
            "iteration 10976 : loss : 0.127207, loss_ce: 0.034888 loss_dice: 0.188753\n",
            "iteration 10977 : loss : 0.110351, loss_ce: 0.020280 loss_dice: 0.170399\n",
            "iteration 10978 : loss : 0.152821, loss_ce: 0.043698 loss_dice: 0.225570\n",
            "iteration 10979 : loss : 0.183885, loss_ce: 0.008795 loss_dice: 0.300611\n",
            "iteration 10980 : loss : 0.152765, loss_ce: 0.034256 loss_dice: 0.231771\n",
            "iteration 10981 : loss : 0.235363, loss_ce: 0.063154 loss_dice: 0.350169\n",
            "iteration 10982 : loss : 0.091184, loss_ce: 0.027938 loss_dice: 0.133348\n",
            "iteration 10983 : loss : 0.180663, loss_ce: 0.021453 loss_dice: 0.286803\n",
            "iteration 10984 : loss : 0.135026, loss_ce: 0.030286 loss_dice: 0.204853\n",
            "iteration 10985 : loss : 0.097945, loss_ce: 0.027995 loss_dice: 0.144578\n",
            "iteration 10986 : loss : 0.075818, loss_ce: 0.026652 loss_dice: 0.108595\n",
            "iteration 10987 : loss : 0.086578, loss_ce: 0.026943 loss_dice: 0.126334\n",
            "iteration 10988 : loss : 0.133788, loss_ce: 0.037262 loss_dice: 0.198138\n",
            "iteration 10989 : loss : 0.178324, loss_ce: 0.030296 loss_dice: 0.277010\n",
            "iteration 10990 : loss : 0.148853, loss_ce: 0.028915 loss_dice: 0.228811\n",
            "iteration 10991 : loss : 0.089202, loss_ce: 0.045399 loss_dice: 0.118403\n",
            "iteration 10992 : loss : 0.130951, loss_ce: 0.020683 loss_dice: 0.204462\n",
            "iteration 10993 : loss : 0.122270, loss_ce: 0.046703 loss_dice: 0.172648\n",
            "iteration 10994 : loss : 0.121305, loss_ce: 0.027343 loss_dice: 0.183946\n",
            "iteration 10995 : loss : 0.123755, loss_ce: 0.034421 loss_dice: 0.183311\n",
            "iteration 10996 : loss : 0.123072, loss_ce: 0.016311 loss_dice: 0.194247\n",
            "iteration 10997 : loss : 0.075063, loss_ce: 0.019884 loss_dice: 0.111850\n",
            "iteration 10998 : loss : 0.084106, loss_ce: 0.035837 loss_dice: 0.116286\n",
            "iteration 10999 : loss : 0.156221, loss_ce: 0.025480 loss_dice: 0.243381\n",
            "iteration 11000 : loss : 0.143657, loss_ce: 0.028786 loss_dice: 0.220238\n",
            "iteration 11001 : loss : 0.123652, loss_ce: 0.020850 loss_dice: 0.192187\n",
            "iteration 11002 : loss : 0.131321, loss_ce: 0.056356 loss_dice: 0.181298\n",
            "iteration 11003 : loss : 0.226650, loss_ce: 0.020081 loss_dice: 0.364363\n",
            "iteration 11004 : loss : 0.116111, loss_ce: 0.009738 loss_dice: 0.187027\n",
            "iteration 11005 : loss : 0.132092, loss_ce: 0.028703 loss_dice: 0.201017\n",
            "iteration 11006 : loss : 0.109957, loss_ce: 0.019017 loss_dice: 0.170584\n",
            "iteration 11007 : loss : 0.126039, loss_ce: 0.013793 loss_dice: 0.200870\n",
            "iteration 11008 : loss : 0.056718, loss_ce: 0.016880 loss_dice: 0.083277\n",
            "iteration 11009 : loss : 0.351650, loss_ce: 0.001889 loss_dice: 0.584823\n",
            "iteration 11010 : loss : 0.134709, loss_ce: 0.020735 loss_dice: 0.210692\n",
            "iteration 11011 : loss : 0.133679, loss_ce: 0.030354 loss_dice: 0.202563\n",
            "iteration 11012 : loss : 0.130731, loss_ce: 0.030692 loss_dice: 0.197423\n",
            "iteration 11013 : loss : 0.115255, loss_ce: 0.031711 loss_dice: 0.170952\n",
            "iteration 11014 : loss : 0.096641, loss_ce: 0.027852 loss_dice: 0.142500\n",
            "iteration 11015 : loss : 0.088950, loss_ce: 0.022193 loss_dice: 0.133455\n",
            "iteration 11016 : loss : 0.177514, loss_ce: 0.016126 loss_dice: 0.285107\n",
            "iteration 11017 : loss : 0.078630, loss_ce: 0.034814 loss_dice: 0.107840\n",
            "iteration 11018 : loss : 0.150231, loss_ce: 0.034865 loss_dice: 0.227142\n",
            "iteration 11019 : loss : 0.107804, loss_ce: 0.015603 loss_dice: 0.169271\n",
            "iteration 11020 : loss : 0.150365, loss_ce: 0.026793 loss_dice: 0.232746\n",
            "iteration 11021 : loss : 0.200095, loss_ce: 0.006608 loss_dice: 0.329087\n",
            "iteration 11022 : loss : 0.115971, loss_ce: 0.036294 loss_dice: 0.169090\n",
            "iteration 11023 : loss : 0.066646, loss_ce: 0.017807 loss_dice: 0.099205\n",
            "iteration 11024 : loss : 0.099025, loss_ce: 0.018154 loss_dice: 0.152939\n",
            "iteration 11025 : loss : 0.196207, loss_ce: 0.020225 loss_dice: 0.313528\n",
            "iteration 11026 : loss : 0.165484, loss_ce: 0.007087 loss_dice: 0.271082\n",
            "iteration 11027 : loss : 0.096293, loss_ce: 0.028799 loss_dice: 0.141289\n",
            "iteration 11028 : loss : 0.085893, loss_ce: 0.022230 loss_dice: 0.128335\n",
            "iteration 11029 : loss : 0.185122, loss_ce: 0.051015 loss_dice: 0.274526\n",
            "iteration 11030 : loss : 0.134025, loss_ce: 0.028105 loss_dice: 0.204638\n",
            "iteration 11031 : loss : 0.089027, loss_ce: 0.036954 loss_dice: 0.123742\n",
            "iteration 11032 : loss : 0.091998, loss_ce: 0.019372 loss_dice: 0.140415\n",
            "iteration 11033 : loss : 0.088314, loss_ce: 0.026280 loss_dice: 0.129670\n",
            "iteration 11034 : loss : 0.281648, loss_ce: 0.012406 loss_dice: 0.461143\n",
            "iteration 11035 : loss : 0.094869, loss_ce: 0.040098 loss_dice: 0.131383\n",
            "iteration 11036 : loss : 0.111270, loss_ce: 0.035725 loss_dice: 0.161634\n",
            "iteration 11037 : loss : 0.121121, loss_ce: 0.027086 loss_dice: 0.183811\n",
            "iteration 11038 : loss : 0.118996, loss_ce: 0.022630 loss_dice: 0.183239\n",
            "iteration 11039 : loss : 0.161538, loss_ce: 0.039798 loss_dice: 0.242698\n",
            "iteration 11040 : loss : 0.113684, loss_ce: 0.036045 loss_dice: 0.165444\n",
            "iteration 11041 : loss : 0.136574, loss_ce: 0.016317 loss_dice: 0.216745\n",
            "iteration 11042 : loss : 0.153784, loss_ce: 0.025361 loss_dice: 0.239398\n",
            "iteration 11043 : loss : 0.140620, loss_ce: 0.049142 loss_dice: 0.201606\n",
            "iteration 11044 : loss : 0.087538, loss_ce: 0.049861 loss_dice: 0.112656\n",
            "iteration 11045 : loss : 0.128939, loss_ce: 0.016236 loss_dice: 0.204074\n",
            "iteration 11046 : loss : 0.122387, loss_ce: 0.018279 loss_dice: 0.191793\n",
            "iteration 11047 : loss : 0.134256, loss_ce: 0.016665 loss_dice: 0.212650\n",
            "iteration 11048 : loss : 0.092956, loss_ce: 0.043544 loss_dice: 0.125897\n",
            "iteration 11049 : loss : 0.289956, loss_ce: 0.013035 loss_dice: 0.474571\n",
            "iteration 11050 : loss : 0.110528, loss_ce: 0.023310 loss_dice: 0.168674\n",
            "iteration 11051 : loss : 0.096431, loss_ce: 0.039489 loss_dice: 0.134392\n",
            "iteration 11052 : loss : 0.089065, loss_ce: 0.035955 loss_dice: 0.124472\n",
            "iteration 11053 : loss : 0.102464, loss_ce: 0.044256 loss_dice: 0.141269\n",
            "iteration 11054 : loss : 0.137065, loss_ce: 0.037194 loss_dice: 0.203646\n",
            "iteration 11055 : loss : 0.155195, loss_ce: 0.046145 loss_dice: 0.227895\n",
            "iteration 11056 : loss : 0.180508, loss_ce: 0.054049 loss_dice: 0.264815\n",
            "iteration 11057 : loss : 0.170084, loss_ce: 0.038809 loss_dice: 0.257601\n",
            "iteration 11058 : loss : 0.151440, loss_ce: 0.042327 loss_dice: 0.224182\n",
            "iteration 11059 : loss : 0.113242, loss_ce: 0.032241 loss_dice: 0.167242\n",
            "iteration 11060 : loss : 0.142799, loss_ce: 0.020018 loss_dice: 0.224652\n",
            "iteration 11061 : loss : 0.112707, loss_ce: 0.012174 loss_dice: 0.179730\n",
            "iteration 11062 : loss : 0.156490, loss_ce: 0.055205 loss_dice: 0.224014\n",
            "iteration 11063 : loss : 0.115148, loss_ce: 0.036642 loss_dice: 0.167486\n",
            "iteration 11064 : loss : 0.086882, loss_ce: 0.011752 loss_dice: 0.136968\n",
            "iteration 11065 : loss : 0.172642, loss_ce: 0.033816 loss_dice: 0.265192\n",
            "iteration 11066 : loss : 0.158101, loss_ce: 0.041628 loss_dice: 0.235750\n",
            "iteration 11067 : loss : 0.196733, loss_ce: 0.075905 loss_dice: 0.277285\n",
            "iteration 11068 : loss : 0.180040, loss_ce: 0.049316 loss_dice: 0.267190\n",
            "iteration 11069 : loss : 0.159902, loss_ce: 0.031446 loss_dice: 0.245540\n",
            "iteration 11070 : loss : 0.087347, loss_ce: 0.029728 loss_dice: 0.125759\n",
            "iteration 11071 : loss : 0.115628, loss_ce: 0.022186 loss_dice: 0.177923\n",
            "iteration 11072 : loss : 0.113955, loss_ce: 0.038164 loss_dice: 0.164483\n",
            "iteration 11073 : loss : 0.158835, loss_ce: 0.025259 loss_dice: 0.247885\n",
            "iteration 11074 : loss : 0.257196, loss_ce: 0.029411 loss_dice: 0.409052\n",
            "iteration 11075 : loss : 0.145519, loss_ce: 0.025212 loss_dice: 0.225723\n",
            "iteration 11076 : loss : 0.134261, loss_ce: 0.044527 loss_dice: 0.194084\n",
            "iteration 11077 : loss : 0.097680, loss_ce: 0.016313 loss_dice: 0.151925\n",
            "iteration 11078 : loss : 0.208603, loss_ce: 0.036474 loss_dice: 0.323355\n",
            "iteration 11079 : loss : 0.099880, loss_ce: 0.037854 loss_dice: 0.141231\n",
            "iteration 11080 : loss : 0.130518, loss_ce: 0.027688 loss_dice: 0.199071\n",
            "iteration 11081 : loss : 0.131631, loss_ce: 0.021288 loss_dice: 0.205194\n",
            "iteration 11082 : loss : 0.180812, loss_ce: 0.039602 loss_dice: 0.274953\n",
            "iteration 11083 : loss : 0.131592, loss_ce: 0.052735 loss_dice: 0.184163\n",
            "iteration 11084 : loss : 0.096999, loss_ce: 0.018729 loss_dice: 0.149180\n",
            "iteration 11085 : loss : 0.165551, loss_ce: 0.031493 loss_dice: 0.254923\n",
            "iteration 11086 : loss : 0.120591, loss_ce: 0.044660 loss_dice: 0.171211\n",
            "iteration 11087 : loss : 0.174064, loss_ce: 0.021920 loss_dice: 0.275494\n",
            "iteration 11088 : loss : 0.150223, loss_ce: 0.017484 loss_dice: 0.238716\n",
            "iteration 11089 : loss : 0.189829, loss_ce: 0.023131 loss_dice: 0.300962\n",
            "iteration 11090 : loss : 0.124438, loss_ce: 0.019362 loss_dice: 0.194488\n",
            "iteration 11091 : loss : 0.142435, loss_ce: 0.031154 loss_dice: 0.216622\n",
            "iteration 11092 : loss : 0.106758, loss_ce: 0.029626 loss_dice: 0.158179\n",
            "iteration 11093 : loss : 0.086232, loss_ce: 0.029431 loss_dice: 0.124099\n",
            "iteration 11094 : loss : 0.129606, loss_ce: 0.020515 loss_dice: 0.202334\n",
            "iteration 11095 : loss : 0.192695, loss_ce: 0.018862 loss_dice: 0.308584\n",
            "iteration 11096 : loss : 0.100156, loss_ce: 0.031540 loss_dice: 0.145900\n",
            "iteration 11097 : loss : 0.298425, loss_ce: 0.003574 loss_dice: 0.494993\n",
            "iteration 11098 : loss : 0.121647, loss_ce: 0.042902 loss_dice: 0.174144\n",
            "iteration 11099 : loss : 0.225043, loss_ce: 0.006780 loss_dice: 0.370551\n",
            "iteration 11100 : loss : 0.168522, loss_ce: 0.049182 loss_dice: 0.248082\n",
            " 10%|██▋                        | 50/500 [1:56:33<11:51:53, 94.92s/it]iteration 11101 : loss : 0.162351, loss_ce: 0.018038 loss_dice: 0.258560\n",
            "iteration 11102 : loss : 0.141302, loss_ce: 0.018341 loss_dice: 0.223275\n",
            "iteration 11103 : loss : 0.124523, loss_ce: 0.032762 loss_dice: 0.185697\n",
            "iteration 11104 : loss : 0.170094, loss_ce: 0.010738 loss_dice: 0.276331\n",
            "iteration 11105 : loss : 0.163194, loss_ce: 0.024199 loss_dice: 0.255857\n",
            "iteration 11106 : loss : 0.113922, loss_ce: 0.040048 loss_dice: 0.163172\n",
            "iteration 11107 : loss : 0.100795, loss_ce: 0.031108 loss_dice: 0.147252\n",
            "iteration 11108 : loss : 0.113562, loss_ce: 0.033571 loss_dice: 0.166889\n",
            "iteration 11109 : loss : 0.091409, loss_ce: 0.036943 loss_dice: 0.127720\n",
            "iteration 11110 : loss : 0.116584, loss_ce: 0.032518 loss_dice: 0.172628\n",
            "iteration 11111 : loss : 0.197091, loss_ce: 0.019059 loss_dice: 0.315779\n",
            "iteration 11112 : loss : 0.149893, loss_ce: 0.027795 loss_dice: 0.231292\n",
            "iteration 11113 : loss : 0.261282, loss_ce: 0.021099 loss_dice: 0.421404\n",
            "iteration 11114 : loss : 0.071441, loss_ce: 0.025323 loss_dice: 0.102185\n",
            "iteration 11115 : loss : 0.113407, loss_ce: 0.024609 loss_dice: 0.172605\n",
            "iteration 11116 : loss : 0.112890, loss_ce: 0.027054 loss_dice: 0.170114\n",
            "iteration 11117 : loss : 0.092044, loss_ce: 0.050037 loss_dice: 0.120048\n",
            "iteration 11118 : loss : 0.084252, loss_ce: 0.018271 loss_dice: 0.128239\n",
            "iteration 11119 : loss : 0.137170, loss_ce: 0.016393 loss_dice: 0.217688\n",
            "iteration 11120 : loss : 0.132982, loss_ce: 0.016203 loss_dice: 0.210835\n",
            "iteration 11121 : loss : 0.079160, loss_ce: 0.027562 loss_dice: 0.113559\n",
            "iteration 11122 : loss : 0.139424, loss_ce: 0.021937 loss_dice: 0.217749\n",
            "iteration 11123 : loss : 0.141758, loss_ce: 0.022271 loss_dice: 0.221415\n",
            "iteration 11124 : loss : 0.307659, loss_ce: 0.000718 loss_dice: 0.512287\n",
            "iteration 11125 : loss : 0.122299, loss_ce: 0.016951 loss_dice: 0.192530\n",
            "iteration 11126 : loss : 0.138787, loss_ce: 0.033792 loss_dice: 0.208784\n",
            "iteration 11127 : loss : 0.319672, loss_ce: 0.000976 loss_dice: 0.532135\n",
            "iteration 11128 : loss : 0.093857, loss_ce: 0.026426 loss_dice: 0.138811\n",
            "iteration 11129 : loss : 0.077526, loss_ce: 0.029344 loss_dice: 0.109647\n",
            "iteration 11130 : loss : 0.240242, loss_ce: 0.015290 loss_dice: 0.390210\n",
            "iteration 11131 : loss : 0.190419, loss_ce: 0.034985 loss_dice: 0.294041\n",
            "iteration 11132 : loss : 0.117608, loss_ce: 0.019570 loss_dice: 0.182966\n",
            "iteration 11133 : loss : 0.236770, loss_ce: 0.004911 loss_dice: 0.391343\n",
            "iteration 11134 : loss : 0.064575, loss_ce: 0.014283 loss_dice: 0.098103\n",
            "iteration 11135 : loss : 0.238231, loss_ce: 0.023702 loss_dice: 0.381249\n",
            "iteration 11136 : loss : 0.135120, loss_ce: 0.060466 loss_dice: 0.184889\n",
            "iteration 11137 : loss : 0.107597, loss_ce: 0.026954 loss_dice: 0.161360\n",
            "iteration 11138 : loss : 0.145305, loss_ce: 0.012133 loss_dice: 0.234086\n",
            "iteration 11139 : loss : 0.109165, loss_ce: 0.053093 loss_dice: 0.146546\n",
            "iteration 11140 : loss : 0.137030, loss_ce: 0.026895 loss_dice: 0.210453\n",
            "iteration 11141 : loss : 0.081904, loss_ce: 0.024349 loss_dice: 0.120274\n",
            "iteration 11142 : loss : 0.090300, loss_ce: 0.029314 loss_dice: 0.130958\n",
            "iteration 11143 : loss : 0.089170, loss_ce: 0.026519 loss_dice: 0.130937\n",
            "iteration 11144 : loss : 0.195822, loss_ce: 0.031566 loss_dice: 0.305327\n",
            "iteration 11145 : loss : 0.097916, loss_ce: 0.020855 loss_dice: 0.149290\n",
            "iteration 11146 : loss : 0.179621, loss_ce: 0.036031 loss_dice: 0.275348\n",
            "iteration 11147 : loss : 0.159489, loss_ce: 0.041277 loss_dice: 0.238297\n",
            "iteration 11148 : loss : 0.120630, loss_ce: 0.041169 loss_dice: 0.173604\n",
            "iteration 11149 : loss : 0.154960, loss_ce: 0.045659 loss_dice: 0.227828\n",
            "iteration 11150 : loss : 0.142144, loss_ce: 0.028907 loss_dice: 0.217636\n",
            "iteration 11151 : loss : 0.124332, loss_ce: 0.036578 loss_dice: 0.182834\n",
            "iteration 11152 : loss : 0.190682, loss_ce: 0.012044 loss_dice: 0.309774\n",
            "iteration 11153 : loss : 0.071120, loss_ce: 0.025278 loss_dice: 0.101682\n",
            "iteration 11154 : loss : 0.168139, loss_ce: 0.028596 loss_dice: 0.261167\n",
            "iteration 11155 : loss : 0.148884, loss_ce: 0.044628 loss_dice: 0.218387\n",
            "iteration 11156 : loss : 0.120669, loss_ce: 0.022445 loss_dice: 0.186152\n",
            "iteration 11157 : loss : 0.187686, loss_ce: 0.077553 loss_dice: 0.261108\n",
            "iteration 11158 : loss : 0.212796, loss_ce: 0.026165 loss_dice: 0.337216\n",
            "iteration 11159 : loss : 0.203804, loss_ce: 0.048733 loss_dice: 0.307185\n",
            "iteration 11160 : loss : 0.157273, loss_ce: 0.030179 loss_dice: 0.242003\n",
            "iteration 11161 : loss : 0.141854, loss_ce: 0.038315 loss_dice: 0.210879\n",
            "iteration 11162 : loss : 0.137289, loss_ce: 0.023396 loss_dice: 0.213217\n",
            "iteration 11163 : loss : 0.250500, loss_ce: 0.019931 loss_dice: 0.404213\n",
            "iteration 11164 : loss : 0.141476, loss_ce: 0.038991 loss_dice: 0.209799\n",
            "iteration 11165 : loss : 0.098696, loss_ce: 0.034629 loss_dice: 0.141407\n",
            "iteration 11166 : loss : 0.222671, loss_ce: 0.017594 loss_dice: 0.359389\n",
            "iteration 11167 : loss : 0.122504, loss_ce: 0.031777 loss_dice: 0.182988\n",
            "iteration 11168 : loss : 0.117988, loss_ce: 0.031352 loss_dice: 0.175746\n",
            "iteration 11169 : loss : 0.078489, loss_ce: 0.016636 loss_dice: 0.119724\n",
            "iteration 11170 : loss : 0.098288, loss_ce: 0.028051 loss_dice: 0.145113\n",
            "iteration 11171 : loss : 0.130727, loss_ce: 0.028436 loss_dice: 0.198921\n",
            "iteration 11172 : loss : 0.144514, loss_ce: 0.040260 loss_dice: 0.214016\n",
            "iteration 11173 : loss : 0.165258, loss_ce: 0.029882 loss_dice: 0.255510\n",
            "iteration 11174 : loss : 0.162340, loss_ce: 0.043764 loss_dice: 0.241391\n",
            "iteration 11175 : loss : 0.179834, loss_ce: 0.071811 loss_dice: 0.251849\n",
            "iteration 11176 : loss : 0.161879, loss_ce: 0.047466 loss_dice: 0.238154\n",
            "iteration 11177 : loss : 0.170219, loss_ce: 0.061873 loss_dice: 0.242450\n",
            "iteration 11178 : loss : 0.130973, loss_ce: 0.048497 loss_dice: 0.185956\n",
            "iteration 11179 : loss : 0.136539, loss_ce: 0.031620 loss_dice: 0.206484\n",
            "iteration 11180 : loss : 0.061853, loss_ce: 0.015699 loss_dice: 0.092623\n",
            "iteration 11181 : loss : 0.170464, loss_ce: 0.067015 loss_dice: 0.239430\n",
            "iteration 11182 : loss : 0.156370, loss_ce: 0.051784 loss_dice: 0.226095\n",
            "iteration 11183 : loss : 0.117793, loss_ce: 0.024399 loss_dice: 0.180056\n",
            "iteration 11184 : loss : 0.091316, loss_ce: 0.030918 loss_dice: 0.131580\n",
            "iteration 11185 : loss : 0.129221, loss_ce: 0.028715 loss_dice: 0.196225\n",
            "iteration 11186 : loss : 0.075096, loss_ce: 0.023267 loss_dice: 0.109649\n",
            "iteration 11187 : loss : 0.132491, loss_ce: 0.044400 loss_dice: 0.191219\n",
            "iteration 11188 : loss : 0.191653, loss_ce: 0.052507 loss_dice: 0.284418\n",
            "iteration 11189 : loss : 0.214019, loss_ce: 0.054300 loss_dice: 0.320499\n",
            "iteration 11190 : loss : 0.162053, loss_ce: 0.054316 loss_dice: 0.233877\n",
            "iteration 11191 : loss : 0.157345, loss_ce: 0.037567 loss_dice: 0.237197\n",
            "iteration 11192 : loss : 0.179649, loss_ce: 0.048452 loss_dice: 0.267113\n",
            "iteration 11193 : loss : 0.072207, loss_ce: 0.032226 loss_dice: 0.098861\n",
            "iteration 11194 : loss : 0.156742, loss_ce: 0.088007 loss_dice: 0.202566\n",
            "iteration 11195 : loss : 0.151682, loss_ce: 0.024759 loss_dice: 0.236298\n",
            "iteration 11196 : loss : 0.143745, loss_ce: 0.031147 loss_dice: 0.218811\n",
            "iteration 11197 : loss : 0.139870, loss_ce: 0.026200 loss_dice: 0.215650\n",
            "iteration 11198 : loss : 0.169820, loss_ce: 0.056943 loss_dice: 0.245071\n",
            "iteration 11199 : loss : 0.158240, loss_ce: 0.073385 loss_dice: 0.214810\n",
            "iteration 11200 : loss : 0.132468, loss_ce: 0.023715 loss_dice: 0.204971\n",
            "iteration 11201 : loss : 0.215861, loss_ce: 0.026664 loss_dice: 0.341992\n",
            "iteration 11202 : loss : 0.147107, loss_ce: 0.015644 loss_dice: 0.234749\n",
            "iteration 11203 : loss : 0.126431, loss_ce: 0.014145 loss_dice: 0.201289\n",
            "iteration 11204 : loss : 0.247255, loss_ce: 0.033820 loss_dice: 0.389546\n",
            "iteration 11205 : loss : 0.132818, loss_ce: 0.023216 loss_dice: 0.205886\n",
            "iteration 11206 : loss : 0.077679, loss_ce: 0.021514 loss_dice: 0.115122\n",
            "iteration 11207 : loss : 0.112161, loss_ce: 0.023715 loss_dice: 0.171125\n",
            "iteration 11208 : loss : 0.170404, loss_ce: 0.043180 loss_dice: 0.255220\n",
            "iteration 11209 : loss : 0.129691, loss_ce: 0.032630 loss_dice: 0.194398\n",
            "iteration 11210 : loss : 0.084451, loss_ce: 0.019493 loss_dice: 0.127756\n",
            "iteration 11211 : loss : 0.117289, loss_ce: 0.017340 loss_dice: 0.183922\n",
            "iteration 11212 : loss : 0.134757, loss_ce: 0.012722 loss_dice: 0.216114\n",
            "iteration 11213 : loss : 0.136010, loss_ce: 0.022853 loss_dice: 0.211448\n",
            "iteration 11214 : loss : 0.184231, loss_ce: 0.020352 loss_dice: 0.293483\n",
            "iteration 11215 : loss : 0.206852, loss_ce: 0.015958 loss_dice: 0.334114\n",
            "iteration 11216 : loss : 0.120891, loss_ce: 0.048641 loss_dice: 0.169058\n",
            "iteration 11217 : loss : 0.094901, loss_ce: 0.021583 loss_dice: 0.143780\n",
            "iteration 11218 : loss : 0.124218, loss_ce: 0.022240 loss_dice: 0.192204\n",
            "iteration 11219 : loss : 0.155831, loss_ce: 0.037996 loss_dice: 0.234388\n",
            "iteration 11220 : loss : 0.133066, loss_ce: 0.046162 loss_dice: 0.191002\n",
            "iteration 11221 : loss : 0.124963, loss_ce: 0.028043 loss_dice: 0.189576\n",
            "iteration 11222 : loss : 0.145130, loss_ce: 0.020278 loss_dice: 0.228365\n",
            "iteration 11223 : loss : 0.121480, loss_ce: 0.048697 loss_dice: 0.170003\n",
            "iteration 11224 : loss : 0.122638, loss_ce: 0.038635 loss_dice: 0.178641\n",
            "iteration 11225 : loss : 0.109887, loss_ce: 0.039715 loss_dice: 0.156669\n",
            "iteration 11226 : loss : 0.183148, loss_ce: 0.023849 loss_dice: 0.289347\n",
            "iteration 11227 : loss : 0.068003, loss_ce: 0.016949 loss_dice: 0.102039\n",
            "iteration 11228 : loss : 0.143246, loss_ce: 0.025400 loss_dice: 0.221810\n",
            "iteration 11229 : loss : 0.121888, loss_ce: 0.015480 loss_dice: 0.192827\n",
            "iteration 11230 : loss : 0.092503, loss_ce: 0.031396 loss_dice: 0.133241\n",
            "iteration 11231 : loss : 0.068791, loss_ce: 0.014368 loss_dice: 0.105073\n",
            "iteration 11232 : loss : 0.162658, loss_ce: 0.022222 loss_dice: 0.256282\n",
            "iteration 11233 : loss : 0.107091, loss_ce: 0.038575 loss_dice: 0.152768\n",
            "iteration 11234 : loss : 0.137021, loss_ce: 0.008739 loss_dice: 0.222543\n",
            "iteration 11235 : loss : 0.219086, loss_ce: 0.048383 loss_dice: 0.332888\n",
            "iteration 11236 : loss : 0.140830, loss_ce: 0.022108 loss_dice: 0.219978\n",
            "iteration 11237 : loss : 0.276105, loss_ce: 0.013933 loss_dice: 0.450887\n",
            "iteration 11238 : loss : 0.232331, loss_ce: 0.003636 loss_dice: 0.384794\n",
            "iteration 11239 : loss : 0.093606, loss_ce: 0.050522 loss_dice: 0.122329\n",
            "iteration 11240 : loss : 0.105346, loss_ce: 0.021976 loss_dice: 0.160926\n",
            "iteration 11241 : loss : 0.108129, loss_ce: 0.019209 loss_dice: 0.167408\n",
            "iteration 11242 : loss : 0.109154, loss_ce: 0.014458 loss_dice: 0.172285\n",
            "iteration 11243 : loss : 0.162771, loss_ce: 0.015550 loss_dice: 0.260917\n",
            "iteration 11244 : loss : 0.122059, loss_ce: 0.022083 loss_dice: 0.188710\n",
            "iteration 11245 : loss : 0.138843, loss_ce: 0.014529 loss_dice: 0.221719\n",
            "iteration 11246 : loss : 0.117140, loss_ce: 0.014979 loss_dice: 0.185247\n",
            "iteration 11247 : loss : 0.151853, loss_ce: 0.022558 loss_dice: 0.238050\n",
            "iteration 11248 : loss : 0.192995, loss_ce: 0.024690 loss_dice: 0.305199\n",
            "iteration 11249 : loss : 0.147177, loss_ce: 0.026033 loss_dice: 0.227940\n",
            "iteration 11250 : loss : 0.157953, loss_ce: 0.052375 loss_dice: 0.228339\n",
            "iteration 11251 : loss : 0.101847, loss_ce: 0.042447 loss_dice: 0.141447\n",
            "iteration 11252 : loss : 0.138248, loss_ce: 0.013306 loss_dice: 0.221543\n",
            "iteration 11253 : loss : 0.147743, loss_ce: 0.014369 loss_dice: 0.236659\n",
            "iteration 11254 : loss : 0.090812, loss_ce: 0.021289 loss_dice: 0.137161\n",
            "iteration 11255 : loss : 0.056591, loss_ce: 0.019223 loss_dice: 0.081503\n",
            "iteration 11256 : loss : 0.149013, loss_ce: 0.024670 loss_dice: 0.231909\n",
            "iteration 11257 : loss : 0.257044, loss_ce: 0.004092 loss_dice: 0.425679\n",
            "iteration 11258 : loss : 0.159302, loss_ce: 0.048849 loss_dice: 0.232937\n",
            "iteration 11259 : loss : 0.083610, loss_ce: 0.019882 loss_dice: 0.126096\n",
            "iteration 11260 : loss : 0.090056, loss_ce: 0.028020 loss_dice: 0.131412\n",
            "iteration 11261 : loss : 0.074840, loss_ce: 0.016998 loss_dice: 0.113402\n",
            "iteration 11262 : loss : 0.143202, loss_ce: 0.041739 loss_dice: 0.210844\n",
            "iteration 11263 : loss : 0.143254, loss_ce: 0.037968 loss_dice: 0.213444\n",
            "iteration 11264 : loss : 0.153642, loss_ce: 0.010275 loss_dice: 0.249221\n",
            "iteration 11265 : loss : 0.076616, loss_ce: 0.031166 loss_dice: 0.106917\n",
            "iteration 11266 : loss : 0.143532, loss_ce: 0.044184 loss_dice: 0.209763\n",
            "iteration 11267 : loss : 0.128249, loss_ce: 0.016745 loss_dice: 0.202585\n",
            "iteration 11268 : loss : 0.074464, loss_ce: 0.017010 loss_dice: 0.112766\n",
            "iteration 11269 : loss : 0.069388, loss_ce: 0.016933 loss_dice: 0.104358\n",
            "iteration 11270 : loss : 0.182559, loss_ce: 0.007628 loss_dice: 0.299179\n",
            "iteration 11271 : loss : 0.158164, loss_ce: 0.040095 loss_dice: 0.236877\n",
            "iteration 11272 : loss : 0.143739, loss_ce: 0.029905 loss_dice: 0.219629\n",
            "iteration 11273 : loss : 0.133665, loss_ce: 0.016071 loss_dice: 0.212061\n",
            "iteration 11274 : loss : 0.127554, loss_ce: 0.042371 loss_dice: 0.184342\n",
            "iteration 11275 : loss : 0.163240, loss_ce: 0.059654 loss_dice: 0.232297\n",
            "iteration 11276 : loss : 0.116775, loss_ce: 0.020924 loss_dice: 0.180675\n",
            "iteration 11277 : loss : 0.103480, loss_ce: 0.058643 loss_dice: 0.133372\n",
            "iteration 11278 : loss : 0.169679, loss_ce: 0.066197 loss_dice: 0.238667\n",
            "iteration 11279 : loss : 0.092430, loss_ce: 0.018744 loss_dice: 0.141554\n",
            "iteration 11280 : loss : 0.056525, loss_ce: 0.013420 loss_dice: 0.085261\n",
            "iteration 11281 : loss : 0.120032, loss_ce: 0.034166 loss_dice: 0.177277\n",
            "iteration 11282 : loss : 0.254457, loss_ce: 0.021900 loss_dice: 0.409495\n",
            "iteration 11283 : loss : 0.102048, loss_ce: 0.044490 loss_dice: 0.140419\n",
            "iteration 11284 : loss : 0.149974, loss_ce: 0.032048 loss_dice: 0.228592\n",
            "iteration 11285 : loss : 0.183810, loss_ce: 0.037228 loss_dice: 0.281531\n",
            "iteration 11286 : loss : 0.085491, loss_ce: 0.015489 loss_dice: 0.132159\n",
            "iteration 11287 : loss : 0.041832, loss_ce: 0.007716 loss_dice: 0.064576\n",
            "iteration 11288 : loss : 0.096654, loss_ce: 0.026164 loss_dice: 0.143647\n",
            "iteration 11289 : loss : 0.138960, loss_ce: 0.033267 loss_dice: 0.209422\n",
            "iteration 11290 : loss : 0.129191, loss_ce: 0.036572 loss_dice: 0.190936\n",
            "iteration 11291 : loss : 0.226219, loss_ce: 0.039964 loss_dice: 0.350389\n",
            "iteration 11292 : loss : 0.116064, loss_ce: 0.032610 loss_dice: 0.171700\n",
            "iteration 11293 : loss : 0.077886, loss_ce: 0.008829 loss_dice: 0.123923\n",
            "iteration 11294 : loss : 0.167435, loss_ce: 0.004947 loss_dice: 0.275760\n",
            "iteration 11295 : loss : 0.175875, loss_ce: 0.058288 loss_dice: 0.254267\n",
            "iteration 11296 : loss : 0.242636, loss_ce: 0.030281 loss_dice: 0.384206\n",
            "iteration 11297 : loss : 0.139458, loss_ce: 0.017192 loss_dice: 0.220968\n",
            "iteration 11298 : loss : 0.124798, loss_ce: 0.050848 loss_dice: 0.174099\n",
            "iteration 11299 : loss : 0.154257, loss_ce: 0.031149 loss_dice: 0.236329\n",
            "iteration 11300 : loss : 0.104948, loss_ce: 0.034613 loss_dice: 0.151839\n",
            "iteration 11301 : loss : 0.086667, loss_ce: 0.034398 loss_dice: 0.121513\n",
            "iteration 11302 : loss : 0.128655, loss_ce: 0.027064 loss_dice: 0.196382\n",
            "iteration 11303 : loss : 0.150274, loss_ce: 0.038380 loss_dice: 0.224869\n",
            "iteration 11304 : loss : 0.093268, loss_ce: 0.022460 loss_dice: 0.140474\n",
            "iteration 11305 : loss : 0.220606, loss_ce: 0.007575 loss_dice: 0.362627\n",
            "iteration 11306 : loss : 0.081871, loss_ce: 0.024783 loss_dice: 0.119930\n",
            "iteration 11307 : loss : 0.117118, loss_ce: 0.043051 loss_dice: 0.166496\n",
            "iteration 11308 : loss : 0.097032, loss_ce: 0.024653 loss_dice: 0.145286\n",
            "iteration 11309 : loss : 0.146893, loss_ce: 0.022348 loss_dice: 0.229924\n",
            "iteration 11310 : loss : 0.090841, loss_ce: 0.020438 loss_dice: 0.137776\n",
            "iteration 11311 : loss : 0.138114, loss_ce: 0.009176 loss_dice: 0.224073\n",
            "iteration 11312 : loss : 0.140349, loss_ce: 0.045353 loss_dice: 0.203679\n",
            "iteration 11313 : loss : 0.157871, loss_ce: 0.032020 loss_dice: 0.241772\n",
            "iteration 11314 : loss : 0.085387, loss_ce: 0.019818 loss_dice: 0.129100\n",
            "iteration 11315 : loss : 0.109859, loss_ce: 0.038607 loss_dice: 0.157360\n",
            "iteration 11316 : loss : 0.151776, loss_ce: 0.034016 loss_dice: 0.230283\n",
            "iteration 11317 : loss : 0.123205, loss_ce: 0.050514 loss_dice: 0.171666\n",
            "iteration 11318 : loss : 0.121387, loss_ce: 0.047301 loss_dice: 0.170777\n",
            "iteration 11319 : loss : 0.180975, loss_ce: 0.039515 loss_dice: 0.275281\n",
            "iteration 11320 : loss : 0.150703, loss_ce: 0.028705 loss_dice: 0.232034\n",
            "iteration 11321 : loss : 0.093337, loss_ce: 0.035218 loss_dice: 0.132083\n",
            "iteration 11322 : loss : 0.139398, loss_ce: 0.000101 loss_dice: 0.232263\n",
            " 10%|██▊                        | 51/500 [1:57:56<11:24:19, 91.45s/it]iteration 11323 : loss : 0.093924, loss_ce: 0.036274 loss_dice: 0.132357\n",
            "iteration 11324 : loss : 0.131729, loss_ce: 0.011456 loss_dice: 0.211912\n",
            "iteration 11325 : loss : 0.142096, loss_ce: 0.038967 loss_dice: 0.210848\n",
            "iteration 11326 : loss : 0.148638, loss_ce: 0.026385 loss_dice: 0.230139\n",
            "iteration 11327 : loss : 0.081579, loss_ce: 0.019259 loss_dice: 0.123126\n",
            "iteration 11328 : loss : 0.086903, loss_ce: 0.033544 loss_dice: 0.122476\n",
            "iteration 11329 : loss : 0.156693, loss_ce: 0.018682 loss_dice: 0.248701\n",
            "iteration 11330 : loss : 0.114345, loss_ce: 0.011078 loss_dice: 0.183189\n",
            "iteration 11331 : loss : 0.078550, loss_ce: 0.017724 loss_dice: 0.119101\n",
            "iteration 11332 : loss : 0.155755, loss_ce: 0.024720 loss_dice: 0.243112\n",
            "iteration 11333 : loss : 0.127489, loss_ce: 0.029858 loss_dice: 0.192576\n",
            "iteration 11334 : loss : 0.112969, loss_ce: 0.026456 loss_dice: 0.170644\n",
            "iteration 11335 : loss : 0.091515, loss_ce: 0.033657 loss_dice: 0.130087\n",
            "iteration 11336 : loss : 0.101828, loss_ce: 0.050171 loss_dice: 0.136266\n",
            "iteration 11337 : loss : 0.080968, loss_ce: 0.027893 loss_dice: 0.116352\n",
            "iteration 11338 : loss : 0.072770, loss_ce: 0.021184 loss_dice: 0.107161\n",
            "iteration 11339 : loss : 0.175038, loss_ce: 0.019235 loss_dice: 0.278907\n",
            "iteration 11340 : loss : 0.041385, loss_ce: 0.012238 loss_dice: 0.060816\n",
            "iteration 11341 : loss : 0.071840, loss_ce: 0.030780 loss_dice: 0.099214\n",
            "iteration 11342 : loss : 0.155506, loss_ce: 0.020782 loss_dice: 0.245322\n",
            "iteration 11343 : loss : 0.086396, loss_ce: 0.018427 loss_dice: 0.131708\n",
            "iteration 11344 : loss : 0.099892, loss_ce: 0.019005 loss_dice: 0.153816\n",
            "iteration 11345 : loss : 0.063374, loss_ce: 0.017981 loss_dice: 0.093636\n",
            "iteration 11346 : loss : 0.126276, loss_ce: 0.030287 loss_dice: 0.190268\n",
            "iteration 11347 : loss : 0.126822, loss_ce: 0.018280 loss_dice: 0.199184\n",
            "iteration 11348 : loss : 0.121781, loss_ce: 0.038555 loss_dice: 0.177265\n",
            "iteration 11349 : loss : 0.140170, loss_ce: 0.032794 loss_dice: 0.211754\n",
            "iteration 11350 : loss : 0.113933, loss_ce: 0.038857 loss_dice: 0.163983\n",
            "iteration 11351 : loss : 0.139942, loss_ce: 0.020865 loss_dice: 0.219326\n",
            "iteration 11352 : loss : 0.184490, loss_ce: 0.055147 loss_dice: 0.270719\n",
            "iteration 11353 : loss : 0.100260, loss_ce: 0.036275 loss_dice: 0.142917\n",
            "iteration 11354 : loss : 0.207790, loss_ce: 0.020088 loss_dice: 0.332924\n",
            "iteration 11355 : loss : 0.169400, loss_ce: 0.026474 loss_dice: 0.264684\n",
            "iteration 11356 : loss : 0.201509, loss_ce: 0.092249 loss_dice: 0.274349\n",
            "iteration 11357 : loss : 0.198141, loss_ce: 0.059996 loss_dice: 0.290238\n",
            "iteration 11358 : loss : 0.197593, loss_ce: 0.070409 loss_dice: 0.282383\n",
            "iteration 11359 : loss : 0.093790, loss_ce: 0.018311 loss_dice: 0.144109\n",
            "iteration 11360 : loss : 0.120489, loss_ce: 0.019646 loss_dice: 0.187717\n",
            "iteration 11361 : loss : 0.304201, loss_ce: 0.030387 loss_dice: 0.486744\n",
            "iteration 11362 : loss : 0.083797, loss_ce: 0.028638 loss_dice: 0.120569\n",
            "iteration 11363 : loss : 0.147660, loss_ce: 0.044302 loss_dice: 0.216565\n",
            "iteration 11364 : loss : 0.137549, loss_ce: 0.026612 loss_dice: 0.211507\n",
            "iteration 11365 : loss : 0.185743, loss_ce: 0.058176 loss_dice: 0.270788\n",
            "iteration 11366 : loss : 0.219350, loss_ce: 0.067040 loss_dice: 0.320889\n",
            "iteration 11367 : loss : 0.217193, loss_ce: 0.115358 loss_dice: 0.285084\n",
            "iteration 11368 : loss : 0.128748, loss_ce: 0.018181 loss_dice: 0.202459\n",
            "iteration 11369 : loss : 0.151412, loss_ce: 0.022033 loss_dice: 0.237665\n",
            "iteration 11370 : loss : 0.105265, loss_ce: 0.040598 loss_dice: 0.148377\n",
            "iteration 11371 : loss : 0.100550, loss_ce: 0.015192 loss_dice: 0.157456\n",
            "iteration 11372 : loss : 0.146596, loss_ce: 0.026078 loss_dice: 0.226941\n",
            "iteration 11373 : loss : 0.147244, loss_ce: 0.052363 loss_dice: 0.210499\n",
            "iteration 11374 : loss : 0.149124, loss_ce: 0.029842 loss_dice: 0.228646\n",
            "iteration 11375 : loss : 0.110913, loss_ce: 0.015540 loss_dice: 0.174496\n",
            "iteration 11376 : loss : 0.129862, loss_ce: 0.021721 loss_dice: 0.201955\n",
            "iteration 11377 : loss : 0.064541, loss_ce: 0.025460 loss_dice: 0.090594\n",
            "iteration 11378 : loss : 0.130808, loss_ce: 0.015703 loss_dice: 0.207545\n",
            "iteration 11379 : loss : 0.147762, loss_ce: 0.038977 loss_dice: 0.220285\n",
            "iteration 11380 : loss : 0.075084, loss_ce: 0.026426 loss_dice: 0.107522\n",
            "iteration 11381 : loss : 0.154175, loss_ce: 0.043013 loss_dice: 0.228284\n",
            "iteration 11382 : loss : 0.085221, loss_ce: 0.014265 loss_dice: 0.132524\n",
            "iteration 11383 : loss : 0.078025, loss_ce: 0.026213 loss_dice: 0.112566\n",
            "iteration 11384 : loss : 0.117162, loss_ce: 0.010273 loss_dice: 0.188421\n",
            "iteration 11385 : loss : 0.109420, loss_ce: 0.026887 loss_dice: 0.164443\n",
            "iteration 11386 : loss : 0.100160, loss_ce: 0.045323 loss_dice: 0.136718\n",
            "iteration 11387 : loss : 0.175984, loss_ce: 0.018531 loss_dice: 0.280953\n",
            "iteration 11388 : loss : 0.107991, loss_ce: 0.022209 loss_dice: 0.165179\n",
            "iteration 11389 : loss : 0.152278, loss_ce: 0.037359 loss_dice: 0.228891\n",
            "iteration 11390 : loss : 0.099381, loss_ce: 0.025060 loss_dice: 0.148928\n",
            "iteration 11391 : loss : 0.115559, loss_ce: 0.021965 loss_dice: 0.177955\n",
            "iteration 11392 : loss : 0.074216, loss_ce: 0.031351 loss_dice: 0.102793\n",
            "iteration 11393 : loss : 0.086172, loss_ce: 0.021919 loss_dice: 0.129008\n",
            "iteration 11394 : loss : 0.071713, loss_ce: 0.016183 loss_dice: 0.108733\n",
            "iteration 11395 : loss : 0.162690, loss_ce: 0.009329 loss_dice: 0.264931\n",
            "iteration 11396 : loss : 0.137580, loss_ce: 0.015054 loss_dice: 0.219264\n",
            "iteration 11397 : loss : 0.201051, loss_ce: 0.020788 loss_dice: 0.321227\n",
            "iteration 11398 : loss : 0.056555, loss_ce: 0.013752 loss_dice: 0.085090\n",
            "iteration 11399 : loss : 0.116655, loss_ce: 0.020876 loss_dice: 0.180507\n",
            "iteration 11400 : loss : 0.248384, loss_ce: 0.008796 loss_dice: 0.408110\n",
            "iteration 11401 : loss : 0.130030, loss_ce: 0.030918 loss_dice: 0.196105\n",
            "iteration 11402 : loss : 0.137187, loss_ce: 0.011921 loss_dice: 0.220698\n",
            "iteration 11403 : loss : 0.119109, loss_ce: 0.005845 loss_dice: 0.194618\n",
            "iteration 11404 : loss : 0.070583, loss_ce: 0.024714 loss_dice: 0.101163\n",
            "iteration 11405 : loss : 0.283756, loss_ce: 0.034475 loss_dice: 0.449944\n",
            "iteration 11406 : loss : 0.126371, loss_ce: 0.025416 loss_dice: 0.193674\n",
            "iteration 11407 : loss : 0.140332, loss_ce: 0.028080 loss_dice: 0.215166\n",
            "iteration 11408 : loss : 0.137232, loss_ce: 0.028276 loss_dice: 0.209870\n",
            "iteration 11409 : loss : 0.248865, loss_ce: 0.019381 loss_dice: 0.401854\n",
            "iteration 11410 : loss : 0.264366, loss_ce: 0.027839 loss_dice: 0.422050\n",
            "iteration 11411 : loss : 0.145797, loss_ce: 0.042047 loss_dice: 0.214964\n",
            "iteration 11412 : loss : 0.089431, loss_ce: 0.026645 loss_dice: 0.131289\n",
            "iteration 11413 : loss : 0.192430, loss_ce: 0.049576 loss_dice: 0.287666\n",
            "iteration 11414 : loss : 0.192947, loss_ce: 0.031252 loss_dice: 0.300744\n",
            "iteration 11415 : loss : 0.173349, loss_ce: 0.051315 loss_dice: 0.254704\n",
            "iteration 11416 : loss : 0.253410, loss_ce: 0.031611 loss_dice: 0.401276\n",
            "iteration 11417 : loss : 0.169420, loss_ce: 0.061791 loss_dice: 0.241172\n",
            "iteration 11418 : loss : 0.154483, loss_ce: 0.064141 loss_dice: 0.214711\n",
            "iteration 11419 : loss : 0.167260, loss_ce: 0.049271 loss_dice: 0.245919\n",
            "iteration 11420 : loss : 0.153991, loss_ce: 0.068209 loss_dice: 0.211179\n",
            "iteration 11421 : loss : 0.153056, loss_ce: 0.020470 loss_dice: 0.241447\n",
            "iteration 11422 : loss : 0.137820, loss_ce: 0.039666 loss_dice: 0.203256\n",
            "iteration 11423 : loss : 0.288802, loss_ce: 0.025867 loss_dice: 0.464092\n",
            "iteration 11424 : loss : 0.149247, loss_ce: 0.040364 loss_dice: 0.221837\n",
            "iteration 11425 : loss : 0.149802, loss_ce: 0.024781 loss_dice: 0.233149\n",
            "iteration 11426 : loss : 0.175881, loss_ce: 0.050572 loss_dice: 0.259420\n",
            "iteration 11427 : loss : 0.157883, loss_ce: 0.060955 loss_dice: 0.222501\n",
            "iteration 11428 : loss : 0.269760, loss_ce: 0.022943 loss_dice: 0.434304\n",
            "iteration 11429 : loss : 0.181224, loss_ce: 0.015312 loss_dice: 0.291832\n",
            "iteration 11430 : loss : 0.170343, loss_ce: 0.031374 loss_dice: 0.262989\n",
            "iteration 11431 : loss : 0.171290, loss_ce: 0.086690 loss_dice: 0.227690\n",
            "iteration 11432 : loss : 0.126849, loss_ce: 0.020049 loss_dice: 0.198048\n",
            "iteration 11433 : loss : 0.168715, loss_ce: 0.049956 loss_dice: 0.247888\n",
            "iteration 11434 : loss : 0.229908, loss_ce: 0.057680 loss_dice: 0.344726\n",
            "iteration 11435 : loss : 0.139940, loss_ce: 0.072987 loss_dice: 0.184576\n",
            "iteration 11436 : loss : 0.151667, loss_ce: 0.054941 loss_dice: 0.216151\n",
            "iteration 11437 : loss : 0.155449, loss_ce: 0.066094 loss_dice: 0.215020\n",
            "iteration 11438 : loss : 0.174656, loss_ce: 0.010206 loss_dice: 0.284289\n",
            "iteration 11439 : loss : 0.131242, loss_ce: 0.044128 loss_dice: 0.189319\n",
            "iteration 11440 : loss : 0.100749, loss_ce: 0.019361 loss_dice: 0.155007\n",
            "iteration 11441 : loss : 0.095253, loss_ce: 0.026992 loss_dice: 0.140760\n",
            "iteration 11442 : loss : 0.125535, loss_ce: 0.015102 loss_dice: 0.199157\n",
            "iteration 11443 : loss : 0.132725, loss_ce: 0.014178 loss_dice: 0.211756\n",
            "iteration 11444 : loss : 0.088461, loss_ce: 0.021569 loss_dice: 0.133056\n",
            "iteration 11445 : loss : 0.101615, loss_ce: 0.010361 loss_dice: 0.162451\n",
            "iteration 11446 : loss : 0.158756, loss_ce: 0.040461 loss_dice: 0.237619\n",
            "iteration 11447 : loss : 0.058072, loss_ce: 0.019016 loss_dice: 0.084109\n",
            "iteration 11448 : loss : 0.123060, loss_ce: 0.038516 loss_dice: 0.179423\n",
            "iteration 11449 : loss : 0.152052, loss_ce: 0.025445 loss_dice: 0.236457\n",
            "iteration 11450 : loss : 0.103864, loss_ce: 0.012571 loss_dice: 0.164726\n",
            "iteration 11451 : loss : 0.089739, loss_ce: 0.020262 loss_dice: 0.136057\n",
            "iteration 11452 : loss : 0.136476, loss_ce: 0.039840 loss_dice: 0.200900\n",
            "iteration 11453 : loss : 0.166379, loss_ce: 0.008281 loss_dice: 0.271778\n",
            "iteration 11454 : loss : 0.147665, loss_ce: 0.046885 loss_dice: 0.214853\n",
            "iteration 11455 : loss : 0.057067, loss_ce: 0.018442 loss_dice: 0.082817\n",
            "iteration 11456 : loss : 0.143479, loss_ce: 0.042304 loss_dice: 0.210929\n",
            "iteration 11457 : loss : 0.049987, loss_ce: 0.017757 loss_dice: 0.071473\n",
            "iteration 11458 : loss : 0.088324, loss_ce: 0.030014 loss_dice: 0.127198\n",
            "iteration 11459 : loss : 0.044673, loss_ce: 0.013021 loss_dice: 0.065775\n",
            "iteration 11460 : loss : 0.149730, loss_ce: 0.026610 loss_dice: 0.231809\n",
            "iteration 11461 : loss : 0.139596, loss_ce: 0.020096 loss_dice: 0.219262\n",
            "iteration 11462 : loss : 0.415301, loss_ce: 0.005517 loss_dice: 0.688491\n",
            "iteration 11463 : loss : 0.173458, loss_ce: 0.025937 loss_dice: 0.271806\n",
            "iteration 11464 : loss : 0.144265, loss_ce: 0.007474 loss_dice: 0.235458\n",
            "iteration 11465 : loss : 0.067255, loss_ce: 0.012190 loss_dice: 0.103965\n",
            "iteration 11466 : loss : 0.193024, loss_ce: 0.012568 loss_dice: 0.313327\n",
            "iteration 11467 : loss : 0.187281, loss_ce: 0.030846 loss_dice: 0.291572\n",
            "iteration 11468 : loss : 0.071131, loss_ce: 0.029691 loss_dice: 0.098758\n",
            "iteration 11469 : loss : 0.077421, loss_ce: 0.009670 loss_dice: 0.122589\n",
            "iteration 11470 : loss : 0.045894, loss_ce: 0.010381 loss_dice: 0.069569\n",
            "iteration 11471 : loss : 0.085610, loss_ce: 0.029854 loss_dice: 0.122781\n",
            "iteration 11472 : loss : 0.113494, loss_ce: 0.036505 loss_dice: 0.164819\n",
            "iteration 11473 : loss : 0.095691, loss_ce: 0.024842 loss_dice: 0.142924\n",
            "iteration 11474 : loss : 0.143905, loss_ce: 0.017214 loss_dice: 0.228366\n",
            "iteration 11475 : loss : 0.171065, loss_ce: 0.047154 loss_dice: 0.253673\n",
            "iteration 11476 : loss : 0.099219, loss_ce: 0.028440 loss_dice: 0.146406\n",
            "iteration 11477 : loss : 0.137454, loss_ce: 0.030011 loss_dice: 0.209083\n",
            "iteration 11478 : loss : 0.124301, loss_ce: 0.032226 loss_dice: 0.185685\n",
            "iteration 11479 : loss : 0.112303, loss_ce: 0.034727 loss_dice: 0.164020\n",
            "iteration 11480 : loss : 0.207730, loss_ce: 0.040894 loss_dice: 0.318954\n",
            "iteration 11481 : loss : 0.114607, loss_ce: 0.028491 loss_dice: 0.172018\n",
            "iteration 11482 : loss : 0.111051, loss_ce: 0.025796 loss_dice: 0.167887\n",
            "iteration 11483 : loss : 0.187445, loss_ce: 0.011930 loss_dice: 0.304454\n",
            "iteration 11484 : loss : 0.113452, loss_ce: 0.014675 loss_dice: 0.179304\n",
            "iteration 11485 : loss : 0.201311, loss_ce: 0.013237 loss_dice: 0.326694\n",
            "iteration 11486 : loss : 0.119974, loss_ce: 0.032971 loss_dice: 0.177976\n",
            "iteration 11487 : loss : 0.183674, loss_ce: 0.036119 loss_dice: 0.282045\n",
            "iteration 11488 : loss : 0.079345, loss_ce: 0.012158 loss_dice: 0.124136\n",
            "iteration 11489 : loss : 0.083147, loss_ce: 0.031099 loss_dice: 0.117846\n",
            "iteration 11490 : loss : 0.102909, loss_ce: 0.036702 loss_dice: 0.147046\n",
            "iteration 11491 : loss : 0.105397, loss_ce: 0.024023 loss_dice: 0.159646\n",
            "iteration 11492 : loss : 0.309591, loss_ce: 0.016534 loss_dice: 0.504963\n",
            "iteration 11493 : loss : 0.104631, loss_ce: 0.041117 loss_dice: 0.146974\n",
            "iteration 11494 : loss : 0.185724, loss_ce: 0.022374 loss_dice: 0.294625\n",
            "iteration 11495 : loss : 0.104191, loss_ce: 0.019950 loss_dice: 0.160351\n",
            "iteration 11496 : loss : 0.213321, loss_ce: 0.058267 loss_dice: 0.316691\n",
            "iteration 11497 : loss : 0.081236, loss_ce: 0.020296 loss_dice: 0.121863\n",
            "iteration 11498 : loss : 0.174465, loss_ce: 0.049267 loss_dice: 0.257931\n",
            "iteration 11499 : loss : 0.149895, loss_ce: 0.040008 loss_dice: 0.223153\n",
            "iteration 11500 : loss : 0.170665, loss_ce: 0.026227 loss_dice: 0.266957\n",
            "iteration 11501 : loss : 0.171574, loss_ce: 0.069355 loss_dice: 0.239720\n",
            "iteration 11502 : loss : 0.162335, loss_ce: 0.038321 loss_dice: 0.245012\n",
            "iteration 11503 : loss : 0.163577, loss_ce: 0.046684 loss_dice: 0.241506\n",
            "iteration 11504 : loss : 0.153268, loss_ce: 0.045829 loss_dice: 0.224894\n",
            "iteration 11505 : loss : 0.161463, loss_ce: 0.022261 loss_dice: 0.254265\n",
            "iteration 11506 : loss : 0.109285, loss_ce: 0.011801 loss_dice: 0.174274\n",
            "iteration 11507 : loss : 0.160166, loss_ce: 0.049080 loss_dice: 0.234224\n",
            "iteration 11508 : loss : 0.104480, loss_ce: 0.037831 loss_dice: 0.148913\n",
            "iteration 11509 : loss : 0.175922, loss_ce: 0.008802 loss_dice: 0.287335\n",
            "iteration 11510 : loss : 0.146344, loss_ce: 0.031717 loss_dice: 0.222761\n",
            "iteration 11511 : loss : 0.163091, loss_ce: 0.068360 loss_dice: 0.226245\n",
            "iteration 11512 : loss : 0.183562, loss_ce: 0.052418 loss_dice: 0.270992\n",
            "iteration 11513 : loss : 0.216080, loss_ce: 0.136597 loss_dice: 0.269069\n",
            "iteration 11514 : loss : 0.077710, loss_ce: 0.023468 loss_dice: 0.113872\n",
            "iteration 11515 : loss : 0.145486, loss_ce: 0.051333 loss_dice: 0.208254\n",
            "iteration 11516 : loss : 0.187431, loss_ce: 0.070557 loss_dice: 0.265348\n",
            "iteration 11517 : loss : 0.145531, loss_ce: 0.044320 loss_dice: 0.213005\n",
            "iteration 11518 : loss : 0.110901, loss_ce: 0.016140 loss_dice: 0.174074\n",
            "iteration 11519 : loss : 0.156503, loss_ce: 0.039330 loss_dice: 0.234618\n",
            "iteration 11520 : loss : 0.132280, loss_ce: 0.034766 loss_dice: 0.197290\n",
            "iteration 11521 : loss : 0.109196, loss_ce: 0.023646 loss_dice: 0.166229\n",
            "iteration 11522 : loss : 0.132532, loss_ce: 0.021167 loss_dice: 0.206775\n",
            "iteration 11523 : loss : 0.089185, loss_ce: 0.037641 loss_dice: 0.123548\n",
            "iteration 11524 : loss : 0.175531, loss_ce: 0.055865 loss_dice: 0.255309\n",
            "iteration 11525 : loss : 0.159523, loss_ce: 0.033627 loss_dice: 0.243454\n",
            "iteration 11526 : loss : 0.099502, loss_ce: 0.018656 loss_dice: 0.153399\n",
            "iteration 11527 : loss : 0.163500, loss_ce: 0.069799 loss_dice: 0.225967\n",
            "iteration 11528 : loss : 0.145967, loss_ce: 0.026986 loss_dice: 0.225287\n",
            "iteration 11529 : loss : 0.115728, loss_ce: 0.015867 loss_dice: 0.182302\n",
            "iteration 11530 : loss : 0.149792, loss_ce: 0.040157 loss_dice: 0.222883\n",
            "iteration 11531 : loss : 0.155642, loss_ce: 0.054136 loss_dice: 0.223313\n",
            "iteration 11532 : loss : 0.137831, loss_ce: 0.017703 loss_dice: 0.217917\n",
            "iteration 11533 : loss : 0.171280, loss_ce: 0.036170 loss_dice: 0.261353\n",
            "iteration 11534 : loss : 0.130453, loss_ce: 0.024846 loss_dice: 0.200858\n",
            "iteration 11535 : loss : 0.146876, loss_ce: 0.058627 loss_dice: 0.205708\n",
            "iteration 11536 : loss : 0.137597, loss_ce: 0.019720 loss_dice: 0.216181\n",
            "iteration 11537 : loss : 0.105546, loss_ce: 0.041584 loss_dice: 0.148187\n",
            "iteration 11538 : loss : 0.152794, loss_ce: 0.022522 loss_dice: 0.239643\n",
            "iteration 11539 : loss : 0.131296, loss_ce: 0.038593 loss_dice: 0.193098\n",
            "iteration 11540 : loss : 0.165695, loss_ce: 0.029612 loss_dice: 0.256418\n",
            "iteration 11541 : loss : 0.129593, loss_ce: 0.008736 loss_dice: 0.210164\n",
            "iteration 11542 : loss : 0.101985, loss_ce: 0.043116 loss_dice: 0.141232\n",
            "iteration 11543 : loss : 0.148471, loss_ce: 0.019878 loss_dice: 0.234200\n",
            "iteration 11544 : loss : 0.273634, loss_ce: 0.006365 loss_dice: 0.451813\n",
            " 10%|██▊                        | 52/500 [1:59:20<11:04:59, 89.06s/it]iteration 11545 : loss : 0.127086, loss_ce: 0.019349 loss_dice: 0.198911\n",
            "iteration 11546 : loss : 0.114336, loss_ce: 0.014914 loss_dice: 0.180618\n",
            "iteration 11547 : loss : 0.110740, loss_ce: 0.029744 loss_dice: 0.164738\n",
            "iteration 11548 : loss : 0.066700, loss_ce: 0.015256 loss_dice: 0.100997\n",
            "iteration 11549 : loss : 0.174400, loss_ce: 0.030786 loss_dice: 0.270143\n",
            "iteration 11550 : loss : 0.064482, loss_ce: 0.033309 loss_dice: 0.085264\n",
            "iteration 11551 : loss : 0.192801, loss_ce: 0.047673 loss_dice: 0.289553\n",
            "iteration 11552 : loss : 0.116515, loss_ce: 0.015149 loss_dice: 0.184093\n",
            "iteration 11553 : loss : 0.080112, loss_ce: 0.013265 loss_dice: 0.124676\n",
            "iteration 11554 : loss : 0.141662, loss_ce: 0.035639 loss_dice: 0.212344\n",
            "iteration 11555 : loss : 0.096366, loss_ce: 0.021123 loss_dice: 0.146527\n",
            "iteration 11556 : loss : 0.128978, loss_ce: 0.017477 loss_dice: 0.203313\n",
            "iteration 11557 : loss : 0.123630, loss_ce: 0.029651 loss_dice: 0.186282\n",
            "iteration 11558 : loss : 0.115464, loss_ce: 0.050129 loss_dice: 0.159020\n",
            "iteration 11559 : loss : 0.127551, loss_ce: 0.027365 loss_dice: 0.194342\n",
            "iteration 11560 : loss : 0.290269, loss_ce: 0.034260 loss_dice: 0.460943\n",
            "iteration 11561 : loss : 0.091225, loss_ce: 0.028903 loss_dice: 0.132773\n",
            "iteration 11562 : loss : 0.118945, loss_ce: 0.020850 loss_dice: 0.184342\n",
            "iteration 11563 : loss : 0.157786, loss_ce: 0.048152 loss_dice: 0.230876\n",
            "iteration 11564 : loss : 0.176758, loss_ce: 0.007773 loss_dice: 0.289414\n",
            "iteration 11565 : loss : 0.130594, loss_ce: 0.019710 loss_dice: 0.204516\n",
            "iteration 11566 : loss : 0.055247, loss_ce: 0.014800 loss_dice: 0.082212\n",
            "iteration 11567 : loss : 0.120549, loss_ce: 0.044763 loss_dice: 0.171073\n",
            "iteration 11568 : loss : 0.164276, loss_ce: 0.020250 loss_dice: 0.260293\n",
            "iteration 11569 : loss : 0.120644, loss_ce: 0.014170 loss_dice: 0.191627\n",
            "iteration 11570 : loss : 0.143250, loss_ce: 0.013451 loss_dice: 0.229784\n",
            "iteration 11571 : loss : 0.174243, loss_ce: 0.046343 loss_dice: 0.259509\n",
            "iteration 11572 : loss : 0.054743, loss_ce: 0.011121 loss_dice: 0.083824\n",
            "iteration 11573 : loss : 0.174027, loss_ce: 0.039338 loss_dice: 0.263820\n",
            "iteration 11574 : loss : 0.148796, loss_ce: 0.029000 loss_dice: 0.228660\n",
            "iteration 11575 : loss : 0.108699, loss_ce: 0.029412 loss_dice: 0.161556\n",
            "iteration 11576 : loss : 0.118039, loss_ce: 0.023731 loss_dice: 0.180911\n",
            "iteration 11577 : loss : 0.079885, loss_ce: 0.036536 loss_dice: 0.108785\n",
            "iteration 11578 : loss : 0.181501, loss_ce: 0.020507 loss_dice: 0.288830\n",
            "iteration 11579 : loss : 0.145419, loss_ce: 0.053389 loss_dice: 0.206773\n",
            "iteration 11580 : loss : 0.131679, loss_ce: 0.025567 loss_dice: 0.202420\n",
            "iteration 11581 : loss : 0.246867, loss_ce: 0.011136 loss_dice: 0.404021\n",
            "iteration 11582 : loss : 0.084961, loss_ce: 0.027582 loss_dice: 0.123214\n",
            "iteration 11583 : loss : 0.066565, loss_ce: 0.033534 loss_dice: 0.088586\n",
            "iteration 11584 : loss : 0.172961, loss_ce: 0.013671 loss_dice: 0.279153\n",
            "iteration 11585 : loss : 0.134723, loss_ce: 0.024835 loss_dice: 0.207982\n",
            "iteration 11586 : loss : 0.096451, loss_ce: 0.025311 loss_dice: 0.143878\n",
            "iteration 11587 : loss : 0.162649, loss_ce: 0.028726 loss_dice: 0.251931\n",
            "iteration 11588 : loss : 0.052587, loss_ce: 0.011131 loss_dice: 0.080225\n",
            "iteration 11589 : loss : 0.145584, loss_ce: 0.029568 loss_dice: 0.222927\n",
            "iteration 11590 : loss : 0.152561, loss_ce: 0.021035 loss_dice: 0.240245\n",
            "iteration 11591 : loss : 0.138198, loss_ce: 0.022490 loss_dice: 0.215336\n",
            "iteration 11592 : loss : 0.172400, loss_ce: 0.023961 loss_dice: 0.271359\n",
            "iteration 11593 : loss : 0.081639, loss_ce: 0.030177 loss_dice: 0.115948\n",
            "iteration 11594 : loss : 0.130981, loss_ce: 0.031159 loss_dice: 0.197529\n",
            "iteration 11595 : loss : 0.118366, loss_ce: 0.026796 loss_dice: 0.179413\n",
            "iteration 11596 : loss : 0.119306, loss_ce: 0.019390 loss_dice: 0.185916\n",
            "iteration 11597 : loss : 0.093762, loss_ce: 0.022224 loss_dice: 0.141454\n",
            "iteration 11598 : loss : 0.127800, loss_ce: 0.026269 loss_dice: 0.195488\n",
            "iteration 11599 : loss : 0.165623, loss_ce: 0.029834 loss_dice: 0.256149\n",
            "iteration 11600 : loss : 0.134241, loss_ce: 0.010435 loss_dice: 0.216778\n",
            "iteration 11601 : loss : 0.137401, loss_ce: 0.041180 loss_dice: 0.201548\n",
            "iteration 11602 : loss : 0.079528, loss_ce: 0.036005 loss_dice: 0.108544\n",
            "iteration 11603 : loss : 0.236403, loss_ce: 0.023618 loss_dice: 0.378260\n",
            "iteration 11604 : loss : 0.224661, loss_ce: 0.022243 loss_dice: 0.359607\n",
            "iteration 11605 : loss : 0.076360, loss_ce: 0.037655 loss_dice: 0.102163\n",
            "iteration 11606 : loss : 0.212594, loss_ce: 0.025665 loss_dice: 0.337213\n",
            "iteration 11607 : loss : 0.052111, loss_ce: 0.007639 loss_dice: 0.081758\n",
            "iteration 11608 : loss : 0.127600, loss_ce: 0.028876 loss_dice: 0.193415\n",
            "iteration 11609 : loss : 0.140663, loss_ce: 0.024057 loss_dice: 0.218400\n",
            "iteration 11610 : loss : 0.080539, loss_ce: 0.019832 loss_dice: 0.121010\n",
            "iteration 11611 : loss : 0.114309, loss_ce: 0.019546 loss_dice: 0.177484\n",
            "iteration 11612 : loss : 0.126640, loss_ce: 0.016145 loss_dice: 0.200303\n",
            "iteration 11613 : loss : 0.109514, loss_ce: 0.017348 loss_dice: 0.170958\n",
            "iteration 11614 : loss : 0.197054, loss_ce: 0.011602 loss_dice: 0.320688\n",
            "iteration 11615 : loss : 0.092846, loss_ce: 0.031321 loss_dice: 0.133863\n",
            "iteration 11616 : loss : 0.140543, loss_ce: 0.053634 loss_dice: 0.198482\n",
            "iteration 11617 : loss : 0.127883, loss_ce: 0.050667 loss_dice: 0.179360\n",
            "iteration 11618 : loss : 0.082465, loss_ce: 0.024301 loss_dice: 0.121241\n",
            "iteration 11619 : loss : 0.196845, loss_ce: 0.014139 loss_dice: 0.318648\n",
            "iteration 11620 : loss : 0.148069, loss_ce: 0.023972 loss_dice: 0.230801\n",
            "iteration 11621 : loss : 0.159108, loss_ce: 0.027700 loss_dice: 0.246714\n",
            "iteration 11622 : loss : 0.135015, loss_ce: 0.011824 loss_dice: 0.217142\n",
            "iteration 11623 : loss : 0.097755, loss_ce: 0.020637 loss_dice: 0.149167\n",
            "iteration 11624 : loss : 0.075676, loss_ce: 0.016409 loss_dice: 0.115187\n",
            "iteration 11625 : loss : 0.124929, loss_ce: 0.023838 loss_dice: 0.192323\n",
            "iteration 11626 : loss : 0.099382, loss_ce: 0.034216 loss_dice: 0.142826\n",
            "iteration 11627 : loss : 0.117650, loss_ce: 0.053167 loss_dice: 0.160638\n",
            "iteration 11628 : loss : 0.081731, loss_ce: 0.030680 loss_dice: 0.115765\n",
            "iteration 11629 : loss : 0.141006, loss_ce: 0.030840 loss_dice: 0.214451\n",
            "iteration 11630 : loss : 0.128647, loss_ce: 0.024080 loss_dice: 0.198358\n",
            "iteration 11631 : loss : 0.104287, loss_ce: 0.040267 loss_dice: 0.146967\n",
            "iteration 11632 : loss : 0.206562, loss_ce: 0.030556 loss_dice: 0.323900\n",
            "iteration 11633 : loss : 0.126877, loss_ce: 0.025377 loss_dice: 0.194544\n",
            "iteration 11634 : loss : 0.124517, loss_ce: 0.017653 loss_dice: 0.195759\n",
            "iteration 11635 : loss : 0.090513, loss_ce: 0.025408 loss_dice: 0.133916\n",
            "iteration 11636 : loss : 0.082886, loss_ce: 0.022578 loss_dice: 0.123091\n",
            "iteration 11637 : loss : 0.202524, loss_ce: 0.007880 loss_dice: 0.332287\n",
            "iteration 11638 : loss : 0.135684, loss_ce: 0.009644 loss_dice: 0.219711\n",
            "iteration 11639 : loss : 0.143962, loss_ce: 0.009859 loss_dice: 0.233364\n",
            "iteration 11640 : loss : 0.092954, loss_ce: 0.019655 loss_dice: 0.141820\n",
            "iteration 11641 : loss : 0.164694, loss_ce: 0.011641 loss_dice: 0.266729\n",
            "iteration 11642 : loss : 0.135541, loss_ce: 0.026474 loss_dice: 0.208252\n",
            "iteration 11643 : loss : 0.124145, loss_ce: 0.015638 loss_dice: 0.196483\n",
            "iteration 11644 : loss : 0.128698, loss_ce: 0.029865 loss_dice: 0.194586\n",
            "iteration 11645 : loss : 0.084620, loss_ce: 0.024378 loss_dice: 0.124781\n",
            "iteration 11646 : loss : 0.160165, loss_ce: 0.017494 loss_dice: 0.255280\n",
            "iteration 11647 : loss : 0.150666, loss_ce: 0.028017 loss_dice: 0.232432\n",
            "iteration 11648 : loss : 0.081850, loss_ce: 0.026930 loss_dice: 0.118462\n",
            "iteration 11649 : loss : 0.102285, loss_ce: 0.036072 loss_dice: 0.146426\n",
            "iteration 11650 : loss : 0.246041, loss_ce: 0.016842 loss_dice: 0.398841\n",
            "iteration 11651 : loss : 0.229333, loss_ce: 0.026149 loss_dice: 0.364789\n",
            "iteration 11652 : loss : 0.119886, loss_ce: 0.021393 loss_dice: 0.185549\n",
            "iteration 11653 : loss : 0.134985, loss_ce: 0.016766 loss_dice: 0.213797\n",
            "iteration 11654 : loss : 0.082256, loss_ce: 0.031615 loss_dice: 0.116016\n",
            "iteration 11655 : loss : 0.080139, loss_ce: 0.030250 loss_dice: 0.113398\n",
            "iteration 11656 : loss : 0.074029, loss_ce: 0.037779 loss_dice: 0.098195\n",
            "iteration 11657 : loss : 0.138415, loss_ce: 0.040745 loss_dice: 0.203529\n",
            "iteration 11658 : loss : 0.120855, loss_ce: 0.026185 loss_dice: 0.183968\n",
            "iteration 11659 : loss : 0.130568, loss_ce: 0.016707 loss_dice: 0.206475\n",
            "iteration 11660 : loss : 0.084448, loss_ce: 0.031053 loss_dice: 0.120044\n",
            "iteration 11661 : loss : 0.129219, loss_ce: 0.027967 loss_dice: 0.196720\n",
            "iteration 11662 : loss : 0.091373, loss_ce: 0.024942 loss_dice: 0.135661\n",
            "iteration 11663 : loss : 0.058279, loss_ce: 0.020303 loss_dice: 0.083596\n",
            "iteration 11664 : loss : 0.075588, loss_ce: 0.011485 loss_dice: 0.118323\n",
            "iteration 11665 : loss : 0.136375, loss_ce: 0.015963 loss_dice: 0.216650\n",
            "iteration 11666 : loss : 0.130937, loss_ce: 0.037012 loss_dice: 0.193554\n",
            "iteration 11667 : loss : 0.073389, loss_ce: 0.017486 loss_dice: 0.110658\n",
            "iteration 11668 : loss : 0.148726, loss_ce: 0.017267 loss_dice: 0.236365\n",
            "iteration 11669 : loss : 0.151627, loss_ce: 0.030633 loss_dice: 0.232289\n",
            "iteration 11670 : loss : 0.075802, loss_ce: 0.029688 loss_dice: 0.106545\n",
            "iteration 11671 : loss : 0.072735, loss_ce: 0.035641 loss_dice: 0.097464\n",
            "iteration 11672 : loss : 0.065358, loss_ce: 0.017312 loss_dice: 0.097389\n",
            "iteration 11673 : loss : 0.099872, loss_ce: 0.033546 loss_dice: 0.144090\n",
            "iteration 11674 : loss : 0.037293, loss_ce: 0.009807 loss_dice: 0.055617\n",
            "iteration 11675 : loss : 0.093166, loss_ce: 0.023888 loss_dice: 0.139352\n",
            "iteration 11676 : loss : 0.079307, loss_ce: 0.035470 loss_dice: 0.108531\n",
            "iteration 11677 : loss : 0.090724, loss_ce: 0.038428 loss_dice: 0.125589\n",
            "iteration 11678 : loss : 0.059307, loss_ce: 0.012389 loss_dice: 0.090586\n",
            "iteration 11679 : loss : 0.193562, loss_ce: 0.037998 loss_dice: 0.297271\n",
            "iteration 11680 : loss : 0.077736, loss_ce: 0.023829 loss_dice: 0.113674\n",
            "iteration 11681 : loss : 0.061891, loss_ce: 0.023066 loss_dice: 0.087773\n",
            "iteration 11682 : loss : 0.073179, loss_ce: 0.016931 loss_dice: 0.110678\n",
            "iteration 11683 : loss : 0.076014, loss_ce: 0.016223 loss_dice: 0.115875\n",
            "iteration 11684 : loss : 0.235730, loss_ce: 0.011509 loss_dice: 0.385210\n",
            "iteration 11685 : loss : 0.136996, loss_ce: 0.038215 loss_dice: 0.202851\n",
            "iteration 11686 : loss : 0.187441, loss_ce: 0.032139 loss_dice: 0.290975\n",
            "iteration 11687 : loss : 0.078004, loss_ce: 0.028604 loss_dice: 0.110937\n",
            "iteration 11688 : loss : 0.121224, loss_ce: 0.037740 loss_dice: 0.176879\n",
            "iteration 11689 : loss : 0.185895, loss_ce: 0.028127 loss_dice: 0.291074\n",
            "iteration 11690 : loss : 0.068755, loss_ce: 0.014664 loss_dice: 0.104816\n",
            "iteration 11691 : loss : 0.109619, loss_ce: 0.021693 loss_dice: 0.168236\n",
            "iteration 11692 : loss : 0.346389, loss_ce: 0.008023 loss_dice: 0.571966\n",
            "iteration 11693 : loss : 0.102313, loss_ce: 0.035525 loss_dice: 0.146839\n",
            "iteration 11694 : loss : 0.099689, loss_ce: 0.034126 loss_dice: 0.143397\n",
            "iteration 11695 : loss : 0.149327, loss_ce: 0.015452 loss_dice: 0.238577\n",
            "iteration 11696 : loss : 0.097456, loss_ce: 0.020503 loss_dice: 0.148758\n",
            "iteration 11697 : loss : 0.095312, loss_ce: 0.039801 loss_dice: 0.132320\n",
            "iteration 11698 : loss : 0.127172, loss_ce: 0.013035 loss_dice: 0.203264\n",
            "iteration 11699 : loss : 0.139228, loss_ce: 0.015375 loss_dice: 0.221796\n",
            "iteration 11700 : loss : 0.105520, loss_ce: 0.040415 loss_dice: 0.148923\n",
            "iteration 11701 : loss : 0.067302, loss_ce: 0.020463 loss_dice: 0.098527\n",
            "iteration 11702 : loss : 0.090062, loss_ce: 0.040593 loss_dice: 0.123041\n",
            "iteration 11703 : loss : 0.063342, loss_ce: 0.011638 loss_dice: 0.097812\n",
            "iteration 11704 : loss : 0.058827, loss_ce: 0.018858 loss_dice: 0.085474\n",
            "iteration 11705 : loss : 0.118028, loss_ce: 0.032672 loss_dice: 0.174931\n",
            "iteration 11706 : loss : 0.153726, loss_ce: 0.016337 loss_dice: 0.245318\n",
            "iteration 11707 : loss : 0.113653, loss_ce: 0.020591 loss_dice: 0.175695\n",
            "iteration 11708 : loss : 0.119675, loss_ce: 0.018732 loss_dice: 0.186970\n",
            "iteration 11709 : loss : 0.081964, loss_ce: 0.034328 loss_dice: 0.113722\n",
            "iteration 11710 : loss : 0.058601, loss_ce: 0.022015 loss_dice: 0.082991\n",
            "iteration 11711 : loss : 0.165666, loss_ce: 0.030098 loss_dice: 0.256045\n",
            "iteration 11712 : loss : 0.127504, loss_ce: 0.028686 loss_dice: 0.193382\n",
            "iteration 11713 : loss : 0.093791, loss_ce: 0.018830 loss_dice: 0.143765\n",
            "iteration 11714 : loss : 0.200782, loss_ce: 0.026069 loss_dice: 0.317258\n",
            "iteration 11715 : loss : 0.079806, loss_ce: 0.049313 loss_dice: 0.100134\n",
            "iteration 11716 : loss : 0.147974, loss_ce: 0.012082 loss_dice: 0.238568\n",
            "iteration 11717 : loss : 0.126528, loss_ce: 0.026251 loss_dice: 0.193378\n",
            "iteration 11718 : loss : 0.049628, loss_ce: 0.014335 loss_dice: 0.073156\n",
            "iteration 11719 : loss : 0.090734, loss_ce: 0.031388 loss_dice: 0.130297\n",
            "iteration 11720 : loss : 0.275524, loss_ce: 0.011751 loss_dice: 0.451372\n",
            "iteration 11721 : loss : 0.147484, loss_ce: 0.011403 loss_dice: 0.238204\n",
            "iteration 11722 : loss : 0.103437, loss_ce: 0.016362 loss_dice: 0.161487\n",
            "iteration 11723 : loss : 0.087604, loss_ce: 0.025930 loss_dice: 0.128721\n",
            "iteration 11724 : loss : 0.058737, loss_ce: 0.026843 loss_dice: 0.079999\n",
            "iteration 11725 : loss : 0.110019, loss_ce: 0.013432 loss_dice: 0.174410\n",
            "iteration 11726 : loss : 0.063961, loss_ce: 0.021744 loss_dice: 0.092105\n",
            "iteration 11727 : loss : 0.130075, loss_ce: 0.024500 loss_dice: 0.200458\n",
            "iteration 11728 : loss : 0.117179, loss_ce: 0.017819 loss_dice: 0.183419\n",
            "iteration 11729 : loss : 0.130380, loss_ce: 0.029587 loss_dice: 0.197575\n",
            "iteration 11730 : loss : 0.194628, loss_ce: 0.016438 loss_dice: 0.313422\n",
            "iteration 11731 : loss : 0.221059, loss_ce: 0.003537 loss_dice: 0.366073\n",
            "iteration 11732 : loss : 0.091874, loss_ce: 0.025974 loss_dice: 0.135807\n",
            "iteration 11733 : loss : 0.082732, loss_ce: 0.021942 loss_dice: 0.123258\n",
            "iteration 11734 : loss : 0.265072, loss_ce: 0.011937 loss_dice: 0.433828\n",
            "iteration 11735 : loss : 0.225489, loss_ce: 0.023395 loss_dice: 0.360219\n",
            "iteration 11736 : loss : 0.066822, loss_ce: 0.018150 loss_dice: 0.099270\n",
            "iteration 11737 : loss : 0.119827, loss_ce: 0.049443 loss_dice: 0.166750\n",
            "iteration 11738 : loss : 0.235415, loss_ce: 0.027386 loss_dice: 0.374102\n",
            "iteration 11739 : loss : 0.091770, loss_ce: 0.031387 loss_dice: 0.132026\n",
            "iteration 11740 : loss : 0.154793, loss_ce: 0.034759 loss_dice: 0.234816\n",
            "iteration 11741 : loss : 0.069903, loss_ce: 0.011789 loss_dice: 0.108646\n",
            "iteration 11742 : loss : 0.102900, loss_ce: 0.042818 loss_dice: 0.142955\n",
            "iteration 11743 : loss : 0.145864, loss_ce: 0.038043 loss_dice: 0.217744\n",
            "iteration 11744 : loss : 0.089857, loss_ce: 0.032561 loss_dice: 0.128054\n",
            "iteration 11745 : loss : 0.173113, loss_ce: 0.029991 loss_dice: 0.268528\n",
            "iteration 11746 : loss : 0.200859, loss_ce: 0.036925 loss_dice: 0.310149\n",
            "iteration 11747 : loss : 0.185466, loss_ce: 0.049607 loss_dice: 0.276038\n",
            "iteration 11748 : loss : 0.141194, loss_ce: 0.020701 loss_dice: 0.221523\n",
            "iteration 11749 : loss : 0.114044, loss_ce: 0.039621 loss_dice: 0.163660\n",
            "iteration 11750 : loss : 0.078888, loss_ce: 0.035681 loss_dice: 0.107693\n",
            "iteration 11751 : loss : 0.061848, loss_ce: 0.024454 loss_dice: 0.086777\n",
            "iteration 11752 : loss : 0.147133, loss_ce: 0.041111 loss_dice: 0.217814\n",
            "iteration 11753 : loss : 0.112039, loss_ce: 0.047312 loss_dice: 0.155191\n",
            "iteration 11754 : loss : 0.082377, loss_ce: 0.015190 loss_dice: 0.127169\n",
            "iteration 11755 : loss : 0.102197, loss_ce: 0.026066 loss_dice: 0.152950\n",
            "iteration 11756 : loss : 0.115646, loss_ce: 0.013295 loss_dice: 0.183880\n",
            "iteration 11757 : loss : 0.149738, loss_ce: 0.026251 loss_dice: 0.232062\n",
            "iteration 11758 : loss : 0.138443, loss_ce: 0.036989 loss_dice: 0.206079\n",
            "iteration 11759 : loss : 0.103820, loss_ce: 0.046517 loss_dice: 0.142022\n",
            "iteration 11760 : loss : 0.134149, loss_ce: 0.025775 loss_dice: 0.206399\n",
            "iteration 11761 : loss : 0.107308, loss_ce: 0.008053 loss_dice: 0.173478\n",
            "iteration 11762 : loss : 0.088696, loss_ce: 0.049994 loss_dice: 0.114497\n",
            "iteration 11763 : loss : 0.184126, loss_ce: 0.024141 loss_dice: 0.290783\n",
            "iteration 11764 : loss : 0.094498, loss_ce: 0.027447 loss_dice: 0.139199\n",
            "iteration 11765 : loss : 0.190010, loss_ce: 0.016113 loss_dice: 0.305940\n",
            "iteration 11766 : loss : 0.148681, loss_ce: 0.000194 loss_dice: 0.247672\n",
            " 11%|██▊                        | 53/500 [2:00:43<10:50:12, 87.28s/it]iteration 11767 : loss : 0.214345, loss_ce: 0.017156 loss_dice: 0.345804\n",
            "iteration 11768 : loss : 0.147013, loss_ce: 0.023775 loss_dice: 0.229172\n",
            "iteration 11769 : loss : 0.060045, loss_ce: 0.012529 loss_dice: 0.091722\n",
            "iteration 11770 : loss : 0.184696, loss_ce: 0.053961 loss_dice: 0.271852\n",
            "iteration 11771 : loss : 0.147416, loss_ce: 0.043144 loss_dice: 0.216931\n",
            "iteration 11772 : loss : 0.103141, loss_ce: 0.023282 loss_dice: 0.156381\n",
            "iteration 11773 : loss : 0.126855, loss_ce: 0.047031 loss_dice: 0.180071\n",
            "iteration 11774 : loss : 0.104047, loss_ce: 0.047248 loss_dice: 0.141913\n",
            "iteration 11775 : loss : 0.077381, loss_ce: 0.016754 loss_dice: 0.117799\n",
            "iteration 11776 : loss : 0.083941, loss_ce: 0.028404 loss_dice: 0.120966\n",
            "iteration 11777 : loss : 0.081969, loss_ce: 0.026828 loss_dice: 0.118730\n",
            "iteration 11778 : loss : 0.115451, loss_ce: 0.021695 loss_dice: 0.177954\n",
            "iteration 11779 : loss : 0.101997, loss_ce: 0.041035 loss_dice: 0.142639\n",
            "iteration 11780 : loss : 0.098192, loss_ce: 0.038978 loss_dice: 0.137669\n",
            "iteration 11781 : loss : 0.079331, loss_ce: 0.025189 loss_dice: 0.115425\n",
            "iteration 11782 : loss : 0.091468, loss_ce: 0.017614 loss_dice: 0.140704\n",
            "iteration 11783 : loss : 0.121399, loss_ce: 0.081252 loss_dice: 0.148163\n",
            "iteration 11784 : loss : 0.080389, loss_ce: 0.024265 loss_dice: 0.117804\n",
            "iteration 11785 : loss : 0.106942, loss_ce: 0.040699 loss_dice: 0.151103\n",
            "iteration 11786 : loss : 0.076202, loss_ce: 0.029423 loss_dice: 0.107388\n",
            "iteration 11787 : loss : 0.115312, loss_ce: 0.016514 loss_dice: 0.181177\n",
            "iteration 11788 : loss : 0.067580, loss_ce: 0.022651 loss_dice: 0.097532\n",
            "iteration 11789 : loss : 0.087189, loss_ce: 0.022987 loss_dice: 0.129990\n",
            "iteration 11790 : loss : 0.114085, loss_ce: 0.019674 loss_dice: 0.177026\n",
            "iteration 11791 : loss : 0.120027, loss_ce: 0.042448 loss_dice: 0.171746\n",
            "iteration 11792 : loss : 0.283133, loss_ce: 0.004038 loss_dice: 0.469196\n",
            "iteration 11793 : loss : 0.084701, loss_ce: 0.024869 loss_dice: 0.124590\n",
            "iteration 11794 : loss : 0.153011, loss_ce: 0.028818 loss_dice: 0.235806\n",
            "iteration 11795 : loss : 0.115785, loss_ce: 0.041629 loss_dice: 0.165222\n",
            "iteration 11796 : loss : 0.112283, loss_ce: 0.030458 loss_dice: 0.166833\n",
            "iteration 11797 : loss : 0.155604, loss_ce: 0.019577 loss_dice: 0.246288\n",
            "iteration 11798 : loss : 0.078310, loss_ce: 0.018072 loss_dice: 0.118469\n",
            "iteration 11799 : loss : 0.123939, loss_ce: 0.053341 loss_dice: 0.171005\n",
            "iteration 11800 : loss : 0.105954, loss_ce: 0.027897 loss_dice: 0.157992\n",
            "iteration 11801 : loss : 0.107203, loss_ce: 0.009889 loss_dice: 0.172079\n",
            "iteration 11802 : loss : 0.052961, loss_ce: 0.012821 loss_dice: 0.079721\n",
            "iteration 11803 : loss : 0.080899, loss_ce: 0.022155 loss_dice: 0.120062\n",
            "iteration 11804 : loss : 0.104831, loss_ce: 0.013745 loss_dice: 0.165555\n",
            "iteration 11805 : loss : 0.088677, loss_ce: 0.025316 loss_dice: 0.130918\n",
            "iteration 11806 : loss : 0.112063, loss_ce: 0.015171 loss_dice: 0.176657\n",
            "iteration 11807 : loss : 0.129173, loss_ce: 0.024628 loss_dice: 0.198870\n",
            "iteration 11808 : loss : 0.070980, loss_ce: 0.041395 loss_dice: 0.090704\n",
            "iteration 11809 : loss : 0.066077, loss_ce: 0.032730 loss_dice: 0.088308\n",
            "iteration 11810 : loss : 0.150855, loss_ce: 0.030653 loss_dice: 0.230989\n",
            "iteration 11811 : loss : 0.131310, loss_ce: 0.048554 loss_dice: 0.186481\n",
            "iteration 11812 : loss : 0.186163, loss_ce: 0.019021 loss_dice: 0.297591\n",
            "iteration 11813 : loss : 0.151346, loss_ce: 0.035040 loss_dice: 0.228883\n",
            "iteration 11814 : loss : 0.055231, loss_ce: 0.020748 loss_dice: 0.078219\n",
            "iteration 11815 : loss : 0.181120, loss_ce: 0.031028 loss_dice: 0.281181\n",
            "iteration 11816 : loss : 0.154274, loss_ce: 0.058587 loss_dice: 0.218066\n",
            "iteration 11817 : loss : 0.119818, loss_ce: 0.022346 loss_dice: 0.184800\n",
            "iteration 11818 : loss : 0.171164, loss_ce: 0.078880 loss_dice: 0.232686\n",
            "iteration 11819 : loss : 0.082598, loss_ce: 0.027530 loss_dice: 0.119311\n",
            "iteration 11820 : loss : 0.139948, loss_ce: 0.062075 loss_dice: 0.191862\n",
            "iteration 11821 : loss : 0.094089, loss_ce: 0.010598 loss_dice: 0.149749\n",
            "iteration 11822 : loss : 0.101698, loss_ce: 0.025675 loss_dice: 0.152380\n",
            "iteration 11823 : loss : 0.187553, loss_ce: 0.057300 loss_dice: 0.274388\n",
            "iteration 11824 : loss : 0.136448, loss_ce: 0.037606 loss_dice: 0.202343\n",
            "iteration 11825 : loss : 0.186691, loss_ce: 0.017595 loss_dice: 0.299421\n",
            "iteration 11826 : loss : 0.099275, loss_ce: 0.017658 loss_dice: 0.153686\n",
            "iteration 11827 : loss : 0.080564, loss_ce: 0.021964 loss_dice: 0.119632\n",
            "iteration 11828 : loss : 0.127505, loss_ce: 0.046082 loss_dice: 0.181787\n",
            "iteration 11829 : loss : 0.137449, loss_ce: 0.071676 loss_dice: 0.181297\n",
            "iteration 11830 : loss : 0.115148, loss_ce: 0.038881 loss_dice: 0.165992\n",
            "iteration 11831 : loss : 0.128166, loss_ce: 0.045024 loss_dice: 0.183593\n",
            "iteration 11832 : loss : 0.130320, loss_ce: 0.051031 loss_dice: 0.183179\n",
            "iteration 11833 : loss : 0.169745, loss_ce: 0.015067 loss_dice: 0.272864\n",
            "iteration 11834 : loss : 0.111163, loss_ce: 0.027598 loss_dice: 0.166873\n",
            "iteration 11835 : loss : 0.159759, loss_ce: 0.035772 loss_dice: 0.242417\n",
            "iteration 11836 : loss : 0.094039, loss_ce: 0.012729 loss_dice: 0.148245\n",
            "iteration 11837 : loss : 0.171235, loss_ce: 0.037681 loss_dice: 0.260271\n",
            "iteration 11838 : loss : 0.145154, loss_ce: 0.028859 loss_dice: 0.222684\n",
            "iteration 11839 : loss : 0.187241, loss_ce: 0.015562 loss_dice: 0.301694\n",
            "iteration 11840 : loss : 0.183037, loss_ce: 0.019232 loss_dice: 0.292240\n",
            "iteration 11841 : loss : 0.089620, loss_ce: 0.024559 loss_dice: 0.132994\n",
            "iteration 11842 : loss : 0.202095, loss_ce: 0.020532 loss_dice: 0.323137\n",
            "iteration 11843 : loss : 0.079488, loss_ce: 0.032819 loss_dice: 0.110601\n",
            "iteration 11844 : loss : 0.114525, loss_ce: 0.029662 loss_dice: 0.171100\n",
            "iteration 11845 : loss : 0.166437, loss_ce: 0.040937 loss_dice: 0.250103\n",
            "iteration 11846 : loss : 0.160319, loss_ce: 0.050367 loss_dice: 0.233620\n",
            "iteration 11847 : loss : 0.136945, loss_ce: 0.027377 loss_dice: 0.209990\n",
            "iteration 11848 : loss : 0.074529, loss_ce: 0.023546 loss_dice: 0.108518\n",
            "iteration 11849 : loss : 0.146120, loss_ce: 0.049070 loss_dice: 0.210820\n",
            "iteration 11850 : loss : 0.112532, loss_ce: 0.051994 loss_dice: 0.152891\n",
            "iteration 11851 : loss : 0.139233, loss_ce: 0.039726 loss_dice: 0.205572\n",
            "iteration 11852 : loss : 0.202777, loss_ce: 0.020142 loss_dice: 0.324534\n",
            "iteration 11853 : loss : 0.174757, loss_ce: 0.054557 loss_dice: 0.254890\n",
            "iteration 11854 : loss : 0.077847, loss_ce: 0.030149 loss_dice: 0.109645\n",
            "iteration 11855 : loss : 0.178863, loss_ce: 0.068360 loss_dice: 0.252532\n",
            "iteration 11856 : loss : 0.113564, loss_ce: 0.031855 loss_dice: 0.168037\n",
            "iteration 11857 : loss : 0.069835, loss_ce: 0.013112 loss_dice: 0.107651\n",
            "iteration 11858 : loss : 0.133668, loss_ce: 0.034300 loss_dice: 0.199913\n",
            "iteration 11859 : loss : 0.206097, loss_ce: 0.016041 loss_dice: 0.332801\n",
            "iteration 11860 : loss : 0.085013, loss_ce: 0.028228 loss_dice: 0.122870\n",
            "iteration 11861 : loss : 0.097648, loss_ce: 0.024382 loss_dice: 0.146492\n",
            "iteration 11862 : loss : 0.134687, loss_ce: 0.020715 loss_dice: 0.210668\n",
            "iteration 11863 : loss : 0.107977, loss_ce: 0.021429 loss_dice: 0.165676\n",
            "iteration 11864 : loss : 0.083983, loss_ce: 0.013896 loss_dice: 0.130708\n",
            "iteration 11865 : loss : 0.161940, loss_ce: 0.031008 loss_dice: 0.249228\n",
            "iteration 11866 : loss : 0.118858, loss_ce: 0.032885 loss_dice: 0.176173\n",
            "iteration 11867 : loss : 0.072105, loss_ce: 0.028282 loss_dice: 0.101320\n",
            "iteration 11868 : loss : 0.122057, loss_ce: 0.010912 loss_dice: 0.196153\n",
            "iteration 11869 : loss : 0.099429, loss_ce: 0.032455 loss_dice: 0.144079\n",
            "iteration 11870 : loss : 0.114009, loss_ce: 0.012604 loss_dice: 0.181613\n",
            "iteration 11871 : loss : 0.094583, loss_ce: 0.033336 loss_dice: 0.135414\n",
            "iteration 11872 : loss : 0.143002, loss_ce: 0.026930 loss_dice: 0.220383\n",
            "iteration 11873 : loss : 0.092076, loss_ce: 0.013655 loss_dice: 0.144356\n",
            "iteration 11874 : loss : 0.122010, loss_ce: 0.020583 loss_dice: 0.189628\n",
            "iteration 11875 : loss : 0.095029, loss_ce: 0.027381 loss_dice: 0.140129\n",
            "iteration 11876 : loss : 0.083240, loss_ce: 0.024338 loss_dice: 0.122508\n",
            "iteration 11877 : loss : 0.196232, loss_ce: 0.014613 loss_dice: 0.317312\n",
            "iteration 11878 : loss : 0.082584, loss_ce: 0.021962 loss_dice: 0.122999\n",
            "iteration 11879 : loss : 0.110865, loss_ce: 0.029796 loss_dice: 0.164910\n",
            "iteration 11880 : loss : 0.102078, loss_ce: 0.051508 loss_dice: 0.135792\n",
            "iteration 11881 : loss : 0.109206, loss_ce: 0.049325 loss_dice: 0.149127\n",
            "iteration 11882 : loss : 0.091107, loss_ce: 0.025567 loss_dice: 0.134801\n",
            "iteration 11883 : loss : 0.104653, loss_ce: 0.020102 loss_dice: 0.161020\n",
            "iteration 11884 : loss : 0.165389, loss_ce: 0.025874 loss_dice: 0.258398\n",
            "iteration 11885 : loss : 0.240840, loss_ce: 0.000043 loss_dice: 0.401371\n",
            "iteration 11886 : loss : 0.140926, loss_ce: 0.001124 loss_dice: 0.234127\n",
            "iteration 11887 : loss : 0.138329, loss_ce: 0.031607 loss_dice: 0.209477\n",
            "iteration 11888 : loss : 0.135805, loss_ce: 0.031052 loss_dice: 0.205640\n",
            "iteration 11889 : loss : 0.212580, loss_ce: 0.010840 loss_dice: 0.347074\n",
            "iteration 11890 : loss : 0.189950, loss_ce: 0.011940 loss_dice: 0.308624\n",
            "iteration 11891 : loss : 0.275200, loss_ce: 0.001639 loss_dice: 0.457575\n",
            "iteration 11892 : loss : 0.135985, loss_ce: 0.048782 loss_dice: 0.194120\n",
            "iteration 11893 : loss : 0.179905, loss_ce: 0.033856 loss_dice: 0.277271\n",
            "iteration 11894 : loss : 0.188208, loss_ce: 0.059171 loss_dice: 0.274233\n",
            "iteration 11895 : loss : 0.127189, loss_ce: 0.048356 loss_dice: 0.179744\n",
            "iteration 11896 : loss : 0.148582, loss_ce: 0.018056 loss_dice: 0.235600\n",
            "iteration 11897 : loss : 0.118692, loss_ce: 0.016106 loss_dice: 0.187083\n",
            "iteration 11898 : loss : 0.132230, loss_ce: 0.070399 loss_dice: 0.173450\n",
            "iteration 11899 : loss : 0.171581, loss_ce: 0.048962 loss_dice: 0.253327\n",
            "iteration 11900 : loss : 0.153521, loss_ce: 0.048022 loss_dice: 0.223853\n",
            "iteration 11901 : loss : 0.193958, loss_ce: 0.049112 loss_dice: 0.290521\n",
            "iteration 11902 : loss : 0.158042, loss_ce: 0.057600 loss_dice: 0.225004\n",
            "iteration 11903 : loss : 0.209709, loss_ce: 0.039942 loss_dice: 0.322887\n",
            "iteration 11904 : loss : 0.165483, loss_ce: 0.073417 loss_dice: 0.226860\n",
            "iteration 11905 : loss : 0.099201, loss_ce: 0.033255 loss_dice: 0.143165\n",
            "iteration 11906 : loss : 0.110742, loss_ce: 0.045438 loss_dice: 0.154278\n",
            "iteration 11907 : loss : 0.109278, loss_ce: 0.038300 loss_dice: 0.156596\n",
            "iteration 11908 : loss : 0.229074, loss_ce: 0.044901 loss_dice: 0.351855\n",
            "iteration 11909 : loss : 0.126289, loss_ce: 0.053663 loss_dice: 0.174706\n",
            "iteration 11910 : loss : 0.255518, loss_ce: 0.033091 loss_dice: 0.403803\n",
            "iteration 11911 : loss : 0.127576, loss_ce: 0.038457 loss_dice: 0.186989\n",
            "iteration 11912 : loss : 0.115600, loss_ce: 0.020151 loss_dice: 0.179232\n",
            "iteration 11913 : loss : 0.118095, loss_ce: 0.011730 loss_dice: 0.189005\n",
            "iteration 11914 : loss : 0.152604, loss_ce: 0.026685 loss_dice: 0.236551\n",
            "iteration 11915 : loss : 0.234792, loss_ce: 0.052135 loss_dice: 0.356564\n",
            "iteration 11916 : loss : 0.073136, loss_ce: 0.032396 loss_dice: 0.100296\n",
            "iteration 11917 : loss : 0.217206, loss_ce: 0.046633 loss_dice: 0.330922\n",
            "iteration 11918 : loss : 0.121685, loss_ce: 0.044930 loss_dice: 0.172855\n",
            "iteration 11919 : loss : 0.188407, loss_ce: 0.030042 loss_dice: 0.293984\n",
            "iteration 11920 : loss : 0.101865, loss_ce: 0.036845 loss_dice: 0.145212\n",
            "iteration 11921 : loss : 0.200044, loss_ce: 0.013810 loss_dice: 0.324200\n",
            "iteration 11922 : loss : 0.109512, loss_ce: 0.038496 loss_dice: 0.156856\n",
            "iteration 11923 : loss : 0.221772, loss_ce: 0.015400 loss_dice: 0.359352\n",
            "iteration 11924 : loss : 0.200684, loss_ce: 0.017188 loss_dice: 0.323014\n",
            "iteration 11925 : loss : 0.183226, loss_ce: 0.010373 loss_dice: 0.298462\n",
            "iteration 11926 : loss : 0.067875, loss_ce: 0.016525 loss_dice: 0.102109\n",
            "iteration 11927 : loss : 0.197349, loss_ce: 0.037355 loss_dice: 0.304011\n",
            "iteration 11928 : loss : 0.239773, loss_ce: 0.005467 loss_dice: 0.395976\n",
            "iteration 11929 : loss : 0.142355, loss_ce: 0.036747 loss_dice: 0.212760\n",
            "iteration 11930 : loss : 0.152999, loss_ce: 0.027377 loss_dice: 0.236747\n",
            "iteration 11931 : loss : 0.208096, loss_ce: 0.057448 loss_dice: 0.308528\n",
            "iteration 11932 : loss : 0.163083, loss_ce: 0.021561 loss_dice: 0.257430\n",
            "iteration 11933 : loss : 0.169294, loss_ce: 0.062753 loss_dice: 0.240322\n",
            "iteration 11934 : loss : 0.186409, loss_ce: 0.073349 loss_dice: 0.261782\n",
            "iteration 11935 : loss : 0.185303, loss_ce: 0.074063 loss_dice: 0.259464\n",
            "iteration 11936 : loss : 0.170285, loss_ce: 0.061642 loss_dice: 0.242713\n",
            "iteration 11937 : loss : 0.164771, loss_ce: 0.043914 loss_dice: 0.245342\n",
            "iteration 11938 : loss : 0.181161, loss_ce: 0.050370 loss_dice: 0.268354\n",
            "iteration 11939 : loss : 0.200170, loss_ce: 0.086484 loss_dice: 0.275961\n",
            "iteration 11940 : loss : 0.168219, loss_ce: 0.029291 loss_dice: 0.260839\n",
            "iteration 11941 : loss : 0.196286, loss_ce: 0.043589 loss_dice: 0.298085\n",
            "iteration 11942 : loss : 0.135311, loss_ce: 0.084851 loss_dice: 0.168951\n",
            "iteration 11943 : loss : 0.180648, loss_ce: 0.068516 loss_dice: 0.255402\n",
            "iteration 11944 : loss : 0.131586, loss_ce: 0.069776 loss_dice: 0.172794\n",
            "iteration 11945 : loss : 0.132495, loss_ce: 0.029171 loss_dice: 0.201377\n",
            "iteration 11946 : loss : 0.123107, loss_ce: 0.040554 loss_dice: 0.178142\n",
            "iteration 11947 : loss : 0.075218, loss_ce: 0.029790 loss_dice: 0.105504\n",
            "iteration 11948 : loss : 0.154013, loss_ce: 0.015871 loss_dice: 0.246108\n",
            "iteration 11949 : loss : 0.095505, loss_ce: 0.045766 loss_dice: 0.128665\n",
            "iteration 11950 : loss : 0.169733, loss_ce: 0.059410 loss_dice: 0.243282\n",
            "iteration 11951 : loss : 0.129308, loss_ce: 0.053947 loss_dice: 0.179549\n",
            "iteration 11952 : loss : 0.141167, loss_ce: 0.019985 loss_dice: 0.221955\n",
            "iteration 11953 : loss : 0.252168, loss_ce: 0.029860 loss_dice: 0.400373\n",
            "iteration 11954 : loss : 0.246049, loss_ce: 0.034257 loss_dice: 0.387244\n",
            "iteration 11955 : loss : 0.110190, loss_ce: 0.020573 loss_dice: 0.169935\n",
            "iteration 11956 : loss : 0.212484, loss_ce: 0.020192 loss_dice: 0.340679\n",
            "iteration 11957 : loss : 0.096846, loss_ce: 0.033072 loss_dice: 0.139363\n",
            "iteration 11958 : loss : 0.114546, loss_ce: 0.031570 loss_dice: 0.169863\n",
            "iteration 11959 : loss : 0.170884, loss_ce: 0.023035 loss_dice: 0.269451\n",
            "iteration 11960 : loss : 0.100571, loss_ce: 0.039508 loss_dice: 0.141280\n",
            "iteration 11961 : loss : 0.115478, loss_ce: 0.043661 loss_dice: 0.163357\n",
            "iteration 11962 : loss : 0.133624, loss_ce: 0.009099 loss_dice: 0.216641\n",
            "iteration 11963 : loss : 0.209223, loss_ce: 0.035629 loss_dice: 0.324952\n",
            "iteration 11964 : loss : 0.153207, loss_ce: 0.035903 loss_dice: 0.231409\n",
            "iteration 11965 : loss : 0.310459, loss_ce: 0.025355 loss_dice: 0.500529\n",
            "iteration 11966 : loss : 0.111364, loss_ce: 0.053723 loss_dice: 0.149791\n",
            "iteration 11967 : loss : 0.114035, loss_ce: 0.035008 loss_dice: 0.166721\n",
            "iteration 11968 : loss : 0.103500, loss_ce: 0.017078 loss_dice: 0.161115\n",
            "iteration 11969 : loss : 0.184801, loss_ce: 0.055133 loss_dice: 0.271247\n",
            "iteration 11970 : loss : 0.105450, loss_ce: 0.041434 loss_dice: 0.148127\n",
            "iteration 11971 : loss : 0.160942, loss_ce: 0.052405 loss_dice: 0.233300\n",
            "iteration 11972 : loss : 0.272440, loss_ce: 0.033052 loss_dice: 0.432032\n",
            "iteration 11973 : loss : 0.198578, loss_ce: 0.071334 loss_dice: 0.283407\n",
            "iteration 11974 : loss : 0.196159, loss_ce: 0.058270 loss_dice: 0.288085\n",
            "iteration 11975 : loss : 0.280539, loss_ce: 0.039318 loss_dice: 0.441354\n",
            "iteration 11976 : loss : 0.191883, loss_ce: 0.062391 loss_dice: 0.278211\n",
            "iteration 11977 : loss : 0.180312, loss_ce: 0.065674 loss_dice: 0.256738\n",
            "iteration 11978 : loss : 0.161507, loss_ce: 0.037545 loss_dice: 0.244149\n",
            "iteration 11979 : loss : 0.209472, loss_ce: 0.062347 loss_dice: 0.307555\n",
            "iteration 11980 : loss : 0.104528, loss_ce: 0.027226 loss_dice: 0.156063\n",
            "iteration 11981 : loss : 0.151511, loss_ce: 0.034011 loss_dice: 0.229844\n",
            "iteration 11982 : loss : 0.112299, loss_ce: 0.037736 loss_dice: 0.162008\n",
            "iteration 11983 : loss : 0.144081, loss_ce: 0.054637 loss_dice: 0.203710\n",
            "iteration 11984 : loss : 0.164734, loss_ce: 0.081308 loss_dice: 0.220351\n",
            "iteration 11985 : loss : 0.231530, loss_ce: 0.019349 loss_dice: 0.372985\n",
            "iteration 11986 : loss : 0.261957, loss_ce: 0.015577 loss_dice: 0.426211\n",
            "iteration 11987 : loss : 0.115316, loss_ce: 0.029302 loss_dice: 0.172658\n",
            "iteration 11988 : loss : 0.219870, loss_ce: 0.020497 loss_dice: 0.352784\n",
            " 11%|██▉                        | 54/500 [2:02:06<10:39:49, 86.07s/it]iteration 11989 : loss : 0.115710, loss_ce: 0.038943 loss_dice: 0.166888\n",
            "iteration 11990 : loss : 0.148548, loss_ce: 0.013296 loss_dice: 0.238716\n",
            "iteration 11991 : loss : 0.120554, loss_ce: 0.042138 loss_dice: 0.172831\n",
            "iteration 11992 : loss : 0.233133, loss_ce: 0.067959 loss_dice: 0.343249\n",
            "iteration 11993 : loss : 0.108143, loss_ce: 0.013609 loss_dice: 0.171165\n",
            "iteration 11994 : loss : 0.165951, loss_ce: 0.037141 loss_dice: 0.251824\n",
            "iteration 11995 : loss : 0.150789, loss_ce: 0.050797 loss_dice: 0.217450\n",
            "iteration 11996 : loss : 0.109035, loss_ce: 0.042703 loss_dice: 0.153256\n",
            "iteration 11997 : loss : 0.146444, loss_ce: 0.042604 loss_dice: 0.215670\n",
            "iteration 11998 : loss : 0.110716, loss_ce: 0.038226 loss_dice: 0.159042\n",
            "iteration 11999 : loss : 0.125802, loss_ce: 0.021870 loss_dice: 0.195090\n",
            "iteration 12000 : loss : 0.216000, loss_ce: 0.026793 loss_dice: 0.342138\n",
            "iteration 12001 : loss : 0.212488, loss_ce: 0.010438 loss_dice: 0.347188\n",
            "iteration 12002 : loss : 0.106243, loss_ce: 0.036525 loss_dice: 0.152722\n",
            "iteration 12003 : loss : 0.136341, loss_ce: 0.071529 loss_dice: 0.179549\n",
            "iteration 12004 : loss : 0.108381, loss_ce: 0.020392 loss_dice: 0.167041\n",
            "iteration 12005 : loss : 0.132750, loss_ce: 0.047414 loss_dice: 0.189640\n",
            "iteration 12006 : loss : 0.191772, loss_ce: 0.024467 loss_dice: 0.303308\n",
            "iteration 12007 : loss : 0.126990, loss_ce: 0.027772 loss_dice: 0.193135\n",
            "iteration 12008 : loss : 0.110353, loss_ce: 0.037033 loss_dice: 0.159233\n",
            "iteration 12009 : loss : 0.093772, loss_ce: 0.038681 loss_dice: 0.130499\n",
            "iteration 12010 : loss : 0.143903, loss_ce: 0.022529 loss_dice: 0.224819\n",
            "iteration 12011 : loss : 0.224008, loss_ce: 0.017225 loss_dice: 0.361863\n",
            "iteration 12012 : loss : 0.116836, loss_ce: 0.049097 loss_dice: 0.161996\n",
            "iteration 12013 : loss : 0.133618, loss_ce: 0.048040 loss_dice: 0.190669\n",
            "iteration 12014 : loss : 0.053762, loss_ce: 0.013913 loss_dice: 0.080327\n",
            "iteration 12015 : loss : 0.073734, loss_ce: 0.029198 loss_dice: 0.103424\n",
            "iteration 12016 : loss : 0.080321, loss_ce: 0.018244 loss_dice: 0.121707\n",
            "iteration 12017 : loss : 0.146388, loss_ce: 0.048577 loss_dice: 0.211594\n",
            "iteration 12018 : loss : 0.133197, loss_ce: 0.019000 loss_dice: 0.209328\n",
            "iteration 12019 : loss : 0.096173, loss_ce: 0.042072 loss_dice: 0.132241\n",
            "iteration 12020 : loss : 0.150741, loss_ce: 0.032690 loss_dice: 0.229442\n",
            "iteration 12021 : loss : 0.086803, loss_ce: 0.033018 loss_dice: 0.122660\n",
            "iteration 12022 : loss : 0.072234, loss_ce: 0.018469 loss_dice: 0.108077\n",
            "iteration 12023 : loss : 0.149378, loss_ce: 0.035469 loss_dice: 0.225316\n",
            "iteration 12024 : loss : 0.067530, loss_ce: 0.021484 loss_dice: 0.098228\n",
            "iteration 12025 : loss : 0.055867, loss_ce: 0.032766 loss_dice: 0.071268\n",
            "iteration 12026 : loss : 0.105606, loss_ce: 0.011570 loss_dice: 0.168296\n",
            "iteration 12027 : loss : 0.110473, loss_ce: 0.060058 loss_dice: 0.144082\n",
            "iteration 12028 : loss : 0.074594, loss_ce: 0.023231 loss_dice: 0.108836\n",
            "iteration 12029 : loss : 0.084788, loss_ce: 0.018636 loss_dice: 0.128890\n",
            "iteration 12030 : loss : 0.118860, loss_ce: 0.035225 loss_dice: 0.174617\n",
            "iteration 12031 : loss : 0.132548, loss_ce: 0.022357 loss_dice: 0.206009\n",
            "iteration 12032 : loss : 0.135114, loss_ce: 0.058333 loss_dice: 0.186301\n",
            "iteration 12033 : loss : 0.063267, loss_ce: 0.025081 loss_dice: 0.088724\n",
            "iteration 12034 : loss : 0.230898, loss_ce: 0.012325 loss_dice: 0.376613\n",
            "iteration 12035 : loss : 0.124718, loss_ce: 0.018559 loss_dice: 0.195490\n",
            "iteration 12036 : loss : 0.161998, loss_ce: 0.023053 loss_dice: 0.254628\n",
            "iteration 12037 : loss : 0.106512, loss_ce: 0.035072 loss_dice: 0.154139\n",
            "iteration 12038 : loss : 0.122959, loss_ce: 0.035853 loss_dice: 0.181029\n",
            "iteration 12039 : loss : 0.110952, loss_ce: 0.024914 loss_dice: 0.168310\n",
            "iteration 12040 : loss : 0.099167, loss_ce: 0.014287 loss_dice: 0.155753\n",
            "iteration 12041 : loss : 0.072182, loss_ce: 0.020946 loss_dice: 0.106340\n",
            "iteration 12042 : loss : 0.159074, loss_ce: 0.009744 loss_dice: 0.258627\n",
            "iteration 12043 : loss : 0.188569, loss_ce: 0.020350 loss_dice: 0.300715\n",
            "iteration 12044 : loss : 0.126850, loss_ce: 0.052171 loss_dice: 0.176636\n",
            "iteration 12045 : loss : 0.224377, loss_ce: 0.007084 loss_dice: 0.369240\n",
            "iteration 12046 : loss : 0.116991, loss_ce: 0.029246 loss_dice: 0.175488\n",
            "iteration 12047 : loss : 0.089166, loss_ce: 0.027556 loss_dice: 0.130240\n",
            "iteration 12048 : loss : 0.166297, loss_ce: 0.044224 loss_dice: 0.247679\n",
            "iteration 12049 : loss : 0.256480, loss_ce: 0.018456 loss_dice: 0.415162\n",
            "iteration 12050 : loss : 0.137160, loss_ce: 0.022208 loss_dice: 0.213795\n",
            "iteration 12051 : loss : 0.090031, loss_ce: 0.016013 loss_dice: 0.139377\n",
            "iteration 12052 : loss : 0.103918, loss_ce: 0.017026 loss_dice: 0.161846\n",
            "iteration 12053 : loss : 0.135105, loss_ce: 0.025979 loss_dice: 0.207856\n",
            "iteration 12054 : loss : 0.138761, loss_ce: 0.035458 loss_dice: 0.207629\n",
            "iteration 12055 : loss : 0.139358, loss_ce: 0.020630 loss_dice: 0.218509\n",
            "iteration 12056 : loss : 0.072577, loss_ce: 0.018854 loss_dice: 0.108392\n",
            "iteration 12057 : loss : 0.079137, loss_ce: 0.025299 loss_dice: 0.115029\n",
            "iteration 12058 : loss : 0.099597, loss_ce: 0.042254 loss_dice: 0.137826\n",
            "iteration 12059 : loss : 0.161213, loss_ce: 0.037753 loss_dice: 0.243519\n",
            "iteration 12060 : loss : 0.168949, loss_ce: 0.017868 loss_dice: 0.269670\n",
            "iteration 12061 : loss : 0.133262, loss_ce: 0.039062 loss_dice: 0.196062\n",
            "iteration 12062 : loss : 0.079393, loss_ce: 0.013135 loss_dice: 0.123564\n",
            "iteration 12063 : loss : 0.072404, loss_ce: 0.022970 loss_dice: 0.105360\n",
            "iteration 12064 : loss : 0.096330, loss_ce: 0.026113 loss_dice: 0.143142\n",
            "iteration 12065 : loss : 0.098737, loss_ce: 0.007877 loss_dice: 0.159310\n",
            "iteration 12066 : loss : 0.163392, loss_ce: 0.060200 loss_dice: 0.232187\n",
            "iteration 12067 : loss : 0.188377, loss_ce: 0.023191 loss_dice: 0.298500\n",
            "iteration 12068 : loss : 0.143301, loss_ce: 0.028115 loss_dice: 0.220092\n",
            "iteration 12069 : loss : 0.118090, loss_ce: 0.024434 loss_dice: 0.180527\n",
            "iteration 12070 : loss : 0.079926, loss_ce: 0.027300 loss_dice: 0.115009\n",
            "iteration 12071 : loss : 0.106456, loss_ce: 0.044012 loss_dice: 0.148085\n",
            "iteration 12072 : loss : 0.082272, loss_ce: 0.035889 loss_dice: 0.113195\n",
            "iteration 12073 : loss : 0.099034, loss_ce: 0.009355 loss_dice: 0.158819\n",
            "iteration 12074 : loss : 0.103698, loss_ce: 0.044655 loss_dice: 0.143060\n",
            "iteration 12075 : loss : 0.128223, loss_ce: 0.063554 loss_dice: 0.171336\n",
            "iteration 12076 : loss : 0.100534, loss_ce: 0.039177 loss_dice: 0.141439\n",
            "iteration 12077 : loss : 0.160366, loss_ce: 0.006945 loss_dice: 0.262647\n",
            "iteration 12078 : loss : 0.084421, loss_ce: 0.022644 loss_dice: 0.125606\n",
            "iteration 12079 : loss : 0.092124, loss_ce: 0.022202 loss_dice: 0.138739\n",
            "iteration 12080 : loss : 0.157737, loss_ce: 0.056206 loss_dice: 0.225424\n",
            "iteration 12081 : loss : 0.149688, loss_ce: 0.030935 loss_dice: 0.228856\n",
            "iteration 12082 : loss : 0.122921, loss_ce: 0.034611 loss_dice: 0.181794\n",
            "iteration 12083 : loss : 0.072301, loss_ce: 0.018535 loss_dice: 0.108144\n",
            "iteration 12084 : loss : 0.111484, loss_ce: 0.034834 loss_dice: 0.162585\n",
            "iteration 12085 : loss : 0.052637, loss_ce: 0.021576 loss_dice: 0.073345\n",
            "iteration 12086 : loss : 0.136805, loss_ce: 0.025674 loss_dice: 0.210892\n",
            "iteration 12087 : loss : 0.082882, loss_ce: 0.031981 loss_dice: 0.116817\n",
            "iteration 12088 : loss : 0.137249, loss_ce: 0.043287 loss_dice: 0.199890\n",
            "iteration 12089 : loss : 0.214142, loss_ce: 0.043995 loss_dice: 0.327573\n",
            "iteration 12090 : loss : 0.105569, loss_ce: 0.046777 loss_dice: 0.144764\n",
            "iteration 12091 : loss : 0.162430, loss_ce: 0.039264 loss_dice: 0.244540\n",
            "iteration 12092 : loss : 0.122977, loss_ce: 0.037165 loss_dice: 0.180185\n",
            "iteration 12093 : loss : 0.147001, loss_ce: 0.035956 loss_dice: 0.221030\n",
            "iteration 12094 : loss : 0.209771, loss_ce: 0.069707 loss_dice: 0.303147\n",
            "iteration 12095 : loss : 0.157519, loss_ce: 0.041204 loss_dice: 0.235062\n",
            "iteration 12096 : loss : 0.144913, loss_ce: 0.022875 loss_dice: 0.226271\n",
            "iteration 12097 : loss : 0.080946, loss_ce: 0.024617 loss_dice: 0.118499\n",
            "iteration 12098 : loss : 0.061532, loss_ce: 0.007120 loss_dice: 0.097807\n",
            "iteration 12099 : loss : 0.110000, loss_ce: 0.021762 loss_dice: 0.168825\n",
            "iteration 12100 : loss : 0.137144, loss_ce: 0.025181 loss_dice: 0.211786\n",
            "iteration 12101 : loss : 0.137231, loss_ce: 0.035832 loss_dice: 0.204831\n",
            "iteration 12102 : loss : 0.316919, loss_ce: 0.008507 loss_dice: 0.522528\n",
            "iteration 12103 : loss : 0.168591, loss_ce: 0.026620 loss_dice: 0.263238\n",
            "iteration 12104 : loss : 0.087890, loss_ce: 0.021508 loss_dice: 0.132145\n",
            "iteration 12105 : loss : 0.139556, loss_ce: 0.032079 loss_dice: 0.211208\n",
            "iteration 12106 : loss : 0.104148, loss_ce: 0.026683 loss_dice: 0.155791\n",
            "iteration 12107 : loss : 0.144548, loss_ce: 0.028257 loss_dice: 0.222076\n",
            "iteration 12108 : loss : 0.152604, loss_ce: 0.029711 loss_dice: 0.234532\n",
            "iteration 12109 : loss : 0.134793, loss_ce: 0.026323 loss_dice: 0.207106\n",
            "iteration 12110 : loss : 0.111717, loss_ce: 0.040573 loss_dice: 0.159145\n",
            "iteration 12111 : loss : 0.374913, loss_ce: 0.014624 loss_dice: 0.615106\n",
            "iteration 12112 : loss : 0.068942, loss_ce: 0.017408 loss_dice: 0.103298\n",
            "iteration 12113 : loss : 0.265893, loss_ce: 0.010646 loss_dice: 0.436057\n",
            "iteration 12114 : loss : 0.188818, loss_ce: 0.010711 loss_dice: 0.307557\n",
            "iteration 12115 : loss : 0.106281, loss_ce: 0.063754 loss_dice: 0.134632\n",
            "iteration 12116 : loss : 0.165964, loss_ce: 0.018231 loss_dice: 0.264452\n",
            "iteration 12117 : loss : 0.186582, loss_ce: 0.006409 loss_dice: 0.306697\n",
            "iteration 12118 : loss : 0.130617, loss_ce: 0.041385 loss_dice: 0.190105\n",
            "iteration 12119 : loss : 0.064889, loss_ce: 0.013201 loss_dice: 0.099349\n",
            "iteration 12120 : loss : 0.122749, loss_ce: 0.027092 loss_dice: 0.186520\n",
            "iteration 12121 : loss : 0.132935, loss_ce: 0.020825 loss_dice: 0.207674\n",
            "iteration 12122 : loss : 0.150071, loss_ce: 0.032194 loss_dice: 0.228655\n",
            "iteration 12123 : loss : 0.157959, loss_ce: 0.022948 loss_dice: 0.247967\n",
            "iteration 12124 : loss : 0.119807, loss_ce: 0.058077 loss_dice: 0.160960\n",
            "iteration 12125 : loss : 0.115194, loss_ce: 0.006447 loss_dice: 0.187691\n",
            "iteration 12126 : loss : 0.167722, loss_ce: 0.010364 loss_dice: 0.272628\n",
            "iteration 12127 : loss : 0.143591, loss_ce: 0.030307 loss_dice: 0.219114\n",
            "iteration 12128 : loss : 0.124004, loss_ce: 0.030107 loss_dice: 0.186602\n",
            "iteration 12129 : loss : 0.164701, loss_ce: 0.042899 loss_dice: 0.245901\n",
            "iteration 12130 : loss : 0.131378, loss_ce: 0.010317 loss_dice: 0.212085\n",
            "iteration 12131 : loss : 0.080756, loss_ce: 0.018873 loss_dice: 0.122011\n",
            "iteration 12132 : loss : 0.302382, loss_ce: 0.019727 loss_dice: 0.490819\n",
            "iteration 12133 : loss : 0.176909, loss_ce: 0.036319 loss_dice: 0.270635\n",
            "iteration 12134 : loss : 0.143539, loss_ce: 0.033912 loss_dice: 0.216624\n",
            "iteration 12135 : loss : 0.118088, loss_ce: 0.043751 loss_dice: 0.167646\n",
            "iteration 12136 : loss : 0.130271, loss_ce: 0.027733 loss_dice: 0.198629\n",
            "iteration 12137 : loss : 0.128718, loss_ce: 0.038895 loss_dice: 0.188599\n",
            "iteration 12138 : loss : 0.106390, loss_ce: 0.022791 loss_dice: 0.162122\n",
            "iteration 12139 : loss : 0.087125, loss_ce: 0.035807 loss_dice: 0.121337\n",
            "iteration 12140 : loss : 0.090510, loss_ce: 0.021780 loss_dice: 0.136330\n",
            "iteration 12141 : loss : 0.165405, loss_ce: 0.036043 loss_dice: 0.251647\n",
            "iteration 12142 : loss : 0.135335, loss_ce: 0.027312 loss_dice: 0.207351\n",
            "iteration 12143 : loss : 0.165825, loss_ce: 0.020474 loss_dice: 0.262726\n",
            "iteration 12144 : loss : 0.255592, loss_ce: 0.005510 loss_dice: 0.422313\n",
            "iteration 12145 : loss : 0.116193, loss_ce: 0.042572 loss_dice: 0.165274\n",
            "iteration 12146 : loss : 0.103874, loss_ce: 0.025837 loss_dice: 0.155898\n",
            "iteration 12147 : loss : 0.111060, loss_ce: 0.037627 loss_dice: 0.160015\n",
            "iteration 12148 : loss : 0.201914, loss_ce: 0.044246 loss_dice: 0.307025\n",
            "iteration 12149 : loss : 0.157980, loss_ce: 0.024716 loss_dice: 0.246822\n",
            "iteration 12150 : loss : 0.134907, loss_ce: 0.035832 loss_dice: 0.200957\n",
            "iteration 12151 : loss : 0.078965, loss_ce: 0.033869 loss_dice: 0.109029\n",
            "iteration 12152 : loss : 0.100453, loss_ce: 0.022040 loss_dice: 0.152729\n",
            "iteration 12153 : loss : 0.094155, loss_ce: 0.032355 loss_dice: 0.135355\n",
            "iteration 12154 : loss : 0.140899, loss_ce: 0.045581 loss_dice: 0.204445\n",
            "iteration 12155 : loss : 0.129640, loss_ce: 0.019886 loss_dice: 0.202810\n",
            "iteration 12156 : loss : 0.130082, loss_ce: 0.023565 loss_dice: 0.201094\n",
            "iteration 12157 : loss : 0.151290, loss_ce: 0.018369 loss_dice: 0.239904\n",
            "iteration 12158 : loss : 0.109440, loss_ce: 0.040650 loss_dice: 0.155299\n",
            "iteration 12159 : loss : 0.086797, loss_ce: 0.025100 loss_dice: 0.127928\n",
            "iteration 12160 : loss : 0.132045, loss_ce: 0.024696 loss_dice: 0.203611\n",
            "iteration 12161 : loss : 0.153521, loss_ce: 0.024444 loss_dice: 0.239572\n",
            "iteration 12162 : loss : 0.097233, loss_ce: 0.043767 loss_dice: 0.132877\n",
            "iteration 12163 : loss : 0.097125, loss_ce: 0.029182 loss_dice: 0.142420\n",
            "iteration 12164 : loss : 0.090890, loss_ce: 0.029711 loss_dice: 0.131676\n",
            "iteration 12165 : loss : 0.099433, loss_ce: 0.019499 loss_dice: 0.152723\n",
            "iteration 12166 : loss : 0.275599, loss_ce: 0.005674 loss_dice: 0.455548\n",
            "iteration 12167 : loss : 0.085154, loss_ce: 0.015345 loss_dice: 0.131693\n",
            "iteration 12168 : loss : 0.085207, loss_ce: 0.022251 loss_dice: 0.127178\n",
            "iteration 12169 : loss : 0.085149, loss_ce: 0.039766 loss_dice: 0.115405\n",
            "iteration 12170 : loss : 0.131227, loss_ce: 0.019479 loss_dice: 0.205727\n",
            "iteration 12171 : loss : 0.133381, loss_ce: 0.034916 loss_dice: 0.199024\n",
            "iteration 12172 : loss : 0.097097, loss_ce: 0.023137 loss_dice: 0.146404\n",
            "iteration 12173 : loss : 0.225842, loss_ce: 0.026038 loss_dice: 0.359045\n",
            "iteration 12174 : loss : 0.183977, loss_ce: 0.027967 loss_dice: 0.287984\n",
            "iteration 12175 : loss : 0.152838, loss_ce: 0.036712 loss_dice: 0.230256\n",
            "iteration 12176 : loss : 0.081650, loss_ce: 0.025632 loss_dice: 0.118995\n",
            "iteration 12177 : loss : 0.183359, loss_ce: 0.049491 loss_dice: 0.272605\n",
            "iteration 12178 : loss : 0.159784, loss_ce: 0.028623 loss_dice: 0.247224\n",
            "iteration 12179 : loss : 0.271928, loss_ce: 0.064718 loss_dice: 0.410068\n",
            "iteration 12180 : loss : 0.222205, loss_ce: 0.094528 loss_dice: 0.307323\n",
            "iteration 12181 : loss : 0.160700, loss_ce: 0.065279 loss_dice: 0.224314\n",
            "iteration 12182 : loss : 0.191973, loss_ce: 0.039508 loss_dice: 0.293615\n",
            "iteration 12183 : loss : 0.213647, loss_ce: 0.099342 loss_dice: 0.289851\n",
            "iteration 12184 : loss : 0.124278, loss_ce: 0.025155 loss_dice: 0.190361\n",
            "iteration 12185 : loss : 0.186450, loss_ce: 0.039276 loss_dice: 0.284566\n",
            "iteration 12186 : loss : 0.214605, loss_ce: 0.094014 loss_dice: 0.295000\n",
            "iteration 12187 : loss : 0.192173, loss_ce: 0.064607 loss_dice: 0.277217\n",
            "iteration 12188 : loss : 0.167827, loss_ce: 0.030573 loss_dice: 0.259330\n",
            "iteration 12189 : loss : 0.209803, loss_ce: 0.073535 loss_dice: 0.300649\n",
            "iteration 12190 : loss : 0.170866, loss_ce: 0.045170 loss_dice: 0.254663\n",
            "iteration 12191 : loss : 0.121177, loss_ce: 0.010941 loss_dice: 0.194668\n",
            "iteration 12192 : loss : 0.184369, loss_ce: 0.032129 loss_dice: 0.285862\n",
            "iteration 12193 : loss : 0.179311, loss_ce: 0.086791 loss_dice: 0.240991\n",
            "iteration 12194 : loss : 0.160016, loss_ce: 0.040320 loss_dice: 0.239812\n",
            "iteration 12195 : loss : 0.159547, loss_ce: 0.054255 loss_dice: 0.229742\n",
            "iteration 12196 : loss : 0.176278, loss_ce: 0.053823 loss_dice: 0.257914\n",
            "iteration 12197 : loss : 0.201760, loss_ce: 0.089548 loss_dice: 0.276568\n",
            "iteration 12198 : loss : 0.172383, loss_ce: 0.074611 loss_dice: 0.237563\n",
            "iteration 12199 : loss : 0.150714, loss_ce: 0.080155 loss_dice: 0.197753\n",
            "iteration 12200 : loss : 0.220095, loss_ce: 0.109816 loss_dice: 0.293615\n",
            "iteration 12201 : loss : 0.299282, loss_ce: 0.022545 loss_dice: 0.483774\n",
            "iteration 12202 : loss : 0.178477, loss_ce: 0.101373 loss_dice: 0.229879\n",
            "iteration 12203 : loss : 0.186392, loss_ce: 0.046887 loss_dice: 0.279395\n",
            "iteration 12204 : loss : 0.113555, loss_ce: 0.021834 loss_dice: 0.174702\n",
            "iteration 12205 : loss : 0.168705, loss_ce: 0.042508 loss_dice: 0.252836\n",
            "iteration 12206 : loss : 0.166276, loss_ce: 0.064048 loss_dice: 0.234428\n",
            "iteration 12207 : loss : 0.155961, loss_ce: 0.043099 loss_dice: 0.231202\n",
            "iteration 12208 : loss : 0.169438, loss_ce: 0.022381 loss_dice: 0.267476\n",
            "iteration 12209 : loss : 0.162208, loss_ce: 0.064868 loss_dice: 0.227101\n",
            "iteration 12210 : loss : 0.244151, loss_ce: 0.000779 loss_dice: 0.406399\n",
            " 11%|██▉                        | 55/500 [2:03:29<10:32:14, 85.25s/it]iteration 12211 : loss : 0.158224, loss_ce: 0.052603 loss_dice: 0.228637\n",
            "iteration 12212 : loss : 0.197002, loss_ce: 0.047909 loss_dice: 0.296397\n",
            "iteration 12213 : loss : 0.163332, loss_ce: 0.004209 loss_dice: 0.269413\n",
            "iteration 12214 : loss : 0.268084, loss_ce: 0.159136 loss_dice: 0.340715\n",
            "iteration 12215 : loss : 0.237092, loss_ce: 0.094769 loss_dice: 0.331974\n",
            "iteration 12216 : loss : 0.243054, loss_ce: 0.169672 loss_dice: 0.291976\n",
            "iteration 12217 : loss : 0.191889, loss_ce: 0.050315 loss_dice: 0.286271\n",
            "iteration 12218 : loss : 0.241485, loss_ce: 0.041531 loss_dice: 0.374788\n",
            "iteration 12219 : loss : 0.206951, loss_ce: 0.100001 loss_dice: 0.278250\n",
            "iteration 12220 : loss : 0.176964, loss_ce: 0.057473 loss_dice: 0.256625\n",
            "iteration 12221 : loss : 0.196608, loss_ce: 0.060336 loss_dice: 0.287456\n",
            "iteration 12222 : loss : 0.230435, loss_ce: 0.095722 loss_dice: 0.320243\n",
            "iteration 12223 : loss : 0.238762, loss_ce: 0.092244 loss_dice: 0.336440\n",
            "iteration 12224 : loss : 0.190743, loss_ce: 0.055244 loss_dice: 0.281075\n",
            "iteration 12225 : loss : 0.178156, loss_ce: 0.048516 loss_dice: 0.264583\n",
            "iteration 12226 : loss : 0.169879, loss_ce: 0.043050 loss_dice: 0.254431\n",
            "iteration 12227 : loss : 0.213238, loss_ce: 0.061416 loss_dice: 0.314452\n",
            "iteration 12228 : loss : 0.273718, loss_ce: 0.007652 loss_dice: 0.451095\n",
            "iteration 12229 : loss : 0.199704, loss_ce: 0.086659 loss_dice: 0.275068\n",
            "iteration 12230 : loss : 0.110607, loss_ce: 0.053026 loss_dice: 0.148994\n",
            "iteration 12231 : loss : 0.096814, loss_ce: 0.044354 loss_dice: 0.131787\n",
            "iteration 12232 : loss : 0.196744, loss_ce: 0.023396 loss_dice: 0.312308\n",
            "iteration 12233 : loss : 0.188020, loss_ce: 0.062677 loss_dice: 0.271583\n",
            "iteration 12234 : loss : 0.128958, loss_ce: 0.032601 loss_dice: 0.193196\n",
            "iteration 12235 : loss : 0.112902, loss_ce: 0.059213 loss_dice: 0.148694\n",
            "iteration 12236 : loss : 0.222057, loss_ce: 0.135838 loss_dice: 0.279535\n",
            "iteration 12237 : loss : 0.166635, loss_ce: 0.027241 loss_dice: 0.259565\n",
            "iteration 12238 : loss : 0.320852, loss_ce: 0.019662 loss_dice: 0.521646\n",
            "iteration 12239 : loss : 0.139905, loss_ce: 0.020464 loss_dice: 0.219533\n",
            "iteration 12240 : loss : 0.173649, loss_ce: 0.042380 loss_dice: 0.261161\n",
            "iteration 12241 : loss : 0.141783, loss_ce: 0.038450 loss_dice: 0.210672\n",
            "iteration 12242 : loss : 0.203827, loss_ce: 0.116353 loss_dice: 0.262143\n",
            "iteration 12243 : loss : 0.179497, loss_ce: 0.059580 loss_dice: 0.259443\n",
            "iteration 12244 : loss : 0.163300, loss_ce: 0.045080 loss_dice: 0.242113\n",
            "iteration 12245 : loss : 0.124771, loss_ce: 0.053328 loss_dice: 0.172400\n",
            "iteration 12246 : loss : 0.139463, loss_ce: 0.023374 loss_dice: 0.216855\n",
            "iteration 12247 : loss : 0.237374, loss_ce: 0.043375 loss_dice: 0.366707\n",
            "iteration 12248 : loss : 0.140857, loss_ce: 0.019363 loss_dice: 0.221853\n",
            "iteration 12249 : loss : 0.207803, loss_ce: 0.043133 loss_dice: 0.317584\n",
            "iteration 12250 : loss : 0.165141, loss_ce: 0.019619 loss_dice: 0.262156\n",
            "iteration 12251 : loss : 0.156831, loss_ce: 0.027166 loss_dice: 0.243275\n",
            "iteration 12252 : loss : 0.070867, loss_ce: 0.028094 loss_dice: 0.099382\n",
            "iteration 12253 : loss : 0.154435, loss_ce: 0.020903 loss_dice: 0.243456\n",
            "iteration 12254 : loss : 0.227223, loss_ce: 0.036778 loss_dice: 0.354187\n",
            "iteration 12255 : loss : 0.095838, loss_ce: 0.031206 loss_dice: 0.138926\n",
            "iteration 12256 : loss : 0.079356, loss_ce: 0.034208 loss_dice: 0.109454\n",
            "iteration 12257 : loss : 0.090428, loss_ce: 0.026725 loss_dice: 0.132896\n",
            "iteration 12258 : loss : 0.071093, loss_ce: 0.014747 loss_dice: 0.108657\n",
            "iteration 12259 : loss : 0.136526, loss_ce: 0.029445 loss_dice: 0.207913\n",
            "iteration 12260 : loss : 0.108977, loss_ce: 0.039142 loss_dice: 0.155533\n",
            "iteration 12261 : loss : 0.119551, loss_ce: 0.011662 loss_dice: 0.191477\n",
            "iteration 12262 : loss : 0.066107, loss_ce: 0.030224 loss_dice: 0.090029\n",
            "iteration 12263 : loss : 0.108047, loss_ce: 0.024908 loss_dice: 0.163473\n",
            "iteration 12264 : loss : 0.088278, loss_ce: 0.017915 loss_dice: 0.135188\n",
            "iteration 12265 : loss : 0.149681, loss_ce: 0.052316 loss_dice: 0.214591\n",
            "iteration 12266 : loss : 0.180328, loss_ce: 0.054020 loss_dice: 0.264534\n",
            "iteration 12267 : loss : 0.098574, loss_ce: 0.007375 loss_dice: 0.159372\n",
            "iteration 12268 : loss : 0.248435, loss_ce: 0.038950 loss_dice: 0.388091\n",
            "iteration 12269 : loss : 0.233019, loss_ce: 0.075255 loss_dice: 0.338195\n",
            "iteration 12270 : loss : 0.163825, loss_ce: 0.038975 loss_dice: 0.247058\n",
            "iteration 12271 : loss : 0.074456, loss_ce: 0.015461 loss_dice: 0.113786\n",
            "iteration 12272 : loss : 0.060204, loss_ce: 0.013605 loss_dice: 0.091270\n",
            "iteration 12273 : loss : 0.097115, loss_ce: 0.032822 loss_dice: 0.139977\n",
            "iteration 12274 : loss : 0.110707, loss_ce: 0.042980 loss_dice: 0.155858\n",
            "iteration 12275 : loss : 0.137688, loss_ce: 0.038265 loss_dice: 0.203970\n",
            "iteration 12276 : loss : 0.146327, loss_ce: 0.018206 loss_dice: 0.231742\n",
            "iteration 12277 : loss : 0.095811, loss_ce: 0.018052 loss_dice: 0.147649\n",
            "iteration 12278 : loss : 0.126600, loss_ce: 0.031435 loss_dice: 0.190043\n",
            "iteration 12279 : loss : 0.151410, loss_ce: 0.027788 loss_dice: 0.233824\n",
            "iteration 12280 : loss : 0.097521, loss_ce: 0.028384 loss_dice: 0.143612\n",
            "iteration 12281 : loss : 0.117401, loss_ce: 0.060819 loss_dice: 0.155123\n",
            "iteration 12282 : loss : 0.077376, loss_ce: 0.027493 loss_dice: 0.110631\n",
            "iteration 12283 : loss : 0.149914, loss_ce: 0.023809 loss_dice: 0.233984\n",
            "iteration 12284 : loss : 0.121349, loss_ce: 0.031310 loss_dice: 0.181375\n",
            "iteration 12285 : loss : 0.130829, loss_ce: 0.025471 loss_dice: 0.201068\n",
            "iteration 12286 : loss : 0.153869, loss_ce: 0.044158 loss_dice: 0.227009\n",
            "iteration 12287 : loss : 0.152162, loss_ce: 0.058940 loss_dice: 0.214310\n",
            "iteration 12288 : loss : 0.120578, loss_ce: 0.035943 loss_dice: 0.177002\n",
            "iteration 12289 : loss : 0.221472, loss_ce: 0.006062 loss_dice: 0.365078\n",
            "iteration 12290 : loss : 0.188456, loss_ce: 0.133536 loss_dice: 0.225070\n",
            "iteration 12291 : loss : 0.101662, loss_ce: 0.046464 loss_dice: 0.138460\n",
            "iteration 12292 : loss : 0.079559, loss_ce: 0.041663 loss_dice: 0.104824\n",
            "iteration 12293 : loss : 0.075123, loss_ce: 0.038248 loss_dice: 0.099707\n",
            "iteration 12294 : loss : 0.180158, loss_ce: 0.014592 loss_dice: 0.290536\n",
            "iteration 12295 : loss : 0.114475, loss_ce: 0.076665 loss_dice: 0.139681\n",
            "iteration 12296 : loss : 0.292072, loss_ce: 0.005317 loss_dice: 0.483243\n",
            "iteration 12297 : loss : 0.136894, loss_ce: 0.015887 loss_dice: 0.217565\n",
            "iteration 12298 : loss : 0.150736, loss_ce: 0.068809 loss_dice: 0.205354\n",
            "iteration 12299 : loss : 0.086215, loss_ce: 0.032920 loss_dice: 0.121746\n",
            "iteration 12300 : loss : 0.090165, loss_ce: 0.029815 loss_dice: 0.130398\n",
            "iteration 12301 : loss : 0.106038, loss_ce: 0.022335 loss_dice: 0.161841\n",
            "iteration 12302 : loss : 0.082865, loss_ce: 0.032472 loss_dice: 0.116460\n",
            "iteration 12303 : loss : 0.101949, loss_ce: 0.012161 loss_dice: 0.161807\n",
            "iteration 12304 : loss : 0.136328, loss_ce: 0.023257 loss_dice: 0.211709\n",
            "iteration 12305 : loss : 0.140775, loss_ce: 0.032907 loss_dice: 0.212686\n",
            "iteration 12306 : loss : 0.105635, loss_ce: 0.032623 loss_dice: 0.154309\n",
            "iteration 12307 : loss : 0.104456, loss_ce: 0.038948 loss_dice: 0.148128\n",
            "iteration 12308 : loss : 0.086697, loss_ce: 0.024003 loss_dice: 0.128493\n",
            "iteration 12309 : loss : 0.062840, loss_ce: 0.017649 loss_dice: 0.092968\n",
            "iteration 12310 : loss : 0.078087, loss_ce: 0.028205 loss_dice: 0.111341\n",
            "iteration 12311 : loss : 0.128528, loss_ce: 0.020205 loss_dice: 0.200743\n",
            "iteration 12312 : loss : 0.082810, loss_ce: 0.007840 loss_dice: 0.132790\n",
            "iteration 12313 : loss : 0.116024, loss_ce: 0.034380 loss_dice: 0.170454\n",
            "iteration 12314 : loss : 0.145244, loss_ce: 0.022120 loss_dice: 0.227326\n",
            "iteration 12315 : loss : 0.147536, loss_ce: 0.027822 loss_dice: 0.227345\n",
            "iteration 12316 : loss : 0.126065, loss_ce: 0.018496 loss_dice: 0.197778\n",
            "iteration 12317 : loss : 0.143336, loss_ce: 0.014525 loss_dice: 0.229210\n",
            "iteration 12318 : loss : 0.136134, loss_ce: 0.023103 loss_dice: 0.211489\n",
            "iteration 12319 : loss : 0.235491, loss_ce: 0.017723 loss_dice: 0.380670\n",
            "iteration 12320 : loss : 0.165121, loss_ce: 0.023026 loss_dice: 0.259852\n",
            "iteration 12321 : loss : 0.078924, loss_ce: 0.020108 loss_dice: 0.118135\n",
            "iteration 12322 : loss : 0.100845, loss_ce: 0.035628 loss_dice: 0.144323\n",
            "iteration 12323 : loss : 0.072279, loss_ce: 0.025639 loss_dice: 0.103373\n",
            "iteration 12324 : loss : 0.090568, loss_ce: 0.044779 loss_dice: 0.121094\n",
            "iteration 12325 : loss : 0.138495, loss_ce: 0.027889 loss_dice: 0.212233\n",
            "iteration 12326 : loss : 0.178445, loss_ce: 0.028631 loss_dice: 0.278321\n",
            "iteration 12327 : loss : 0.125079, loss_ce: 0.020785 loss_dice: 0.194608\n",
            "iteration 12328 : loss : 0.103996, loss_ce: 0.039495 loss_dice: 0.146997\n",
            "iteration 12329 : loss : 0.123194, loss_ce: 0.017448 loss_dice: 0.193691\n",
            "iteration 12330 : loss : 0.100453, loss_ce: 0.019202 loss_dice: 0.154621\n",
            "iteration 12331 : loss : 0.066529, loss_ce: 0.019481 loss_dice: 0.097894\n",
            "iteration 12332 : loss : 0.225278, loss_ce: 0.003801 loss_dice: 0.372929\n",
            "iteration 12333 : loss : 0.231420, loss_ce: 0.020320 loss_dice: 0.372153\n",
            "iteration 12334 : loss : 0.147308, loss_ce: 0.005921 loss_dice: 0.241566\n",
            "iteration 12335 : loss : 0.177294, loss_ce: 0.061695 loss_dice: 0.254361\n",
            "iteration 12336 : loss : 0.177669, loss_ce: 0.073836 loss_dice: 0.246891\n",
            "iteration 12337 : loss : 0.141539, loss_ce: 0.041476 loss_dice: 0.208248\n",
            "iteration 12338 : loss : 0.142347, loss_ce: 0.061440 loss_dice: 0.196285\n",
            "iteration 12339 : loss : 0.178701, loss_ce: 0.052711 loss_dice: 0.262694\n",
            "iteration 12340 : loss : 0.158015, loss_ce: 0.057682 loss_dice: 0.224903\n",
            "iteration 12341 : loss : 0.180854, loss_ce: 0.025967 loss_dice: 0.284111\n",
            "iteration 12342 : loss : 0.076156, loss_ce: 0.022781 loss_dice: 0.111740\n",
            "iteration 12343 : loss : 0.128518, loss_ce: 0.073529 loss_dice: 0.165178\n",
            "iteration 12344 : loss : 0.195062, loss_ce: 0.044872 loss_dice: 0.295188\n",
            "iteration 12345 : loss : 0.143448, loss_ce: 0.020694 loss_dice: 0.225284\n",
            "iteration 12346 : loss : 0.144235, loss_ce: 0.029892 loss_dice: 0.220463\n",
            "iteration 12347 : loss : 0.141006, loss_ce: 0.026416 loss_dice: 0.217399\n",
            "iteration 12348 : loss : 0.076777, loss_ce: 0.026412 loss_dice: 0.110353\n",
            "iteration 12349 : loss : 0.158666, loss_ce: 0.037417 loss_dice: 0.239499\n",
            "iteration 12350 : loss : 0.141943, loss_ce: 0.061916 loss_dice: 0.195293\n",
            "iteration 12351 : loss : 0.157525, loss_ce: 0.027260 loss_dice: 0.244369\n",
            "iteration 12352 : loss : 0.125561, loss_ce: 0.034345 loss_dice: 0.186371\n",
            "iteration 12353 : loss : 0.179039, loss_ce: 0.022456 loss_dice: 0.283428\n",
            "iteration 12354 : loss : 0.158830, loss_ce: 0.028980 loss_dice: 0.245397\n",
            "iteration 12355 : loss : 0.154649, loss_ce: 0.035788 loss_dice: 0.233890\n",
            "iteration 12356 : loss : 0.159666, loss_ce: 0.046399 loss_dice: 0.235178\n",
            "iteration 12357 : loss : 0.149229, loss_ce: 0.051592 loss_dice: 0.214321\n",
            "iteration 12358 : loss : 0.155308, loss_ce: 0.045944 loss_dice: 0.228218\n",
            "iteration 12359 : loss : 0.079128, loss_ce: 0.026479 loss_dice: 0.114226\n",
            "iteration 12360 : loss : 0.132384, loss_ce: 0.019688 loss_dice: 0.207515\n",
            "iteration 12361 : loss : 0.134818, loss_ce: 0.037598 loss_dice: 0.199632\n",
            "iteration 12362 : loss : 0.152559, loss_ce: 0.061284 loss_dice: 0.213409\n",
            "iteration 12363 : loss : 0.126150, loss_ce: 0.034652 loss_dice: 0.187150\n",
            "iteration 12364 : loss : 0.164940, loss_ce: 0.047453 loss_dice: 0.243265\n",
            "iteration 12365 : loss : 0.215179, loss_ce: 0.133891 loss_dice: 0.269371\n",
            "iteration 12366 : loss : 0.115716, loss_ce: 0.034718 loss_dice: 0.169715\n",
            "iteration 12367 : loss : 0.046908, loss_ce: 0.014349 loss_dice: 0.068613\n",
            "iteration 12368 : loss : 0.136465, loss_ce: 0.038090 loss_dice: 0.202049\n",
            "iteration 12369 : loss : 0.112875, loss_ce: 0.010169 loss_dice: 0.181345\n",
            "iteration 12370 : loss : 0.120503, loss_ce: 0.022156 loss_dice: 0.186067\n",
            "iteration 12371 : loss : 0.111126, loss_ce: 0.018427 loss_dice: 0.172925\n",
            "iteration 12372 : loss : 0.166230, loss_ce: 0.066493 loss_dice: 0.232721\n",
            "iteration 12373 : loss : 0.089490, loss_ce: 0.015096 loss_dice: 0.139086\n",
            "iteration 12374 : loss : 0.167842, loss_ce: 0.032552 loss_dice: 0.258036\n",
            "iteration 12375 : loss : 0.129637, loss_ce: 0.041422 loss_dice: 0.188447\n",
            "iteration 12376 : loss : 0.119049, loss_ce: 0.012352 loss_dice: 0.190180\n",
            "iteration 12377 : loss : 0.192599, loss_ce: 0.009067 loss_dice: 0.314954\n",
            "iteration 12378 : loss : 0.146347, loss_ce: 0.037216 loss_dice: 0.219101\n",
            "iteration 12379 : loss : 0.055399, loss_ce: 0.014660 loss_dice: 0.082558\n",
            "iteration 12380 : loss : 0.059514, loss_ce: 0.022803 loss_dice: 0.083988\n",
            "iteration 12381 : loss : 0.128451, loss_ce: 0.024907 loss_dice: 0.197481\n",
            "iteration 12382 : loss : 0.214223, loss_ce: 0.030781 loss_dice: 0.336518\n",
            "iteration 12383 : loss : 0.150770, loss_ce: 0.036130 loss_dice: 0.227197\n",
            "iteration 12384 : loss : 0.261867, loss_ce: 0.021308 loss_dice: 0.422239\n",
            "iteration 12385 : loss : 0.111377, loss_ce: 0.004932 loss_dice: 0.182340\n",
            "iteration 12386 : loss : 0.101687, loss_ce: 0.005833 loss_dice: 0.165590\n",
            "iteration 12387 : loss : 0.141601, loss_ce: 0.040191 loss_dice: 0.209208\n",
            "iteration 12388 : loss : 0.191699, loss_ce: 0.004994 loss_dice: 0.316169\n",
            "iteration 12389 : loss : 0.135140, loss_ce: 0.040944 loss_dice: 0.197938\n",
            "iteration 12390 : loss : 0.125570, loss_ce: 0.031984 loss_dice: 0.187961\n",
            "iteration 12391 : loss : 0.098266, loss_ce: 0.024792 loss_dice: 0.147248\n",
            "iteration 12392 : loss : 0.138438, loss_ce: 0.056216 loss_dice: 0.193252\n",
            "iteration 12393 : loss : 0.170091, loss_ce: 0.013695 loss_dice: 0.274355\n",
            "iteration 12394 : loss : 0.127761, loss_ce: 0.038057 loss_dice: 0.187563\n",
            "iteration 12395 : loss : 0.053859, loss_ce: 0.029007 loss_dice: 0.070427\n",
            "iteration 12396 : loss : 0.107192, loss_ce: 0.037195 loss_dice: 0.153856\n",
            "iteration 12397 : loss : 0.221659, loss_ce: 0.010763 loss_dice: 0.362257\n",
            "iteration 12398 : loss : 0.123785, loss_ce: 0.015289 loss_dice: 0.196115\n",
            "iteration 12399 : loss : 0.143886, loss_ce: 0.049975 loss_dice: 0.206494\n",
            "iteration 12400 : loss : 0.062054, loss_ce: 0.017135 loss_dice: 0.092001\n",
            "iteration 12401 : loss : 0.101096, loss_ce: 0.024731 loss_dice: 0.152006\n",
            "iteration 12402 : loss : 0.127098, loss_ce: 0.022160 loss_dice: 0.197057\n",
            "iteration 12403 : loss : 0.141705, loss_ce: 0.034509 loss_dice: 0.213169\n",
            "iteration 12404 : loss : 0.188703, loss_ce: 0.034501 loss_dice: 0.291505\n",
            "iteration 12405 : loss : 0.074227, loss_ce: 0.004622 loss_dice: 0.120631\n",
            "iteration 12406 : loss : 0.143188, loss_ce: 0.054589 loss_dice: 0.202255\n",
            "iteration 12407 : loss : 0.185756, loss_ce: 0.015631 loss_dice: 0.299173\n",
            "iteration 12408 : loss : 0.173297, loss_ce: 0.017027 loss_dice: 0.277478\n",
            "iteration 12409 : loss : 0.242140, loss_ce: 0.012692 loss_dice: 0.395105\n",
            "iteration 12410 : loss : 0.194284, loss_ce: 0.040751 loss_dice: 0.296639\n",
            "iteration 12411 : loss : 0.251123, loss_ce: 0.020309 loss_dice: 0.404999\n",
            "iteration 12412 : loss : 0.181653, loss_ce: 0.024724 loss_dice: 0.286273\n",
            "iteration 12413 : loss : 0.153238, loss_ce: 0.012713 loss_dice: 0.246921\n",
            "iteration 12414 : loss : 0.207285, loss_ce: 0.048151 loss_dice: 0.313374\n",
            "iteration 12415 : loss : 0.131230, loss_ce: 0.041577 loss_dice: 0.190999\n",
            "iteration 12416 : loss : 0.127215, loss_ce: 0.046603 loss_dice: 0.180956\n",
            "iteration 12417 : loss : 0.153430, loss_ce: 0.024968 loss_dice: 0.239071\n",
            "iteration 12418 : loss : 0.262524, loss_ce: 0.023784 loss_dice: 0.421684\n",
            "iteration 12419 : loss : 0.205409, loss_ce: 0.031736 loss_dice: 0.321191\n",
            "iteration 12420 : loss : 0.206741, loss_ce: 0.021046 loss_dice: 0.330538\n",
            "iteration 12421 : loss : 0.115378, loss_ce: 0.015184 loss_dice: 0.182173\n",
            "iteration 12422 : loss : 0.216949, loss_ce: 0.076010 loss_dice: 0.310908\n",
            "iteration 12423 : loss : 0.267346, loss_ce: 0.084840 loss_dice: 0.389016\n",
            "iteration 12424 : loss : 0.100875, loss_ce: 0.026428 loss_dice: 0.150506\n",
            "iteration 12425 : loss : 0.203633, loss_ce: 0.021022 loss_dice: 0.325373\n",
            "iteration 12426 : loss : 0.133992, loss_ce: 0.029527 loss_dice: 0.203635\n",
            "iteration 12427 : loss : 0.181086, loss_ce: 0.057442 loss_dice: 0.263515\n",
            "iteration 12428 : loss : 0.204041, loss_ce: 0.056677 loss_dice: 0.302284\n",
            "iteration 12429 : loss : 0.143096, loss_ce: 0.071755 loss_dice: 0.190656\n",
            "iteration 12430 : loss : 0.193015, loss_ce: 0.058121 loss_dice: 0.282945\n",
            "iteration 12431 : loss : 0.225246, loss_ce: 0.111464 loss_dice: 0.301101\n",
            "iteration 12432 : loss : 0.177043, loss_ce: 0.000067 loss_dice: 0.295026\n",
            " 11%|███                        | 56/500 [2:04:52<10:25:29, 84.53s/it]iteration 12433 : loss : 0.104341, loss_ce: 0.038717 loss_dice: 0.148090\n",
            "iteration 12434 : loss : 0.098600, loss_ce: 0.009646 loss_dice: 0.157902\n",
            "iteration 12435 : loss : 0.219404, loss_ce: 0.085903 loss_dice: 0.308404\n",
            "iteration 12436 : loss : 0.285418, loss_ce: 0.045219 loss_dice: 0.445551\n",
            "iteration 12437 : loss : 0.226190, loss_ce: 0.028135 loss_dice: 0.358227\n",
            "iteration 12438 : loss : 0.259762, loss_ce: 0.059233 loss_dice: 0.393448\n",
            "iteration 12439 : loss : 0.045398, loss_ce: 0.009705 loss_dice: 0.069194\n",
            "iteration 12440 : loss : 0.142502, loss_ce: 0.053029 loss_dice: 0.202150\n",
            "iteration 12441 : loss : 0.165706, loss_ce: 0.012204 loss_dice: 0.268041\n",
            "iteration 12442 : loss : 0.159709, loss_ce: 0.024794 loss_dice: 0.249652\n",
            "iteration 12443 : loss : 0.195918, loss_ce: 0.031372 loss_dice: 0.305615\n",
            "iteration 12444 : loss : 0.079602, loss_ce: 0.024415 loss_dice: 0.116394\n",
            "iteration 12445 : loss : 0.203719, loss_ce: 0.050394 loss_dice: 0.305936\n",
            "iteration 12446 : loss : 0.205306, loss_ce: 0.078674 loss_dice: 0.289727\n",
            "iteration 12447 : loss : 0.220108, loss_ce: 0.022007 loss_dice: 0.352176\n",
            "iteration 12448 : loss : 0.167137, loss_ce: 0.071252 loss_dice: 0.231061\n",
            "iteration 12449 : loss : 0.182304, loss_ce: 0.018836 loss_dice: 0.291282\n",
            "iteration 12450 : loss : 0.114761, loss_ce: 0.058152 loss_dice: 0.152500\n",
            "iteration 12451 : loss : 0.158254, loss_ce: 0.037509 loss_dice: 0.238751\n",
            "iteration 12452 : loss : 0.098982, loss_ce: 0.030540 loss_dice: 0.144610\n",
            "iteration 12453 : loss : 0.175490, loss_ce: 0.011882 loss_dice: 0.284561\n",
            "iteration 12454 : loss : 0.187680, loss_ce: 0.068485 loss_dice: 0.267143\n",
            "iteration 12455 : loss : 0.156149, loss_ce: 0.065302 loss_dice: 0.216713\n",
            "iteration 12456 : loss : 0.073730, loss_ce: 0.024496 loss_dice: 0.106552\n",
            "iteration 12457 : loss : 0.113563, loss_ce: 0.027412 loss_dice: 0.170996\n",
            "iteration 12458 : loss : 0.162240, loss_ce: 0.050772 loss_dice: 0.236551\n",
            "iteration 12459 : loss : 0.189414, loss_ce: 0.028036 loss_dice: 0.296999\n",
            "iteration 12460 : loss : 0.196710, loss_ce: 0.022272 loss_dice: 0.313002\n",
            "iteration 12461 : loss : 0.233668, loss_ce: 0.011344 loss_dice: 0.381885\n",
            "iteration 12462 : loss : 0.150302, loss_ce: 0.019271 loss_dice: 0.237656\n",
            "iteration 12463 : loss : 0.210729, loss_ce: 0.037886 loss_dice: 0.325958\n",
            "iteration 12464 : loss : 0.106237, loss_ce: 0.024147 loss_dice: 0.160964\n",
            "iteration 12465 : loss : 0.116074, loss_ce: 0.031518 loss_dice: 0.172445\n",
            "iteration 12466 : loss : 0.112903, loss_ce: 0.058437 loss_dice: 0.149213\n",
            "iteration 12467 : loss : 0.202194, loss_ce: 0.082295 loss_dice: 0.282127\n",
            "iteration 12468 : loss : 0.305526, loss_ce: 0.016667 loss_dice: 0.498099\n",
            "iteration 12469 : loss : 0.210876, loss_ce: 0.043074 loss_dice: 0.322744\n",
            "iteration 12470 : loss : 0.187908, loss_ce: 0.057192 loss_dice: 0.275052\n",
            "iteration 12471 : loss : 0.101967, loss_ce: 0.021026 loss_dice: 0.155927\n",
            "iteration 12472 : loss : 0.124951, loss_ce: 0.008943 loss_dice: 0.202290\n",
            "iteration 12473 : loss : 0.107406, loss_ce: 0.017706 loss_dice: 0.167206\n",
            "iteration 12474 : loss : 0.169723, loss_ce: 0.046737 loss_dice: 0.251714\n",
            "iteration 12475 : loss : 0.272209, loss_ce: 0.042892 loss_dice: 0.425087\n",
            "iteration 12476 : loss : 0.154080, loss_ce: 0.068551 loss_dice: 0.211100\n",
            "iteration 12477 : loss : 0.146026, loss_ce: 0.040520 loss_dice: 0.216363\n",
            "iteration 12478 : loss : 0.112514, loss_ce: 0.041443 loss_dice: 0.159894\n",
            "iteration 12479 : loss : 0.158550, loss_ce: 0.033405 loss_dice: 0.241980\n",
            "iteration 12480 : loss : 0.089703, loss_ce: 0.023741 loss_dice: 0.133678\n",
            "iteration 12481 : loss : 0.057644, loss_ce: 0.016338 loss_dice: 0.085181\n",
            "iteration 12482 : loss : 0.214698, loss_ce: 0.037764 loss_dice: 0.332654\n",
            "iteration 12483 : loss : 0.137962, loss_ce: 0.036688 loss_dice: 0.205479\n",
            "iteration 12484 : loss : 0.130248, loss_ce: 0.030224 loss_dice: 0.196931\n",
            "iteration 12485 : loss : 0.161491, loss_ce: 0.067372 loss_dice: 0.224237\n",
            "iteration 12486 : loss : 0.083049, loss_ce: 0.034192 loss_dice: 0.115620\n",
            "iteration 12487 : loss : 0.187699, loss_ce: 0.023706 loss_dice: 0.297028\n",
            "iteration 12488 : loss : 0.121223, loss_ce: 0.033739 loss_dice: 0.179546\n",
            "iteration 12489 : loss : 0.049913, loss_ce: 0.020779 loss_dice: 0.069335\n",
            "iteration 12490 : loss : 0.133767, loss_ce: 0.030044 loss_dice: 0.202916\n",
            "iteration 12491 : loss : 0.152671, loss_ce: 0.035906 loss_dice: 0.230514\n",
            "iteration 12492 : loss : 0.092390, loss_ce: 0.039243 loss_dice: 0.127821\n",
            "iteration 12493 : loss : 0.084026, loss_ce: 0.014772 loss_dice: 0.130196\n",
            "iteration 12494 : loss : 0.105178, loss_ce: 0.020160 loss_dice: 0.161857\n",
            "iteration 12495 : loss : 0.112577, loss_ce: 0.025956 loss_dice: 0.170324\n",
            "iteration 12496 : loss : 0.077376, loss_ce: 0.036321 loss_dice: 0.104746\n",
            "iteration 12497 : loss : 0.240198, loss_ce: 0.006073 loss_dice: 0.396282\n",
            "iteration 12498 : loss : 0.065423, loss_ce: 0.031981 loss_dice: 0.087718\n",
            "iteration 12499 : loss : 0.096565, loss_ce: 0.031185 loss_dice: 0.140152\n",
            "iteration 12500 : loss : 0.098107, loss_ce: 0.013647 loss_dice: 0.154414\n",
            "iteration 12501 : loss : 0.138052, loss_ce: 0.032627 loss_dice: 0.208335\n",
            "iteration 12502 : loss : 0.174149, loss_ce: 0.016751 loss_dice: 0.279082\n",
            "iteration 12503 : loss : 0.136954, loss_ce: 0.027347 loss_dice: 0.210025\n",
            "iteration 12504 : loss : 0.125402, loss_ce: 0.042952 loss_dice: 0.180369\n",
            "iteration 12505 : loss : 0.162584, loss_ce: 0.016840 loss_dice: 0.259747\n",
            "iteration 12506 : loss : 0.074003, loss_ce: 0.018448 loss_dice: 0.111040\n",
            "iteration 12507 : loss : 0.374397, loss_ce: 0.003577 loss_dice: 0.621610\n",
            "iteration 12508 : loss : 0.118132, loss_ce: 0.014478 loss_dice: 0.187234\n",
            "iteration 12509 : loss : 0.161203, loss_ce: 0.027619 loss_dice: 0.250259\n",
            "iteration 12510 : loss : 0.133726, loss_ce: 0.029069 loss_dice: 0.203498\n",
            "iteration 12511 : loss : 0.116778, loss_ce: 0.043592 loss_dice: 0.165569\n",
            "iteration 12512 : loss : 0.130185, loss_ce: 0.044732 loss_dice: 0.187153\n",
            "iteration 12513 : loss : 0.076946, loss_ce: 0.037239 loss_dice: 0.103417\n",
            "iteration 12514 : loss : 0.118590, loss_ce: 0.007438 loss_dice: 0.192691\n",
            "iteration 12515 : loss : 0.125276, loss_ce: 0.018057 loss_dice: 0.196756\n",
            "iteration 12516 : loss : 0.138678, loss_ce: 0.025228 loss_dice: 0.214311\n",
            "iteration 12517 : loss : 0.100989, loss_ce: 0.030003 loss_dice: 0.148313\n",
            "iteration 12518 : loss : 0.114565, loss_ce: 0.018439 loss_dice: 0.178649\n",
            "iteration 12519 : loss : 0.086902, loss_ce: 0.027873 loss_dice: 0.126254\n",
            "iteration 12520 : loss : 0.145665, loss_ce: 0.030036 loss_dice: 0.222751\n",
            "iteration 12521 : loss : 0.098031, loss_ce: 0.021588 loss_dice: 0.148993\n",
            "iteration 12522 : loss : 0.129306, loss_ce: 0.034155 loss_dice: 0.192741\n",
            "iteration 12523 : loss : 0.095217, loss_ce: 0.040596 loss_dice: 0.131630\n",
            "iteration 12524 : loss : 0.138646, loss_ce: 0.039256 loss_dice: 0.204906\n",
            "iteration 12525 : loss : 0.171374, loss_ce: 0.040568 loss_dice: 0.258579\n",
            "iteration 12526 : loss : 0.065566, loss_ce: 0.026775 loss_dice: 0.091427\n",
            "iteration 12527 : loss : 0.131171, loss_ce: 0.022902 loss_dice: 0.203351\n",
            "iteration 12528 : loss : 0.116494, loss_ce: 0.025442 loss_dice: 0.177196\n",
            "iteration 12529 : loss : 0.109720, loss_ce: 0.023234 loss_dice: 0.167376\n",
            "iteration 12530 : loss : 0.105878, loss_ce: 0.039386 loss_dice: 0.150206\n",
            "iteration 12531 : loss : 0.160263, loss_ce: 0.008493 loss_dice: 0.261444\n",
            "iteration 12532 : loss : 0.201426, loss_ce: 0.013589 loss_dice: 0.326651\n",
            "iteration 12533 : loss : 0.136682, loss_ce: 0.027227 loss_dice: 0.209651\n",
            "iteration 12534 : loss : 0.150781, loss_ce: 0.023314 loss_dice: 0.235759\n",
            "iteration 12535 : loss : 0.083101, loss_ce: 0.027206 loss_dice: 0.120365\n",
            "iteration 12536 : loss : 0.096581, loss_ce: 0.024722 loss_dice: 0.144486\n",
            "iteration 12537 : loss : 0.102339, loss_ce: 0.030813 loss_dice: 0.150023\n",
            "iteration 12538 : loss : 0.082358, loss_ce: 0.022801 loss_dice: 0.122063\n",
            "iteration 12539 : loss : 0.097221, loss_ce: 0.050688 loss_dice: 0.128243\n",
            "iteration 12540 : loss : 0.124239, loss_ce: 0.017222 loss_dice: 0.195583\n",
            "iteration 12541 : loss : 0.149503, loss_ce: 0.014260 loss_dice: 0.239666\n",
            "iteration 12542 : loss : 0.101017, loss_ce: 0.015527 loss_dice: 0.158010\n",
            "iteration 12543 : loss : 0.169390, loss_ce: 0.018426 loss_dice: 0.270032\n",
            "iteration 12544 : loss : 0.169151, loss_ce: 0.014115 loss_dice: 0.272509\n",
            "iteration 12545 : loss : 0.183415, loss_ce: 0.025424 loss_dice: 0.288743\n",
            "iteration 12546 : loss : 0.120289, loss_ce: 0.019000 loss_dice: 0.187815\n",
            "iteration 12547 : loss : 0.350061, loss_ce: 0.003595 loss_dice: 0.581039\n",
            "iteration 12548 : loss : 0.147655, loss_ce: 0.033945 loss_dice: 0.223462\n",
            "iteration 12549 : loss : 0.180235, loss_ce: 0.022503 loss_dice: 0.285390\n",
            "iteration 12550 : loss : 0.144094, loss_ce: 0.022390 loss_dice: 0.225229\n",
            "iteration 12551 : loss : 0.134967, loss_ce: 0.040452 loss_dice: 0.197978\n",
            "iteration 12552 : loss : 0.149565, loss_ce: 0.031316 loss_dice: 0.228397\n",
            "iteration 12553 : loss : 0.159618, loss_ce: 0.022406 loss_dice: 0.251093\n",
            "iteration 12554 : loss : 0.159961, loss_ce: 0.056567 loss_dice: 0.228891\n",
            "iteration 12555 : loss : 0.085269, loss_ce: 0.024879 loss_dice: 0.125529\n",
            "iteration 12556 : loss : 0.164147, loss_ce: 0.020866 loss_dice: 0.259668\n",
            "iteration 12557 : loss : 0.106004, loss_ce: 0.031281 loss_dice: 0.155819\n",
            "iteration 12558 : loss : 0.125908, loss_ce: 0.062113 loss_dice: 0.168438\n",
            "iteration 12559 : loss : 0.137008, loss_ce: 0.046298 loss_dice: 0.197482\n",
            "iteration 12560 : loss : 0.136046, loss_ce: 0.035634 loss_dice: 0.202987\n",
            "iteration 12561 : loss : 0.120264, loss_ce: 0.019255 loss_dice: 0.187604\n",
            "iteration 12562 : loss : 0.114981, loss_ce: 0.039195 loss_dice: 0.165504\n",
            "iteration 12563 : loss : 0.138182, loss_ce: 0.054735 loss_dice: 0.193813\n",
            "iteration 12564 : loss : 0.121452, loss_ce: 0.025775 loss_dice: 0.185236\n",
            "iteration 12565 : loss : 0.137131, loss_ce: 0.023452 loss_dice: 0.212916\n",
            "iteration 12566 : loss : 0.144068, loss_ce: 0.024640 loss_dice: 0.223687\n",
            "iteration 12567 : loss : 0.110162, loss_ce: 0.034566 loss_dice: 0.160558\n",
            "iteration 12568 : loss : 0.088375, loss_ce: 0.020872 loss_dice: 0.133377\n",
            "iteration 12569 : loss : 0.127984, loss_ce: 0.032677 loss_dice: 0.191522\n",
            "iteration 12570 : loss : 0.203746, loss_ce: 0.012179 loss_dice: 0.331457\n",
            "iteration 12571 : loss : 0.092240, loss_ce: 0.030486 loss_dice: 0.133410\n",
            "iteration 12572 : loss : 0.059385, loss_ce: 0.026015 loss_dice: 0.081631\n",
            "iteration 12573 : loss : 0.104449, loss_ce: 0.024820 loss_dice: 0.157535\n",
            "iteration 12574 : loss : 0.089753, loss_ce: 0.045475 loss_dice: 0.119272\n",
            "iteration 12575 : loss : 0.096511, loss_ce: 0.039755 loss_dice: 0.134348\n",
            "iteration 12576 : loss : 0.145781, loss_ce: 0.028949 loss_dice: 0.223670\n",
            "iteration 12577 : loss : 0.117486, loss_ce: 0.040349 loss_dice: 0.168911\n",
            "iteration 12578 : loss : 0.118771, loss_ce: 0.035834 loss_dice: 0.174062\n",
            "iteration 12579 : loss : 0.194273, loss_ce: 0.004788 loss_dice: 0.320597\n",
            "iteration 12580 : loss : 0.077365, loss_ce: 0.029184 loss_dice: 0.109485\n",
            "iteration 12581 : loss : 0.130539, loss_ce: 0.019037 loss_dice: 0.204874\n",
            "iteration 12582 : loss : 0.079776, loss_ce: 0.014545 loss_dice: 0.123264\n",
            "iteration 12583 : loss : 0.106554, loss_ce: 0.034465 loss_dice: 0.154614\n",
            "iteration 12584 : loss : 0.097390, loss_ce: 0.034355 loss_dice: 0.139413\n",
            "iteration 12585 : loss : 0.116107, loss_ce: 0.038449 loss_dice: 0.167878\n",
            "iteration 12586 : loss : 0.252627, loss_ce: 0.008504 loss_dice: 0.415376\n",
            "iteration 12587 : loss : 0.113496, loss_ce: 0.026158 loss_dice: 0.171721\n",
            "iteration 12588 : loss : 0.074063, loss_ce: 0.029020 loss_dice: 0.104091\n",
            "iteration 12589 : loss : 0.146868, loss_ce: 0.021374 loss_dice: 0.230531\n",
            "iteration 12590 : loss : 0.161221, loss_ce: 0.029241 loss_dice: 0.249208\n",
            "iteration 12591 : loss : 0.113647, loss_ce: 0.039047 loss_dice: 0.163381\n",
            "iteration 12592 : loss : 0.081543, loss_ce: 0.017146 loss_dice: 0.124475\n",
            "iteration 12593 : loss : 0.159596, loss_ce: 0.024721 loss_dice: 0.249513\n",
            "iteration 12594 : loss : 0.070144, loss_ce: 0.026912 loss_dice: 0.098966\n",
            "iteration 12595 : loss : 0.072755, loss_ce: 0.026029 loss_dice: 0.103905\n",
            "iteration 12596 : loss : 0.166796, loss_ce: 0.019845 loss_dice: 0.264764\n",
            "iteration 12597 : loss : 0.123621, loss_ce: 0.037302 loss_dice: 0.181167\n",
            "iteration 12598 : loss : 0.154737, loss_ce: 0.038921 loss_dice: 0.231948\n",
            "iteration 12599 : loss : 0.105443, loss_ce: 0.020795 loss_dice: 0.161875\n",
            "iteration 12600 : loss : 0.108224, loss_ce: 0.028167 loss_dice: 0.161595\n",
            "iteration 12601 : loss : 0.146279, loss_ce: 0.030322 loss_dice: 0.223584\n",
            "iteration 12602 : loss : 0.142469, loss_ce: 0.023278 loss_dice: 0.221929\n",
            "iteration 12603 : loss : 0.109486, loss_ce: 0.009494 loss_dice: 0.176147\n",
            "iteration 12604 : loss : 0.177149, loss_ce: 0.031560 loss_dice: 0.274209\n",
            "iteration 12605 : loss : 0.061719, loss_ce: 0.019177 loss_dice: 0.090081\n",
            "iteration 12606 : loss : 0.098794, loss_ce: 0.030733 loss_dice: 0.144167\n",
            "iteration 12607 : loss : 0.394308, loss_ce: 0.000200 loss_dice: 0.657047\n",
            "iteration 12608 : loss : 0.136967, loss_ce: 0.014858 loss_dice: 0.218373\n",
            "iteration 12609 : loss : 0.110925, loss_ce: 0.029953 loss_dice: 0.164906\n",
            "iteration 12610 : loss : 0.083533, loss_ce: 0.024184 loss_dice: 0.123100\n",
            "iteration 12611 : loss : 0.072342, loss_ce: 0.031321 loss_dice: 0.099689\n",
            "iteration 12612 : loss : 0.234010, loss_ce: 0.003687 loss_dice: 0.387558\n",
            "iteration 12613 : loss : 0.146299, loss_ce: 0.022626 loss_dice: 0.228747\n",
            "iteration 12614 : loss : 0.059877, loss_ce: 0.032772 loss_dice: 0.077948\n",
            "iteration 12615 : loss : 0.164344, loss_ce: 0.021605 loss_dice: 0.259503\n",
            "iteration 12616 : loss : 0.102690, loss_ce: 0.043129 loss_dice: 0.142398\n",
            "iteration 12617 : loss : 0.052597, loss_ce: 0.013266 loss_dice: 0.078819\n",
            "iteration 12618 : loss : 0.108329, loss_ce: 0.012231 loss_dice: 0.172394\n",
            "iteration 12619 : loss : 0.218859, loss_ce: 0.003958 loss_dice: 0.362126\n",
            "iteration 12620 : loss : 0.080545, loss_ce: 0.030259 loss_dice: 0.114068\n",
            "iteration 12621 : loss : 0.148804, loss_ce: 0.013925 loss_dice: 0.238723\n",
            "iteration 12622 : loss : 0.132032, loss_ce: 0.045866 loss_dice: 0.189475\n",
            "iteration 12623 : loss : 0.131893, loss_ce: 0.034830 loss_dice: 0.196602\n",
            "iteration 12624 : loss : 0.157889, loss_ce: 0.022219 loss_dice: 0.248336\n",
            "iteration 12625 : loss : 0.057561, loss_ce: 0.012369 loss_dice: 0.087690\n",
            "iteration 12626 : loss : 0.156436, loss_ce: 0.037314 loss_dice: 0.235851\n",
            "iteration 12627 : loss : 0.125165, loss_ce: 0.007245 loss_dice: 0.203777\n",
            "iteration 12628 : loss : 0.083299, loss_ce: 0.030253 loss_dice: 0.118662\n",
            "iteration 12629 : loss : 0.127843, loss_ce: 0.031675 loss_dice: 0.191955\n",
            "iteration 12630 : loss : 0.143356, loss_ce: 0.017619 loss_dice: 0.227181\n",
            "iteration 12631 : loss : 0.103860, loss_ce: 0.040820 loss_dice: 0.145886\n",
            "iteration 12632 : loss : 0.104727, loss_ce: 0.048059 loss_dice: 0.142505\n",
            "iteration 12633 : loss : 0.082680, loss_ce: 0.019200 loss_dice: 0.125000\n",
            "iteration 12634 : loss : 0.095227, loss_ce: 0.034215 loss_dice: 0.135902\n",
            "iteration 12635 : loss : 0.216633, loss_ce: 0.014267 loss_dice: 0.351544\n",
            "iteration 12636 : loss : 0.120951, loss_ce: 0.025196 loss_dice: 0.184787\n",
            "iteration 12637 : loss : 0.077323, loss_ce: 0.010864 loss_dice: 0.121629\n",
            "iteration 12638 : loss : 0.068220, loss_ce: 0.025891 loss_dice: 0.096439\n",
            "iteration 12639 : loss : 0.070566, loss_ce: 0.017665 loss_dice: 0.105834\n",
            "iteration 12640 : loss : 0.114713, loss_ce: 0.052606 loss_dice: 0.156118\n",
            "iteration 12641 : loss : 0.116787, loss_ce: 0.027334 loss_dice: 0.176422\n",
            "iteration 12642 : loss : 0.076817, loss_ce: 0.017804 loss_dice: 0.116160\n",
            "iteration 12643 : loss : 0.086955, loss_ce: 0.023384 loss_dice: 0.129336\n",
            "iteration 12644 : loss : 0.103967, loss_ce: 0.040165 loss_dice: 0.146501\n",
            "iteration 12645 : loss : 0.344480, loss_ce: 0.003932 loss_dice: 0.571511\n",
            "iteration 12646 : loss : 0.116645, loss_ce: 0.018832 loss_dice: 0.181853\n",
            "iteration 12647 : loss : 0.146511, loss_ce: 0.014338 loss_dice: 0.234626\n",
            "iteration 12648 : loss : 0.080499, loss_ce: 0.019296 loss_dice: 0.121301\n",
            "iteration 12649 : loss : 0.078051, loss_ce: 0.036968 loss_dice: 0.105440\n",
            "iteration 12650 : loss : 0.078555, loss_ce: 0.035727 loss_dice: 0.107107\n",
            "iteration 12651 : loss : 0.064200, loss_ce: 0.032823 loss_dice: 0.085118\n",
            "iteration 12652 : loss : 0.071015, loss_ce: 0.014946 loss_dice: 0.108395\n",
            "iteration 12653 : loss : 0.122237, loss_ce: 0.015943 loss_dice: 0.193100\n",
            "iteration 12654 : loss : 0.206910, loss_ce: 0.059112 loss_dice: 0.305442\n",
            " 11%|███                        | 57/500 [2:06:16<10:23:12, 84.41s/it]iteration 12655 : loss : 0.186320, loss_ce: 0.011656 loss_dice: 0.302763\n",
            "iteration 12656 : loss : 0.147554, loss_ce: 0.024535 loss_dice: 0.229566\n",
            "iteration 12657 : loss : 0.216533, loss_ce: 0.017124 loss_dice: 0.349473\n",
            "iteration 12658 : loss : 0.249364, loss_ce: 0.051879 loss_dice: 0.381021\n",
            "iteration 12659 : loss : 0.133302, loss_ce: 0.023604 loss_dice: 0.206435\n",
            "iteration 12660 : loss : 0.144237, loss_ce: 0.044769 loss_dice: 0.210548\n",
            "iteration 12661 : loss : 0.175699, loss_ce: 0.015920 loss_dice: 0.282218\n",
            "iteration 12662 : loss : 0.090107, loss_ce: 0.022637 loss_dice: 0.135087\n",
            "iteration 12663 : loss : 0.090642, loss_ce: 0.027440 loss_dice: 0.132776\n",
            "iteration 12664 : loss : 0.116606, loss_ce: 0.007360 loss_dice: 0.189436\n",
            "iteration 12665 : loss : 0.104391, loss_ce: 0.015994 loss_dice: 0.163323\n",
            "iteration 12666 : loss : 0.158139, loss_ce: 0.032057 loss_dice: 0.242194\n",
            "iteration 12667 : loss : 0.084322, loss_ce: 0.025249 loss_dice: 0.123704\n",
            "iteration 12668 : loss : 0.131996, loss_ce: 0.039855 loss_dice: 0.193424\n",
            "iteration 12669 : loss : 0.086373, loss_ce: 0.021179 loss_dice: 0.129835\n",
            "iteration 12670 : loss : 0.092464, loss_ce: 0.024931 loss_dice: 0.137485\n",
            "iteration 12671 : loss : 0.083352, loss_ce: 0.013958 loss_dice: 0.129615\n",
            "iteration 12672 : loss : 0.163844, loss_ce: 0.031107 loss_dice: 0.252335\n",
            "iteration 12673 : loss : 0.208684, loss_ce: 0.029736 loss_dice: 0.327983\n",
            "iteration 12674 : loss : 0.102154, loss_ce: 0.023054 loss_dice: 0.154887\n",
            "iteration 12675 : loss : 0.098785, loss_ce: 0.019237 loss_dice: 0.151818\n",
            "iteration 12676 : loss : 0.154458, loss_ce: 0.063429 loss_dice: 0.215144\n",
            "iteration 12677 : loss : 0.088356, loss_ce: 0.026944 loss_dice: 0.129297\n",
            "iteration 12678 : loss : 0.161075, loss_ce: 0.014559 loss_dice: 0.258752\n",
            "iteration 12679 : loss : 0.127472, loss_ce: 0.024024 loss_dice: 0.196438\n",
            "iteration 12680 : loss : 0.137547, loss_ce: 0.028193 loss_dice: 0.210450\n",
            "iteration 12681 : loss : 0.110009, loss_ce: 0.014793 loss_dice: 0.173486\n",
            "iteration 12682 : loss : 0.107475, loss_ce: 0.026633 loss_dice: 0.161370\n",
            "iteration 12683 : loss : 0.057919, loss_ce: 0.009395 loss_dice: 0.090269\n",
            "iteration 12684 : loss : 0.085399, loss_ce: 0.030497 loss_dice: 0.122001\n",
            "iteration 12685 : loss : 0.172815, loss_ce: 0.025491 loss_dice: 0.271031\n",
            "iteration 12686 : loss : 0.142490, loss_ce: 0.024776 loss_dice: 0.220966\n",
            "iteration 12687 : loss : 0.162542, loss_ce: 0.016840 loss_dice: 0.259677\n",
            "iteration 12688 : loss : 0.159686, loss_ce: 0.019458 loss_dice: 0.253172\n",
            "iteration 12689 : loss : 0.119701, loss_ce: 0.046193 loss_dice: 0.168707\n",
            "iteration 12690 : loss : 0.176964, loss_ce: 0.033544 loss_dice: 0.272577\n",
            "iteration 12691 : loss : 0.121476, loss_ce: 0.030384 loss_dice: 0.182204\n",
            "iteration 12692 : loss : 0.149064, loss_ce: 0.056501 loss_dice: 0.210773\n",
            "iteration 12693 : loss : 0.246493, loss_ce: 0.044621 loss_dice: 0.381075\n",
            "iteration 12694 : loss : 0.163446, loss_ce: 0.029881 loss_dice: 0.252490\n",
            "iteration 12695 : loss : 0.075185, loss_ce: 0.019355 loss_dice: 0.112404\n",
            "iteration 12696 : loss : 0.137069, loss_ce: 0.020182 loss_dice: 0.214994\n",
            "iteration 12697 : loss : 0.190137, loss_ce: 0.013087 loss_dice: 0.308171\n",
            "iteration 12698 : loss : 0.147376, loss_ce: 0.011053 loss_dice: 0.238258\n",
            "iteration 12699 : loss : 0.142214, loss_ce: 0.037320 loss_dice: 0.212144\n",
            "iteration 12700 : loss : 0.098535, loss_ce: 0.046084 loss_dice: 0.133502\n",
            "iteration 12701 : loss : 0.132289, loss_ce: 0.037528 loss_dice: 0.195463\n",
            "iteration 12702 : loss : 0.067222, loss_ce: 0.027031 loss_dice: 0.094016\n",
            "iteration 12703 : loss : 0.181451, loss_ce: 0.057159 loss_dice: 0.264313\n",
            "iteration 12704 : loss : 0.106180, loss_ce: 0.020043 loss_dice: 0.163604\n",
            "iteration 12705 : loss : 0.120887, loss_ce: 0.029651 loss_dice: 0.181711\n",
            "iteration 12706 : loss : 0.127120, loss_ce: 0.028528 loss_dice: 0.192847\n",
            "iteration 12707 : loss : 0.132932, loss_ce: 0.028457 loss_dice: 0.202583\n",
            "iteration 12708 : loss : 0.146762, loss_ce: 0.045676 loss_dice: 0.214153\n",
            "iteration 12709 : loss : 0.079717, loss_ce: 0.029184 loss_dice: 0.113405\n",
            "iteration 12710 : loss : 0.171659, loss_ce: 0.008860 loss_dice: 0.280192\n",
            "iteration 12711 : loss : 0.171234, loss_ce: 0.013271 loss_dice: 0.276543\n",
            "iteration 12712 : loss : 0.163087, loss_ce: 0.021265 loss_dice: 0.257635\n",
            "iteration 12713 : loss : 0.175392, loss_ce: 0.017374 loss_dice: 0.280737\n",
            "iteration 12714 : loss : 0.099152, loss_ce: 0.048978 loss_dice: 0.132601\n",
            "iteration 12715 : loss : 0.092249, loss_ce: 0.038617 loss_dice: 0.128003\n",
            "iteration 12716 : loss : 0.127196, loss_ce: 0.016351 loss_dice: 0.201092\n",
            "iteration 12717 : loss : 0.134045, loss_ce: 0.025225 loss_dice: 0.206592\n",
            "iteration 12718 : loss : 0.117665, loss_ce: 0.017164 loss_dice: 0.184665\n",
            "iteration 12719 : loss : 0.120249, loss_ce: 0.014605 loss_dice: 0.190679\n",
            "iteration 12720 : loss : 0.145572, loss_ce: 0.039700 loss_dice: 0.216154\n",
            "iteration 12721 : loss : 0.085825, loss_ce: 0.015999 loss_dice: 0.132376\n",
            "iteration 12722 : loss : 0.106247, loss_ce: 0.027346 loss_dice: 0.158848\n",
            "iteration 12723 : loss : 0.054099, loss_ce: 0.026061 loss_dice: 0.072791\n",
            "iteration 12724 : loss : 0.208476, loss_ce: 0.031858 loss_dice: 0.326221\n",
            "iteration 12725 : loss : 0.126176, loss_ce: 0.041516 loss_dice: 0.182615\n",
            "iteration 12726 : loss : 0.242499, loss_ce: 0.019744 loss_dice: 0.391003\n",
            "iteration 12727 : loss : 0.162195, loss_ce: 0.043996 loss_dice: 0.240995\n",
            "iteration 12728 : loss : 0.108229, loss_ce: 0.023066 loss_dice: 0.165005\n",
            "iteration 12729 : loss : 0.135341, loss_ce: 0.046876 loss_dice: 0.194317\n",
            "iteration 12730 : loss : 0.129124, loss_ce: 0.072467 loss_dice: 0.166896\n",
            "iteration 12731 : loss : 0.097329, loss_ce: 0.016589 loss_dice: 0.151156\n",
            "iteration 12732 : loss : 0.074859, loss_ce: 0.035264 loss_dice: 0.101256\n",
            "iteration 12733 : loss : 0.248951, loss_ce: 0.007673 loss_dice: 0.409803\n",
            "iteration 12734 : loss : 0.087428, loss_ce: 0.027172 loss_dice: 0.127599\n",
            "iteration 12735 : loss : 0.124168, loss_ce: 0.032272 loss_dice: 0.185432\n",
            "iteration 12736 : loss : 0.122540, loss_ce: 0.022941 loss_dice: 0.188939\n",
            "iteration 12737 : loss : 0.114574, loss_ce: 0.019606 loss_dice: 0.177885\n",
            "iteration 12738 : loss : 0.134405, loss_ce: 0.007883 loss_dice: 0.218753\n",
            "iteration 12739 : loss : 0.101748, loss_ce: 0.053987 loss_dice: 0.133588\n",
            "iteration 12740 : loss : 0.073123, loss_ce: 0.026669 loss_dice: 0.104093\n",
            "iteration 12741 : loss : 0.116153, loss_ce: 0.027896 loss_dice: 0.174992\n",
            "iteration 12742 : loss : 0.143517, loss_ce: 0.014421 loss_dice: 0.229581\n",
            "iteration 12743 : loss : 0.053050, loss_ce: 0.016646 loss_dice: 0.077319\n",
            "iteration 12744 : loss : 0.099225, loss_ce: 0.019570 loss_dice: 0.152327\n",
            "iteration 12745 : loss : 0.101322, loss_ce: 0.043861 loss_dice: 0.139630\n",
            "iteration 12746 : loss : 0.150165, loss_ce: 0.037612 loss_dice: 0.225201\n",
            "iteration 12747 : loss : 0.141708, loss_ce: 0.021370 loss_dice: 0.221933\n",
            "iteration 12748 : loss : 0.079022, loss_ce: 0.025144 loss_dice: 0.114941\n",
            "iteration 12749 : loss : 0.160567, loss_ce: 0.010135 loss_dice: 0.260855\n",
            "iteration 12750 : loss : 0.097638, loss_ce: 0.018101 loss_dice: 0.150662\n",
            "iteration 12751 : loss : 0.141924, loss_ce: 0.018561 loss_dice: 0.224165\n",
            "iteration 12752 : loss : 0.099783, loss_ce: 0.030118 loss_dice: 0.146227\n",
            "iteration 12753 : loss : 0.126791, loss_ce: 0.023196 loss_dice: 0.195855\n",
            "iteration 12754 : loss : 0.103731, loss_ce: 0.046038 loss_dice: 0.142192\n",
            "iteration 12755 : loss : 0.072050, loss_ce: 0.013129 loss_dice: 0.111330\n",
            "iteration 12756 : loss : 0.281849, loss_ce: 0.003489 loss_dice: 0.467422\n",
            "iteration 12757 : loss : 0.084351, loss_ce: 0.029160 loss_dice: 0.121145\n",
            "iteration 12758 : loss : 0.147993, loss_ce: 0.019063 loss_dice: 0.233946\n",
            "iteration 12759 : loss : 0.199484, loss_ce: 0.019493 loss_dice: 0.319477\n",
            "iteration 12760 : loss : 0.057780, loss_ce: 0.010816 loss_dice: 0.089090\n",
            "iteration 12761 : loss : 0.084409, loss_ce: 0.017440 loss_dice: 0.129055\n",
            "iteration 12762 : loss : 0.195560, loss_ce: 0.031914 loss_dice: 0.304657\n",
            "iteration 12763 : loss : 0.135057, loss_ce: 0.028936 loss_dice: 0.205804\n",
            "iteration 12764 : loss : 0.068608, loss_ce: 0.013123 loss_dice: 0.105597\n",
            "iteration 12765 : loss : 0.072365, loss_ce: 0.015658 loss_dice: 0.110170\n",
            "iteration 12766 : loss : 0.130111, loss_ce: 0.014245 loss_dice: 0.207354\n",
            "iteration 12767 : loss : 0.072055, loss_ce: 0.013034 loss_dice: 0.111403\n",
            "iteration 12768 : loss : 0.155905, loss_ce: 0.013113 loss_dice: 0.251100\n",
            "iteration 12769 : loss : 0.074027, loss_ce: 0.021641 loss_dice: 0.108951\n",
            "iteration 12770 : loss : 0.140824, loss_ce: 0.022641 loss_dice: 0.219612\n",
            "iteration 12771 : loss : 0.050912, loss_ce: 0.023980 loss_dice: 0.068867\n",
            "iteration 12772 : loss : 0.130740, loss_ce: 0.023253 loss_dice: 0.202398\n",
            "iteration 12773 : loss : 0.070794, loss_ce: 0.029372 loss_dice: 0.098410\n",
            "iteration 12774 : loss : 0.140007, loss_ce: 0.026616 loss_dice: 0.215601\n",
            "iteration 12775 : loss : 0.098468, loss_ce: 0.036834 loss_dice: 0.139557\n",
            "iteration 12776 : loss : 0.151317, loss_ce: 0.021781 loss_dice: 0.237674\n",
            "iteration 12777 : loss : 0.064446, loss_ce: 0.021168 loss_dice: 0.093297\n",
            "iteration 12778 : loss : 0.144499, loss_ce: 0.025683 loss_dice: 0.223709\n",
            "iteration 12779 : loss : 0.125544, loss_ce: 0.018881 loss_dice: 0.196653\n",
            "iteration 12780 : loss : 0.107182, loss_ce: 0.016636 loss_dice: 0.167547\n",
            "iteration 12781 : loss : 0.104489, loss_ce: 0.006258 loss_dice: 0.169977\n",
            "iteration 12782 : loss : 0.108578, loss_ce: 0.037105 loss_dice: 0.156227\n",
            "iteration 12783 : loss : 0.084671, loss_ce: 0.038647 loss_dice: 0.115354\n",
            "iteration 12784 : loss : 0.069634, loss_ce: 0.024193 loss_dice: 0.099928\n",
            "iteration 12785 : loss : 0.139309, loss_ce: 0.031388 loss_dice: 0.211256\n",
            "iteration 12786 : loss : 0.086361, loss_ce: 0.032208 loss_dice: 0.122463\n",
            "iteration 12787 : loss : 0.088458, loss_ce: 0.020871 loss_dice: 0.133516\n",
            "iteration 12788 : loss : 0.136650, loss_ce: 0.004940 loss_dice: 0.224456\n",
            "iteration 12789 : loss : 0.085809, loss_ce: 0.020070 loss_dice: 0.129635\n",
            "iteration 12790 : loss : 0.203447, loss_ce: 0.025209 loss_dice: 0.322273\n",
            "iteration 12791 : loss : 0.133760, loss_ce: 0.015721 loss_dice: 0.212453\n",
            "iteration 12792 : loss : 0.080147, loss_ce: 0.037230 loss_dice: 0.108758\n",
            "iteration 12793 : loss : 0.180018, loss_ce: 0.003198 loss_dice: 0.297898\n",
            "iteration 12794 : loss : 0.117653, loss_ce: 0.058891 loss_dice: 0.156828\n",
            "iteration 12795 : loss : 0.083830, loss_ce: 0.035392 loss_dice: 0.116122\n",
            "iteration 12796 : loss : 0.087961, loss_ce: 0.040440 loss_dice: 0.119641\n",
            "iteration 12797 : loss : 0.071510, loss_ce: 0.022143 loss_dice: 0.104421\n",
            "iteration 12798 : loss : 0.104009, loss_ce: 0.036638 loss_dice: 0.148923\n",
            "iteration 12799 : loss : 0.203265, loss_ce: 0.011075 loss_dice: 0.331392\n",
            "iteration 12800 : loss : 0.134168, loss_ce: 0.027700 loss_dice: 0.205147\n",
            "iteration 12801 : loss : 0.080943, loss_ce: 0.025432 loss_dice: 0.117950\n",
            "iteration 12802 : loss : 0.073854, loss_ce: 0.028193 loss_dice: 0.104294\n",
            "iteration 12803 : loss : 0.089778, loss_ce: 0.024529 loss_dice: 0.133278\n",
            "iteration 12804 : loss : 0.146698, loss_ce: 0.014295 loss_dice: 0.234967\n",
            "iteration 12805 : loss : 0.176411, loss_ce: 0.042025 loss_dice: 0.266002\n",
            "iteration 12806 : loss : 0.095711, loss_ce: 0.033190 loss_dice: 0.137391\n",
            "iteration 12807 : loss : 0.135862, loss_ce: 0.026080 loss_dice: 0.209050\n",
            "iteration 12808 : loss : 0.103738, loss_ce: 0.033469 loss_dice: 0.150584\n",
            "iteration 12809 : loss : 0.161226, loss_ce: 0.032726 loss_dice: 0.246893\n",
            "iteration 12810 : loss : 0.142721, loss_ce: 0.044851 loss_dice: 0.207967\n",
            "iteration 12811 : loss : 0.152750, loss_ce: 0.044704 loss_dice: 0.224780\n",
            "iteration 12812 : loss : 0.101167, loss_ce: 0.025968 loss_dice: 0.151300\n",
            "iteration 12813 : loss : 0.220738, loss_ce: 0.006265 loss_dice: 0.363720\n",
            "iteration 12814 : loss : 0.097753, loss_ce: 0.028479 loss_dice: 0.143935\n",
            "iteration 12815 : loss : 0.194572, loss_ce: 0.026817 loss_dice: 0.306409\n",
            "iteration 12816 : loss : 0.137822, loss_ce: 0.037907 loss_dice: 0.204433\n",
            "iteration 12817 : loss : 0.077770, loss_ce: 0.028367 loss_dice: 0.110706\n",
            "iteration 12818 : loss : 0.153427, loss_ce: 0.036044 loss_dice: 0.231683\n",
            "iteration 12819 : loss : 0.214660, loss_ce: 0.030332 loss_dice: 0.337546\n",
            "iteration 12820 : loss : 0.181859, loss_ce: 0.035452 loss_dice: 0.279464\n",
            "iteration 12821 : loss : 0.087971, loss_ce: 0.035015 loss_dice: 0.123274\n",
            "iteration 12822 : loss : 0.170869, loss_ce: 0.041388 loss_dice: 0.257190\n",
            "iteration 12823 : loss : 0.065421, loss_ce: 0.015835 loss_dice: 0.098477\n",
            "iteration 12824 : loss : 0.158565, loss_ce: 0.023491 loss_dice: 0.248614\n",
            "iteration 12825 : loss : 0.144243, loss_ce: 0.039820 loss_dice: 0.213859\n",
            "iteration 12826 : loss : 0.074178, loss_ce: 0.027761 loss_dice: 0.105122\n",
            "iteration 12827 : loss : 0.154692, loss_ce: 0.026556 loss_dice: 0.240115\n",
            "iteration 12828 : loss : 0.174087, loss_ce: 0.007281 loss_dice: 0.285291\n",
            "iteration 12829 : loss : 0.069912, loss_ce: 0.018046 loss_dice: 0.104490\n",
            "iteration 12830 : loss : 0.242815, loss_ce: 0.010821 loss_dice: 0.397478\n",
            "iteration 12831 : loss : 0.155122, loss_ce: 0.014193 loss_dice: 0.249074\n",
            "iteration 12832 : loss : 0.074073, loss_ce: 0.009274 loss_dice: 0.117272\n",
            "iteration 12833 : loss : 0.091936, loss_ce: 0.030958 loss_dice: 0.132588\n",
            "iteration 12834 : loss : 0.175915, loss_ce: 0.048705 loss_dice: 0.260722\n",
            "iteration 12835 : loss : 0.154670, loss_ce: 0.059303 loss_dice: 0.218247\n",
            "iteration 12836 : loss : 0.216446, loss_ce: 0.017934 loss_dice: 0.348787\n",
            "iteration 12837 : loss : 0.110179, loss_ce: 0.040020 loss_dice: 0.156951\n",
            "iteration 12838 : loss : 0.170748, loss_ce: 0.074529 loss_dice: 0.234895\n",
            "iteration 12839 : loss : 0.113347, loss_ce: 0.040693 loss_dice: 0.161782\n",
            "iteration 12840 : loss : 0.158094, loss_ce: 0.064961 loss_dice: 0.220183\n",
            "iteration 12841 : loss : 0.039543, loss_ce: 0.012693 loss_dice: 0.057444\n",
            "iteration 12842 : loss : 0.154894, loss_ce: 0.054434 loss_dice: 0.221868\n",
            "iteration 12843 : loss : 0.148196, loss_ce: 0.033334 loss_dice: 0.224771\n",
            "iteration 12844 : loss : 0.175066, loss_ce: 0.020890 loss_dice: 0.277850\n",
            "iteration 12845 : loss : 0.083837, loss_ce: 0.024529 loss_dice: 0.123375\n",
            "iteration 12846 : loss : 0.159429, loss_ce: 0.025332 loss_dice: 0.248828\n",
            "iteration 12847 : loss : 0.071862, loss_ce: 0.021426 loss_dice: 0.105487\n",
            "iteration 12848 : loss : 0.113202, loss_ce: 0.039483 loss_dice: 0.162348\n",
            "iteration 12849 : loss : 0.180451, loss_ce: 0.053096 loss_dice: 0.265355\n",
            "iteration 12850 : loss : 0.126037, loss_ce: 0.019808 loss_dice: 0.196856\n",
            "iteration 12851 : loss : 0.073529, loss_ce: 0.015349 loss_dice: 0.112315\n",
            "iteration 12852 : loss : 0.097341, loss_ce: 0.014971 loss_dice: 0.152255\n",
            "iteration 12853 : loss : 0.112259, loss_ce: 0.041774 loss_dice: 0.159249\n",
            "iteration 12854 : loss : 0.205290, loss_ce: 0.004957 loss_dice: 0.338845\n",
            "iteration 12855 : loss : 0.165028, loss_ce: 0.024821 loss_dice: 0.258499\n",
            "iteration 12856 : loss : 0.100758, loss_ce: 0.029234 loss_dice: 0.148440\n",
            "iteration 12857 : loss : 0.094128, loss_ce: 0.060537 loss_dice: 0.116521\n",
            "iteration 12858 : loss : 0.162039, loss_ce: 0.040121 loss_dice: 0.243318\n",
            "iteration 12859 : loss : 0.169200, loss_ce: 0.012284 loss_dice: 0.273811\n",
            "iteration 12860 : loss : 0.097699, loss_ce: 0.031124 loss_dice: 0.142082\n",
            "iteration 12861 : loss : 0.090570, loss_ce: 0.018333 loss_dice: 0.138728\n",
            "iteration 12862 : loss : 0.201205, loss_ce: 0.006135 loss_dice: 0.331251\n",
            "iteration 12863 : loss : 0.078984, loss_ce: 0.026572 loss_dice: 0.113926\n",
            "iteration 12864 : loss : 0.053732, loss_ce: 0.014711 loss_dice: 0.079746\n",
            "iteration 12865 : loss : 0.140870, loss_ce: 0.031861 loss_dice: 0.213543\n",
            "iteration 12866 : loss : 0.125252, loss_ce: 0.023963 loss_dice: 0.192778\n",
            "iteration 12867 : loss : 0.074791, loss_ce: 0.035313 loss_dice: 0.101110\n",
            "iteration 12868 : loss : 0.096732, loss_ce: 0.037262 loss_dice: 0.136379\n",
            "iteration 12869 : loss : 0.045006, loss_ce: 0.005116 loss_dice: 0.071599\n",
            "iteration 12870 : loss : 0.141603, loss_ce: 0.030279 loss_dice: 0.215820\n",
            "iteration 12871 : loss : 0.126987, loss_ce: 0.058163 loss_dice: 0.172870\n",
            "iteration 12872 : loss : 0.099137, loss_ce: 0.038787 loss_dice: 0.139370\n",
            "iteration 12873 : loss : 0.147798, loss_ce: 0.038362 loss_dice: 0.220755\n",
            "iteration 12874 : loss : 0.130830, loss_ce: 0.037316 loss_dice: 0.193173\n",
            "iteration 12875 : loss : 0.150073, loss_ce: 0.037582 loss_dice: 0.225067\n",
            "iteration 12876 : loss : 0.223665, loss_ce: 0.086324 loss_dice: 0.315226\n",
            " 12%|███▏                       | 58/500 [2:07:40<10:20:18, 84.20s/it]iteration 12877 : loss : 0.213054, loss_ce: 0.029254 loss_dice: 0.335588\n",
            "iteration 12878 : loss : 0.097051, loss_ce: 0.026062 loss_dice: 0.144377\n",
            "iteration 12879 : loss : 0.241159, loss_ce: 0.005977 loss_dice: 0.397948\n",
            "iteration 12880 : loss : 0.212132, loss_ce: 0.015905 loss_dice: 0.342950\n",
            "iteration 12881 : loss : 0.099583, loss_ce: 0.019592 loss_dice: 0.152911\n",
            "iteration 12882 : loss : 0.188384, loss_ce: 0.018342 loss_dice: 0.301746\n",
            "iteration 12883 : loss : 0.174263, loss_ce: 0.037758 loss_dice: 0.265266\n",
            "iteration 12884 : loss : 0.090666, loss_ce: 0.028347 loss_dice: 0.132211\n",
            "iteration 12885 : loss : 0.086971, loss_ce: 0.026397 loss_dice: 0.127354\n",
            "iteration 12886 : loss : 0.178894, loss_ce: 0.035779 loss_dice: 0.274305\n",
            "iteration 12887 : loss : 0.086858, loss_ce: 0.028335 loss_dice: 0.125873\n",
            "iteration 12888 : loss : 0.116628, loss_ce: 0.023429 loss_dice: 0.178761\n",
            "iteration 12889 : loss : 0.087557, loss_ce: 0.031755 loss_dice: 0.124759\n",
            "iteration 12890 : loss : 0.109733, loss_ce: 0.013822 loss_dice: 0.173674\n",
            "iteration 12891 : loss : 0.089194, loss_ce: 0.016605 loss_dice: 0.137587\n",
            "iteration 12892 : loss : 0.088450, loss_ce: 0.023814 loss_dice: 0.131540\n",
            "iteration 12893 : loss : 0.069962, loss_ce: 0.016261 loss_dice: 0.105762\n",
            "iteration 12894 : loss : 0.109571, loss_ce: 0.022817 loss_dice: 0.167408\n",
            "iteration 12895 : loss : 0.160682, loss_ce: 0.056014 loss_dice: 0.230460\n",
            "iteration 12896 : loss : 0.146049, loss_ce: 0.048842 loss_dice: 0.210853\n",
            "iteration 12897 : loss : 0.134541, loss_ce: 0.015989 loss_dice: 0.213575\n",
            "iteration 12898 : loss : 0.131145, loss_ce: 0.019305 loss_dice: 0.205705\n",
            "iteration 12899 : loss : 0.086131, loss_ce: 0.023629 loss_dice: 0.127800\n",
            "iteration 12900 : loss : 0.093112, loss_ce: 0.017490 loss_dice: 0.143527\n",
            "iteration 12901 : loss : 0.155351, loss_ce: 0.035475 loss_dice: 0.235269\n",
            "iteration 12902 : loss : 0.123518, loss_ce: 0.030672 loss_dice: 0.185416\n",
            "iteration 12903 : loss : 0.079651, loss_ce: 0.014411 loss_dice: 0.123145\n",
            "iteration 12904 : loss : 0.110791, loss_ce: 0.021289 loss_dice: 0.170459\n",
            "iteration 12905 : loss : 0.053914, loss_ce: 0.020681 loss_dice: 0.076070\n",
            "iteration 12906 : loss : 0.144122, loss_ce: 0.040667 loss_dice: 0.213093\n",
            "iteration 12907 : loss : 0.077059, loss_ce: 0.030505 loss_dice: 0.108095\n",
            "iteration 12908 : loss : 0.085441, loss_ce: 0.032905 loss_dice: 0.120465\n",
            "iteration 12909 : loss : 0.130894, loss_ce: 0.034483 loss_dice: 0.195169\n",
            "iteration 12910 : loss : 0.190291, loss_ce: 0.011152 loss_dice: 0.309717\n",
            "iteration 12911 : loss : 0.091637, loss_ce: 0.023190 loss_dice: 0.137269\n",
            "iteration 12912 : loss : 0.060989, loss_ce: 0.022946 loss_dice: 0.086351\n",
            "iteration 12913 : loss : 0.122858, loss_ce: 0.011124 loss_dice: 0.197347\n",
            "iteration 12914 : loss : 0.134965, loss_ce: 0.040442 loss_dice: 0.197980\n",
            "iteration 12915 : loss : 0.182611, loss_ce: 0.032571 loss_dice: 0.282639\n",
            "iteration 12916 : loss : 0.112685, loss_ce: 0.037420 loss_dice: 0.162861\n",
            "iteration 12917 : loss : 0.158555, loss_ce: 0.025715 loss_dice: 0.247115\n",
            "iteration 12918 : loss : 0.193486, loss_ce: 0.042547 loss_dice: 0.294112\n",
            "iteration 12919 : loss : 0.268736, loss_ce: 0.057492 loss_dice: 0.409566\n",
            "iteration 12920 : loss : 0.246387, loss_ce: 0.092907 loss_dice: 0.348707\n",
            "iteration 12921 : loss : 0.281290, loss_ce: 0.041209 loss_dice: 0.441344\n",
            "iteration 12922 : loss : 0.195444, loss_ce: 0.043119 loss_dice: 0.296995\n",
            "iteration 12923 : loss : 0.230914, loss_ce: 0.058750 loss_dice: 0.345690\n",
            "iteration 12924 : loss : 0.239324, loss_ce: 0.054123 loss_dice: 0.362791\n",
            "iteration 12925 : loss : 0.189071, loss_ce: 0.089012 loss_dice: 0.255778\n",
            "iteration 12926 : loss : 0.159030, loss_ce: 0.078843 loss_dice: 0.212488\n",
            "iteration 12927 : loss : 0.143856, loss_ce: 0.065073 loss_dice: 0.196377\n",
            "iteration 12928 : loss : 0.120332, loss_ce: 0.030695 loss_dice: 0.180089\n",
            "iteration 12929 : loss : 0.222142, loss_ce: 0.040143 loss_dice: 0.343475\n",
            "iteration 12930 : loss : 0.205514, loss_ce: 0.014363 loss_dice: 0.332947\n",
            "iteration 12931 : loss : 0.145880, loss_ce: 0.029884 loss_dice: 0.223211\n",
            "iteration 12932 : loss : 0.170435, loss_ce: 0.017151 loss_dice: 0.272624\n",
            "iteration 12933 : loss : 0.159254, loss_ce: 0.049917 loss_dice: 0.232145\n",
            "iteration 12934 : loss : 0.196435, loss_ce: 0.019128 loss_dice: 0.314639\n",
            "iteration 12935 : loss : 0.198909, loss_ce: 0.054848 loss_dice: 0.294949\n",
            "iteration 12936 : loss : 0.144969, loss_ce: 0.042990 loss_dice: 0.212954\n",
            "iteration 12937 : loss : 0.221040, loss_ce: 0.022201 loss_dice: 0.353599\n",
            "iteration 12938 : loss : 0.173016, loss_ce: 0.011912 loss_dice: 0.280418\n",
            "iteration 12939 : loss : 0.115173, loss_ce: 0.050389 loss_dice: 0.158362\n",
            "iteration 12940 : loss : 0.265075, loss_ce: 0.020638 loss_dice: 0.428032\n",
            "iteration 12941 : loss : 0.172106, loss_ce: 0.044214 loss_dice: 0.257367\n",
            "iteration 12942 : loss : 0.111381, loss_ce: 0.022446 loss_dice: 0.170671\n",
            "iteration 12943 : loss : 0.120929, loss_ce: 0.024623 loss_dice: 0.185133\n",
            "iteration 12944 : loss : 0.163503, loss_ce: 0.017707 loss_dice: 0.260701\n",
            "iteration 12945 : loss : 0.121717, loss_ce: 0.058196 loss_dice: 0.164064\n",
            "iteration 12946 : loss : 0.132800, loss_ce: 0.035712 loss_dice: 0.197525\n",
            "iteration 12947 : loss : 0.150545, loss_ce: 0.038307 loss_dice: 0.225371\n",
            "iteration 12948 : loss : 0.091048, loss_ce: 0.042019 loss_dice: 0.123734\n",
            "iteration 12949 : loss : 0.132909, loss_ce: 0.026257 loss_dice: 0.204011\n",
            "iteration 12950 : loss : 0.091315, loss_ce: 0.036058 loss_dice: 0.128153\n",
            "iteration 12951 : loss : 0.102290, loss_ce: 0.021683 loss_dice: 0.156029\n",
            "iteration 12952 : loss : 0.223463, loss_ce: 0.004696 loss_dice: 0.369309\n",
            "iteration 12953 : loss : 0.066979, loss_ce: 0.015175 loss_dice: 0.101516\n",
            "iteration 12954 : loss : 0.105596, loss_ce: 0.035854 loss_dice: 0.152090\n",
            "iteration 12955 : loss : 0.185915, loss_ce: 0.011338 loss_dice: 0.302300\n",
            "iteration 12956 : loss : 0.107071, loss_ce: 0.026807 loss_dice: 0.160581\n",
            "iteration 12957 : loss : 0.081581, loss_ce: 0.035246 loss_dice: 0.112470\n",
            "iteration 12958 : loss : 0.095213, loss_ce: 0.034447 loss_dice: 0.135724\n",
            "iteration 12959 : loss : 0.095924, loss_ce: 0.028029 loss_dice: 0.141187\n",
            "iteration 12960 : loss : 0.119376, loss_ce: 0.028920 loss_dice: 0.179680\n",
            "iteration 12961 : loss : 0.072088, loss_ce: 0.028624 loss_dice: 0.101065\n",
            "iteration 12962 : loss : 0.111574, loss_ce: 0.014612 loss_dice: 0.176216\n",
            "iteration 12963 : loss : 0.070077, loss_ce: 0.022668 loss_dice: 0.101683\n",
            "iteration 12964 : loss : 0.161667, loss_ce: 0.025237 loss_dice: 0.252620\n",
            "iteration 12965 : loss : 0.078172, loss_ce: 0.017314 loss_dice: 0.118745\n",
            "iteration 12966 : loss : 0.132560, loss_ce: 0.021393 loss_dice: 0.206672\n",
            "iteration 12967 : loss : 0.142140, loss_ce: 0.027214 loss_dice: 0.218758\n",
            "iteration 12968 : loss : 0.367491, loss_ce: 0.014543 loss_dice: 0.602790\n",
            "iteration 12969 : loss : 0.107209, loss_ce: 0.031903 loss_dice: 0.157414\n",
            "iteration 12970 : loss : 0.185089, loss_ce: 0.021142 loss_dice: 0.294386\n",
            "iteration 12971 : loss : 0.177744, loss_ce: 0.025853 loss_dice: 0.279005\n",
            "iteration 12972 : loss : 0.137966, loss_ce: 0.033784 loss_dice: 0.207420\n",
            "iteration 12973 : loss : 0.115121, loss_ce: 0.039379 loss_dice: 0.165616\n",
            "iteration 12974 : loss : 0.105236, loss_ce: 0.039462 loss_dice: 0.149085\n",
            "iteration 12975 : loss : 0.055640, loss_ce: 0.022721 loss_dice: 0.077587\n",
            "iteration 12976 : loss : 0.117917, loss_ce: 0.016813 loss_dice: 0.185319\n",
            "iteration 12977 : loss : 0.073168, loss_ce: 0.028407 loss_dice: 0.103010\n",
            "iteration 12978 : loss : 0.145486, loss_ce: 0.046231 loss_dice: 0.211655\n",
            "iteration 12979 : loss : 0.138368, loss_ce: 0.022580 loss_dice: 0.215560\n",
            "iteration 12980 : loss : 0.070873, loss_ce: 0.025879 loss_dice: 0.100869\n",
            "iteration 12981 : loss : 0.090220, loss_ce: 0.021175 loss_dice: 0.136251\n",
            "iteration 12982 : loss : 0.113342, loss_ce: 0.030922 loss_dice: 0.168288\n",
            "iteration 12983 : loss : 0.099789, loss_ce: 0.032811 loss_dice: 0.144441\n",
            "iteration 12984 : loss : 0.125861, loss_ce: 0.016491 loss_dice: 0.198774\n",
            "iteration 12985 : loss : 0.117397, loss_ce: 0.011701 loss_dice: 0.187862\n",
            "iteration 12986 : loss : 0.135369, loss_ce: 0.011277 loss_dice: 0.218098\n",
            "iteration 12987 : loss : 0.049489, loss_ce: 0.009756 loss_dice: 0.075977\n",
            "iteration 12988 : loss : 0.063526, loss_ce: 0.029726 loss_dice: 0.086058\n",
            "iteration 12989 : loss : 0.080556, loss_ce: 0.018736 loss_dice: 0.121770\n",
            "iteration 12990 : loss : 0.099850, loss_ce: 0.010288 loss_dice: 0.159558\n",
            "iteration 12991 : loss : 0.101077, loss_ce: 0.005743 loss_dice: 0.164633\n",
            "iteration 12992 : loss : 0.080262, loss_ce: 0.043210 loss_dice: 0.104964\n",
            "iteration 12993 : loss : 0.091472, loss_ce: 0.034919 loss_dice: 0.129175\n",
            "iteration 12994 : loss : 0.093744, loss_ce: 0.030643 loss_dice: 0.135812\n",
            "iteration 12995 : loss : 0.150672, loss_ce: 0.024090 loss_dice: 0.235060\n",
            "iteration 12996 : loss : 0.178956, loss_ce: 0.008466 loss_dice: 0.292615\n",
            "iteration 12997 : loss : 0.141957, loss_ce: 0.028609 loss_dice: 0.217522\n",
            "iteration 12998 : loss : 0.081745, loss_ce: 0.021428 loss_dice: 0.121955\n",
            "iteration 12999 : loss : 0.130211, loss_ce: 0.024016 loss_dice: 0.201008\n",
            "iteration 13000 : loss : 0.085814, loss_ce: 0.026524 loss_dice: 0.125341\n",
            "iteration 13001 : loss : 0.072155, loss_ce: 0.032146 loss_dice: 0.098827\n",
            "iteration 13002 : loss : 0.168148, loss_ce: 0.012285 loss_dice: 0.272057\n",
            "iteration 13003 : loss : 0.134238, loss_ce: 0.027044 loss_dice: 0.205702\n",
            "iteration 13004 : loss : 0.067924, loss_ce: 0.036593 loss_dice: 0.088811\n",
            "iteration 13005 : loss : 0.099801, loss_ce: 0.018546 loss_dice: 0.153971\n",
            "iteration 13006 : loss : 0.095288, loss_ce: 0.037780 loss_dice: 0.133626\n",
            "iteration 13007 : loss : 0.140364, loss_ce: 0.022971 loss_dice: 0.218626\n",
            "iteration 13008 : loss : 0.089412, loss_ce: 0.043914 loss_dice: 0.119744\n",
            "iteration 13009 : loss : 0.090556, loss_ce: 0.036769 loss_dice: 0.126415\n",
            "iteration 13010 : loss : 0.099925, loss_ce: 0.034392 loss_dice: 0.143614\n",
            "iteration 13011 : loss : 0.131812, loss_ce: 0.032232 loss_dice: 0.198199\n",
            "iteration 13012 : loss : 0.154488, loss_ce: 0.015611 loss_dice: 0.247072\n",
            "iteration 13013 : loss : 0.077351, loss_ce: 0.016928 loss_dice: 0.117633\n",
            "iteration 13014 : loss : 0.060095, loss_ce: 0.023522 loss_dice: 0.084477\n",
            "iteration 13015 : loss : 0.194124, loss_ce: 0.010774 loss_dice: 0.316358\n",
            "iteration 13016 : loss : 0.164010, loss_ce: 0.019012 loss_dice: 0.260676\n",
            "iteration 13017 : loss : 0.135532, loss_ce: 0.019471 loss_dice: 0.212906\n",
            "iteration 13018 : loss : 0.070046, loss_ce: 0.027401 loss_dice: 0.098476\n",
            "iteration 13019 : loss : 0.052999, loss_ce: 0.014981 loss_dice: 0.078345\n",
            "iteration 13020 : loss : 0.084891, loss_ce: 0.020691 loss_dice: 0.127691\n",
            "iteration 13021 : loss : 0.102014, loss_ce: 0.025836 loss_dice: 0.152800\n",
            "iteration 13022 : loss : 0.076756, loss_ce: 0.011168 loss_dice: 0.120481\n",
            "iteration 13023 : loss : 0.100840, loss_ce: 0.017603 loss_dice: 0.156331\n",
            "iteration 13024 : loss : 0.148048, loss_ce: 0.018826 loss_dice: 0.234197\n",
            "iteration 13025 : loss : 0.102886, loss_ce: 0.021703 loss_dice: 0.157008\n",
            "iteration 13026 : loss : 0.068800, loss_ce: 0.011724 loss_dice: 0.106851\n",
            "iteration 13027 : loss : 0.139851, loss_ce: 0.022502 loss_dice: 0.218083\n",
            "iteration 13028 : loss : 0.089972, loss_ce: 0.047635 loss_dice: 0.118196\n",
            "iteration 13029 : loss : 0.080322, loss_ce: 0.023389 loss_dice: 0.118277\n",
            "iteration 13030 : loss : 0.124758, loss_ce: 0.010852 loss_dice: 0.200696\n",
            "iteration 13031 : loss : 0.089899, loss_ce: 0.020537 loss_dice: 0.136141\n",
            "iteration 13032 : loss : 0.072259, loss_ce: 0.032787 loss_dice: 0.098573\n",
            "iteration 13033 : loss : 0.165888, loss_ce: 0.003598 loss_dice: 0.274081\n",
            "iteration 13034 : loss : 0.153284, loss_ce: 0.008546 loss_dice: 0.249776\n",
            "iteration 13035 : loss : 0.141884, loss_ce: 0.056410 loss_dice: 0.198867\n",
            "iteration 13036 : loss : 0.118405, loss_ce: 0.015110 loss_dice: 0.187268\n",
            "iteration 13037 : loss : 0.244950, loss_ce: 0.013349 loss_dice: 0.399351\n",
            "iteration 13038 : loss : 0.156678, loss_ce: 0.026073 loss_dice: 0.243747\n",
            "iteration 13039 : loss : 0.173725, loss_ce: 0.056456 loss_dice: 0.251905\n",
            "iteration 13040 : loss : 0.084007, loss_ce: 0.024093 loss_dice: 0.123950\n",
            "iteration 13041 : loss : 0.163133, loss_ce: 0.061750 loss_dice: 0.230721\n",
            "iteration 13042 : loss : 0.158092, loss_ce: 0.014051 loss_dice: 0.254120\n",
            "iteration 13043 : loss : 0.167778, loss_ce: 0.065305 loss_dice: 0.236093\n",
            "iteration 13044 : loss : 0.182757, loss_ce: 0.089056 loss_dice: 0.245225\n",
            "iteration 13045 : loss : 0.098439, loss_ce: 0.031841 loss_dice: 0.142838\n",
            "iteration 13046 : loss : 0.214488, loss_ce: 0.023368 loss_dice: 0.341901\n",
            "iteration 13047 : loss : 0.144493, loss_ce: 0.048363 loss_dice: 0.208580\n",
            "iteration 13048 : loss : 0.085323, loss_ce: 0.015809 loss_dice: 0.131665\n",
            "iteration 13049 : loss : 0.104890, loss_ce: 0.042919 loss_dice: 0.146204\n",
            "iteration 13050 : loss : 0.147540, loss_ce: 0.047483 loss_dice: 0.214246\n",
            "iteration 13051 : loss : 0.152609, loss_ce: 0.045383 loss_dice: 0.224094\n",
            "iteration 13052 : loss : 0.218135, loss_ce: 0.061367 loss_dice: 0.322647\n",
            "iteration 13053 : loss : 0.163977, loss_ce: 0.018611 loss_dice: 0.260887\n",
            "iteration 13054 : loss : 0.158240, loss_ce: 0.053564 loss_dice: 0.228024\n",
            "iteration 13055 : loss : 0.096024, loss_ce: 0.013268 loss_dice: 0.151194\n",
            "iteration 13056 : loss : 0.072459, loss_ce: 0.025842 loss_dice: 0.103537\n",
            "iteration 13057 : loss : 0.191752, loss_ce: 0.036132 loss_dice: 0.295499\n",
            "iteration 13058 : loss : 0.042659, loss_ce: 0.007603 loss_dice: 0.066029\n",
            "iteration 13059 : loss : 0.231428, loss_ce: 0.017600 loss_dice: 0.373980\n",
            "iteration 13060 : loss : 0.117132, loss_ce: 0.038253 loss_dice: 0.169719\n",
            "iteration 13061 : loss : 0.179312, loss_ce: 0.053183 loss_dice: 0.263398\n",
            "iteration 13062 : loss : 0.094005, loss_ce: 0.016978 loss_dice: 0.145357\n",
            "iteration 13063 : loss : 0.144051, loss_ce: 0.021148 loss_dice: 0.225987\n",
            "iteration 13064 : loss : 0.126547, loss_ce: 0.031454 loss_dice: 0.189942\n",
            "iteration 13065 : loss : 0.152023, loss_ce: 0.055366 loss_dice: 0.216461\n",
            "iteration 13066 : loss : 0.080214, loss_ce: 0.020908 loss_dice: 0.119752\n",
            "iteration 13067 : loss : 0.151124, loss_ce: 0.025965 loss_dice: 0.234563\n",
            "iteration 13068 : loss : 0.076558, loss_ce: 0.021658 loss_dice: 0.113159\n",
            "iteration 13069 : loss : 0.142067, loss_ce: 0.032138 loss_dice: 0.215353\n",
            "iteration 13070 : loss : 0.129690, loss_ce: 0.022128 loss_dice: 0.201397\n",
            "iteration 13071 : loss : 0.150239, loss_ce: 0.040982 loss_dice: 0.223077\n",
            "iteration 13072 : loss : 0.165490, loss_ce: 0.056867 loss_dice: 0.237905\n",
            "iteration 13073 : loss : 0.251894, loss_ce: 0.019987 loss_dice: 0.406499\n",
            "iteration 13074 : loss : 0.158778, loss_ce: 0.038349 loss_dice: 0.239065\n",
            "iteration 13075 : loss : 0.154481, loss_ce: 0.045079 loss_dice: 0.227415\n",
            "iteration 13076 : loss : 0.211210, loss_ce: 0.014581 loss_dice: 0.342296\n",
            "iteration 13077 : loss : 0.143220, loss_ce: 0.038126 loss_dice: 0.213283\n",
            "iteration 13078 : loss : 0.117200, loss_ce: 0.019600 loss_dice: 0.182266\n",
            "iteration 13079 : loss : 0.153697, loss_ce: 0.015958 loss_dice: 0.245523\n",
            "iteration 13080 : loss : 0.154030, loss_ce: 0.034721 loss_dice: 0.233570\n",
            "iteration 13081 : loss : 0.065505, loss_ce: 0.028144 loss_dice: 0.090412\n",
            "iteration 13082 : loss : 0.147974, loss_ce: 0.062521 loss_dice: 0.204942\n",
            "iteration 13083 : loss : 0.065511, loss_ce: 0.022265 loss_dice: 0.094342\n",
            "iteration 13084 : loss : 0.072966, loss_ce: 0.023207 loss_dice: 0.106139\n",
            "iteration 13085 : loss : 0.171697, loss_ce: 0.021100 loss_dice: 0.272094\n",
            "iteration 13086 : loss : 0.128759, loss_ce: 0.035715 loss_dice: 0.190788\n",
            "iteration 13087 : loss : 0.162315, loss_ce: 0.042004 loss_dice: 0.242522\n",
            "iteration 13088 : loss : 0.265068, loss_ce: 0.022347 loss_dice: 0.426883\n",
            "iteration 13089 : loss : 0.119475, loss_ce: 0.024418 loss_dice: 0.182847\n",
            "iteration 13090 : loss : 0.085070, loss_ce: 0.035077 loss_dice: 0.118399\n",
            "iteration 13091 : loss : 0.115624, loss_ce: 0.028083 loss_dice: 0.173985\n",
            "iteration 13092 : loss : 0.083933, loss_ce: 0.016556 loss_dice: 0.128851\n",
            "iteration 13093 : loss : 0.112211, loss_ce: 0.024222 loss_dice: 0.170871\n",
            "iteration 13094 : loss : 0.149683, loss_ce: 0.023863 loss_dice: 0.233564\n",
            "iteration 13095 : loss : 0.100189, loss_ce: 0.025455 loss_dice: 0.150011\n",
            "iteration 13096 : loss : 0.139813, loss_ce: 0.046454 loss_dice: 0.202053\n",
            "iteration 13097 : loss : 0.052659, loss_ce: 0.021396 loss_dice: 0.073501\n",
            "iteration 13098 : loss : 0.073131, loss_ce: 0.000026 loss_dice: 0.121867\n",
            " 12%|███▏                       | 59/500 [2:09:03<10:16:10, 83.83s/it]iteration 13099 : loss : 0.074333, loss_ce: 0.017810 loss_dice: 0.112014\n",
            "iteration 13100 : loss : 0.138266, loss_ce: 0.039156 loss_dice: 0.204339\n",
            "iteration 13101 : loss : 0.149550, loss_ce: 0.040702 loss_dice: 0.222115\n",
            "iteration 13102 : loss : 0.128048, loss_ce: 0.037984 loss_dice: 0.188091\n",
            "iteration 13103 : loss : 0.102485, loss_ce: 0.030679 loss_dice: 0.150356\n",
            "iteration 13104 : loss : 0.171345, loss_ce: 0.009421 loss_dice: 0.279293\n",
            "iteration 13105 : loss : 0.097686, loss_ce: 0.034960 loss_dice: 0.139503\n",
            "iteration 13106 : loss : 0.177881, loss_ce: 0.014782 loss_dice: 0.286613\n",
            "iteration 13107 : loss : 0.093439, loss_ce: 0.012816 loss_dice: 0.147188\n",
            "iteration 13108 : loss : 0.114193, loss_ce: 0.009820 loss_dice: 0.183775\n",
            "iteration 13109 : loss : 0.082013, loss_ce: 0.041111 loss_dice: 0.109281\n",
            "iteration 13110 : loss : 0.060426, loss_ce: 0.014219 loss_dice: 0.091231\n",
            "iteration 13111 : loss : 0.079635, loss_ce: 0.014638 loss_dice: 0.122966\n",
            "iteration 13112 : loss : 0.112783, loss_ce: 0.015953 loss_dice: 0.177336\n",
            "iteration 13113 : loss : 0.157739, loss_ce: 0.011399 loss_dice: 0.255298\n",
            "iteration 13114 : loss : 0.135372, loss_ce: 0.017712 loss_dice: 0.213813\n",
            "iteration 13115 : loss : 0.138053, loss_ce: 0.038650 loss_dice: 0.204321\n",
            "iteration 13116 : loss : 0.108850, loss_ce: 0.034355 loss_dice: 0.158513\n",
            "iteration 13117 : loss : 0.153247, loss_ce: 0.020490 loss_dice: 0.241751\n",
            "iteration 13118 : loss : 0.107928, loss_ce: 0.025695 loss_dice: 0.162750\n",
            "iteration 13119 : loss : 0.128195, loss_ce: 0.020048 loss_dice: 0.200294\n",
            "iteration 13120 : loss : 0.061979, loss_ce: 0.012854 loss_dice: 0.094730\n",
            "iteration 13121 : loss : 0.137882, loss_ce: 0.040408 loss_dice: 0.202865\n",
            "iteration 13122 : loss : 0.170637, loss_ce: 0.008878 loss_dice: 0.278477\n",
            "iteration 13123 : loss : 0.131603, loss_ce: 0.028789 loss_dice: 0.200145\n",
            "iteration 13124 : loss : 0.153186, loss_ce: 0.022071 loss_dice: 0.240596\n",
            "iteration 13125 : loss : 0.084647, loss_ce: 0.011105 loss_dice: 0.133674\n",
            "iteration 13126 : loss : 0.187461, loss_ce: 0.023939 loss_dice: 0.296476\n",
            "iteration 13127 : loss : 0.155974, loss_ce: 0.082697 loss_dice: 0.204825\n",
            "iteration 13128 : loss : 0.096327, loss_ce: 0.035933 loss_dice: 0.136590\n",
            "iteration 13129 : loss : 0.117010, loss_ce: 0.030076 loss_dice: 0.174966\n",
            "iteration 13130 : loss : 0.130662, loss_ce: 0.034665 loss_dice: 0.194659\n",
            "iteration 13131 : loss : 0.096341, loss_ce: 0.032622 loss_dice: 0.138820\n",
            "iteration 13132 : loss : 0.239692, loss_ce: 0.019478 loss_dice: 0.386502\n",
            "iteration 13133 : loss : 0.186885, loss_ce: 0.018359 loss_dice: 0.299235\n",
            "iteration 13134 : loss : 0.077851, loss_ce: 0.008061 loss_dice: 0.124377\n",
            "iteration 13135 : loss : 0.142650, loss_ce: 0.022398 loss_dice: 0.222818\n",
            "iteration 13136 : loss : 0.127830, loss_ce: 0.026290 loss_dice: 0.195524\n",
            "iteration 13137 : loss : 0.125051, loss_ce: 0.016105 loss_dice: 0.197683\n",
            "iteration 13138 : loss : 0.126987, loss_ce: 0.023861 loss_dice: 0.195738\n",
            "iteration 13139 : loss : 0.103699, loss_ce: 0.050674 loss_dice: 0.139048\n",
            "iteration 13140 : loss : 0.079071, loss_ce: 0.020963 loss_dice: 0.117809\n",
            "iteration 13141 : loss : 0.171753, loss_ce: 0.051890 loss_dice: 0.251662\n",
            "iteration 13142 : loss : 0.073950, loss_ce: 0.022072 loss_dice: 0.108535\n",
            "iteration 13143 : loss : 0.139055, loss_ce: 0.020429 loss_dice: 0.218139\n",
            "iteration 13144 : loss : 0.147763, loss_ce: 0.036236 loss_dice: 0.222114\n",
            "iteration 13145 : loss : 0.065751, loss_ce: 0.024774 loss_dice: 0.093069\n",
            "iteration 13146 : loss : 0.127974, loss_ce: 0.041039 loss_dice: 0.185930\n",
            "iteration 13147 : loss : 0.085034, loss_ce: 0.032852 loss_dice: 0.119823\n",
            "iteration 13148 : loss : 0.132882, loss_ce: 0.027250 loss_dice: 0.203303\n",
            "iteration 13149 : loss : 0.158726, loss_ce: 0.014026 loss_dice: 0.255193\n",
            "iteration 13150 : loss : 0.131058, loss_ce: 0.022702 loss_dice: 0.203295\n",
            "iteration 13151 : loss : 0.133985, loss_ce: 0.026461 loss_dice: 0.205668\n",
            "iteration 13152 : loss : 0.200846, loss_ce: 0.039069 loss_dice: 0.308698\n",
            "iteration 13153 : loss : 0.119292, loss_ce: 0.021062 loss_dice: 0.184778\n",
            "iteration 13154 : loss : 0.092264, loss_ce: 0.020485 loss_dice: 0.140117\n",
            "iteration 13155 : loss : 0.154153, loss_ce: 0.042782 loss_dice: 0.228401\n",
            "iteration 13156 : loss : 0.190469, loss_ce: 0.022541 loss_dice: 0.302421\n",
            "iteration 13157 : loss : 0.192013, loss_ce: 0.034385 loss_dice: 0.297098\n",
            "iteration 13158 : loss : 0.112713, loss_ce: 0.022252 loss_dice: 0.173021\n",
            "iteration 13159 : loss : 0.142702, loss_ce: 0.063789 loss_dice: 0.195311\n",
            "iteration 13160 : loss : 0.148925, loss_ce: 0.051747 loss_dice: 0.213710\n",
            "iteration 13161 : loss : 0.139413, loss_ce: 0.032447 loss_dice: 0.210725\n",
            "iteration 13162 : loss : 0.143160, loss_ce: 0.025742 loss_dice: 0.221439\n",
            "iteration 13163 : loss : 0.182823, loss_ce: 0.032392 loss_dice: 0.283110\n",
            "iteration 13164 : loss : 0.106186, loss_ce: 0.034734 loss_dice: 0.153821\n",
            "iteration 13165 : loss : 0.164463, loss_ce: 0.070418 loss_dice: 0.227160\n",
            "iteration 13166 : loss : 0.170881, loss_ce: 0.018775 loss_dice: 0.272285\n",
            "iteration 13167 : loss : 0.144328, loss_ce: 0.021481 loss_dice: 0.226226\n",
            "iteration 13168 : loss : 0.137477, loss_ce: 0.031732 loss_dice: 0.207973\n",
            "iteration 13169 : loss : 0.244296, loss_ce: 0.004359 loss_dice: 0.404253\n",
            "iteration 13170 : loss : 0.202163, loss_ce: 0.092031 loss_dice: 0.275584\n",
            "iteration 13171 : loss : 0.156828, loss_ce: 0.045166 loss_dice: 0.231269\n",
            "iteration 13172 : loss : 0.123826, loss_ce: 0.070158 loss_dice: 0.159604\n",
            "iteration 13173 : loss : 0.156231, loss_ce: 0.047892 loss_dice: 0.228456\n",
            "iteration 13174 : loss : 0.187842, loss_ce: 0.106171 loss_dice: 0.242289\n",
            "iteration 13175 : loss : 0.111256, loss_ce: 0.016899 loss_dice: 0.174161\n",
            "iteration 13176 : loss : 0.139899, loss_ce: 0.044503 loss_dice: 0.203496\n",
            "iteration 13177 : loss : 0.218400, loss_ce: 0.004990 loss_dice: 0.360673\n",
            "iteration 13178 : loss : 0.177751, loss_ce: 0.041963 loss_dice: 0.268276\n",
            "iteration 13179 : loss : 0.129338, loss_ce: 0.023883 loss_dice: 0.199641\n",
            "iteration 13180 : loss : 0.068596, loss_ce: 0.021594 loss_dice: 0.099930\n",
            "iteration 13181 : loss : 0.109620, loss_ce: 0.062752 loss_dice: 0.140865\n",
            "iteration 13182 : loss : 0.151382, loss_ce: 0.031965 loss_dice: 0.230994\n",
            "iteration 13183 : loss : 0.114124, loss_ce: 0.039516 loss_dice: 0.163862\n",
            "iteration 13184 : loss : 0.135706, loss_ce: 0.047914 loss_dice: 0.194234\n",
            "iteration 13185 : loss : 0.171889, loss_ce: 0.055126 loss_dice: 0.249731\n",
            "iteration 13186 : loss : 0.113446, loss_ce: 0.055005 loss_dice: 0.152407\n",
            "iteration 13187 : loss : 0.273895, loss_ce: 0.004612 loss_dice: 0.453418\n",
            "iteration 13188 : loss : 0.093834, loss_ce: 0.027720 loss_dice: 0.137910\n",
            "iteration 13189 : loss : 0.152108, loss_ce: 0.049423 loss_dice: 0.220564\n",
            "iteration 13190 : loss : 0.130553, loss_ce: 0.033462 loss_dice: 0.195281\n",
            "iteration 13191 : loss : 0.182893, loss_ce: 0.031537 loss_dice: 0.283796\n",
            "iteration 13192 : loss : 0.105331, loss_ce: 0.042450 loss_dice: 0.147251\n",
            "iteration 13193 : loss : 0.092304, loss_ce: 0.033943 loss_dice: 0.131211\n",
            "iteration 13194 : loss : 0.101429, loss_ce: 0.034942 loss_dice: 0.145754\n",
            "iteration 13195 : loss : 0.124498, loss_ce: 0.022341 loss_dice: 0.192602\n",
            "iteration 13196 : loss : 0.257419, loss_ce: 0.010752 loss_dice: 0.421863\n",
            "iteration 13197 : loss : 0.073300, loss_ce: 0.031815 loss_dice: 0.100957\n",
            "iteration 13198 : loss : 0.186143, loss_ce: 0.010500 loss_dice: 0.303237\n",
            "iteration 13199 : loss : 0.189467, loss_ce: 0.053349 loss_dice: 0.280213\n",
            "iteration 13200 : loss : 0.154974, loss_ce: 0.029253 loss_dice: 0.238788\n",
            "iteration 13201 : loss : 0.111538, loss_ce: 0.017367 loss_dice: 0.174318\n",
            "iteration 13202 : loss : 0.138417, loss_ce: 0.028972 loss_dice: 0.211380\n",
            "iteration 13203 : loss : 0.045778, loss_ce: 0.014870 loss_dice: 0.066383\n",
            "iteration 13204 : loss : 0.194391, loss_ce: 0.017530 loss_dice: 0.312298\n",
            "iteration 13205 : loss : 0.151209, loss_ce: 0.023159 loss_dice: 0.236576\n",
            "iteration 13206 : loss : 0.157192, loss_ce: 0.053525 loss_dice: 0.226303\n",
            "iteration 13207 : loss : 0.112343, loss_ce: 0.028135 loss_dice: 0.168482\n",
            "iteration 13208 : loss : 0.138346, loss_ce: 0.029969 loss_dice: 0.210596\n",
            "iteration 13209 : loss : 0.183916, loss_ce: 0.040722 loss_dice: 0.279378\n",
            "iteration 13210 : loss : 0.085799, loss_ce: 0.021552 loss_dice: 0.128630\n",
            "iteration 13211 : loss : 0.125058, loss_ce: 0.024987 loss_dice: 0.191772\n",
            "iteration 13212 : loss : 0.152041, loss_ce: 0.042244 loss_dice: 0.225238\n",
            "iteration 13213 : loss : 0.085120, loss_ce: 0.027216 loss_dice: 0.123724\n",
            "iteration 13214 : loss : 0.112219, loss_ce: 0.032001 loss_dice: 0.165699\n",
            "iteration 13215 : loss : 0.173534, loss_ce: 0.039379 loss_dice: 0.262971\n",
            "iteration 13216 : loss : 0.109636, loss_ce: 0.021023 loss_dice: 0.168712\n",
            "iteration 13217 : loss : 0.186955, loss_ce: 0.057029 loss_dice: 0.273573\n",
            "iteration 13218 : loss : 0.179139, loss_ce: 0.015538 loss_dice: 0.288207\n",
            "iteration 13219 : loss : 0.092571, loss_ce: 0.024431 loss_dice: 0.137998\n",
            "iteration 13220 : loss : 0.236202, loss_ce: 0.020644 loss_dice: 0.379907\n",
            "iteration 13221 : loss : 0.068305, loss_ce: 0.029368 loss_dice: 0.094264\n",
            "iteration 13222 : loss : 0.313140, loss_ce: 0.002326 loss_dice: 0.520348\n",
            "iteration 13223 : loss : 0.157623, loss_ce: 0.056986 loss_dice: 0.224714\n",
            "iteration 13224 : loss : 0.137578, loss_ce: 0.024484 loss_dice: 0.212974\n",
            "iteration 13225 : loss : 0.170072, loss_ce: 0.032738 loss_dice: 0.261627\n",
            "iteration 13226 : loss : 0.180160, loss_ce: 0.085949 loss_dice: 0.242967\n",
            "iteration 13227 : loss : 0.252826, loss_ce: 0.017593 loss_dice: 0.409648\n",
            "iteration 13228 : loss : 0.163752, loss_ce: 0.035484 loss_dice: 0.249263\n",
            "iteration 13229 : loss : 0.134599, loss_ce: 0.046036 loss_dice: 0.193641\n",
            "iteration 13230 : loss : 0.166460, loss_ce: 0.069951 loss_dice: 0.230800\n",
            "iteration 13231 : loss : 0.156583, loss_ce: 0.026964 loss_dice: 0.242996\n",
            "iteration 13232 : loss : 0.164245, loss_ce: 0.058235 loss_dice: 0.234918\n",
            "iteration 13233 : loss : 0.195608, loss_ce: 0.016598 loss_dice: 0.314947\n",
            "iteration 13234 : loss : 0.163830, loss_ce: 0.051550 loss_dice: 0.238684\n",
            "iteration 13235 : loss : 0.136627, loss_ce: 0.024605 loss_dice: 0.211308\n",
            "iteration 13236 : loss : 0.098473, loss_ce: 0.041564 loss_dice: 0.136411\n",
            "iteration 13237 : loss : 0.122535, loss_ce: 0.015351 loss_dice: 0.193991\n",
            "iteration 13238 : loss : 0.098097, loss_ce: 0.006478 loss_dice: 0.159177\n",
            "iteration 13239 : loss : 0.092648, loss_ce: 0.025070 loss_dice: 0.137699\n",
            "iteration 13240 : loss : 0.137218, loss_ce: 0.014603 loss_dice: 0.218961\n",
            "iteration 13241 : loss : 0.146874, loss_ce: 0.030892 loss_dice: 0.224196\n",
            "iteration 13242 : loss : 0.161126, loss_ce: 0.045879 loss_dice: 0.237957\n",
            "iteration 13243 : loss : 0.126461, loss_ce: 0.017007 loss_dice: 0.199430\n",
            "iteration 13244 : loss : 0.062745, loss_ce: 0.025252 loss_dice: 0.087740\n",
            "iteration 13245 : loss : 0.117978, loss_ce: 0.031338 loss_dice: 0.175737\n",
            "iteration 13246 : loss : 0.132859, loss_ce: 0.059735 loss_dice: 0.181608\n",
            "iteration 13247 : loss : 0.205809, loss_ce: 0.027789 loss_dice: 0.324489\n",
            "iteration 13248 : loss : 0.142380, loss_ce: 0.039989 loss_dice: 0.210640\n",
            "iteration 13249 : loss : 0.175997, loss_ce: 0.022425 loss_dice: 0.278379\n",
            "iteration 13250 : loss : 0.108316, loss_ce: 0.030550 loss_dice: 0.160161\n",
            "iteration 13251 : loss : 0.101321, loss_ce: 0.014819 loss_dice: 0.158988\n",
            "iteration 13252 : loss : 0.232372, loss_ce: 0.019515 loss_dice: 0.374277\n",
            "iteration 13253 : loss : 0.220213, loss_ce: 0.027506 loss_dice: 0.348685\n",
            "iteration 13254 : loss : 0.151767, loss_ce: 0.059830 loss_dice: 0.213058\n",
            "iteration 13255 : loss : 0.118122, loss_ce: 0.047642 loss_dice: 0.165108\n",
            "iteration 13256 : loss : 0.142954, loss_ce: 0.037186 loss_dice: 0.213467\n",
            "iteration 13257 : loss : 0.064149, loss_ce: 0.012529 loss_dice: 0.098563\n",
            "iteration 13258 : loss : 0.037850, loss_ce: 0.011271 loss_dice: 0.055570\n",
            "iteration 13259 : loss : 0.123189, loss_ce: 0.012879 loss_dice: 0.196729\n",
            "iteration 13260 : loss : 0.102164, loss_ce: 0.034155 loss_dice: 0.147504\n",
            "iteration 13261 : loss : 0.113982, loss_ce: 0.014605 loss_dice: 0.180234\n",
            "iteration 13262 : loss : 0.113933, loss_ce: 0.050492 loss_dice: 0.156227\n",
            "iteration 13263 : loss : 0.226974, loss_ce: 0.049480 loss_dice: 0.345303\n",
            "iteration 13264 : loss : 0.160645, loss_ce: 0.016063 loss_dice: 0.257032\n",
            "iteration 13265 : loss : 0.119503, loss_ce: 0.020154 loss_dice: 0.185736\n",
            "iteration 13266 : loss : 0.150841, loss_ce: 0.033432 loss_dice: 0.229114\n",
            "iteration 13267 : loss : 0.125499, loss_ce: 0.023629 loss_dice: 0.193412\n",
            "iteration 13268 : loss : 0.055595, loss_ce: 0.020554 loss_dice: 0.078956\n",
            "iteration 13269 : loss : 0.215208, loss_ce: 0.030734 loss_dice: 0.338191\n",
            "iteration 13270 : loss : 0.198719, loss_ce: 0.009541 loss_dice: 0.324837\n",
            "iteration 13271 : loss : 0.176125, loss_ce: 0.026238 loss_dice: 0.276050\n",
            "iteration 13272 : loss : 0.161286, loss_ce: 0.038896 loss_dice: 0.242879\n",
            "iteration 13273 : loss : 0.129330, loss_ce: 0.019901 loss_dice: 0.202283\n",
            "iteration 13274 : loss : 0.069062, loss_ce: 0.017644 loss_dice: 0.103340\n",
            "iteration 13275 : loss : 0.151492, loss_ce: 0.024290 loss_dice: 0.236294\n",
            "iteration 13276 : loss : 0.226240, loss_ce: 0.014612 loss_dice: 0.367325\n",
            "iteration 13277 : loss : 0.136862, loss_ce: 0.048852 loss_dice: 0.195536\n",
            "iteration 13278 : loss : 0.114000, loss_ce: 0.025722 loss_dice: 0.172852\n",
            "iteration 13279 : loss : 0.145125, loss_ce: 0.030547 loss_dice: 0.221511\n",
            "iteration 13280 : loss : 0.136373, loss_ce: 0.041788 loss_dice: 0.199430\n",
            "iteration 13281 : loss : 0.088277, loss_ce: 0.019019 loss_dice: 0.134448\n",
            "iteration 13282 : loss : 0.090791, loss_ce: 0.024083 loss_dice: 0.135262\n",
            "iteration 13283 : loss : 0.148569, loss_ce: 0.013621 loss_dice: 0.238535\n",
            "iteration 13284 : loss : 0.155200, loss_ce: 0.007542 loss_dice: 0.253639\n",
            "iteration 13285 : loss : 0.141630, loss_ce: 0.023609 loss_dice: 0.220310\n",
            "iteration 13286 : loss : 0.105575, loss_ce: 0.042392 loss_dice: 0.147697\n",
            "iteration 13287 : loss : 0.090400, loss_ce: 0.024445 loss_dice: 0.134370\n",
            "iteration 13288 : loss : 0.161131, loss_ce: 0.035102 loss_dice: 0.245150\n",
            "iteration 13289 : loss : 0.210445, loss_ce: 0.025336 loss_dice: 0.333851\n",
            "iteration 13290 : loss : 0.142799, loss_ce: 0.028858 loss_dice: 0.218759\n",
            "iteration 13291 : loss : 0.205517, loss_ce: 0.023772 loss_dice: 0.326680\n",
            "iteration 13292 : loss : 0.152344, loss_ce: 0.031710 loss_dice: 0.232767\n",
            "iteration 13293 : loss : 0.271251, loss_ce: 0.029141 loss_dice: 0.432658\n",
            "iteration 13294 : loss : 0.153509, loss_ce: 0.038946 loss_dice: 0.229884\n",
            "iteration 13295 : loss : 0.228442, loss_ce: 0.016499 loss_dice: 0.369737\n",
            "iteration 13296 : loss : 0.196781, loss_ce: 0.021008 loss_dice: 0.313963\n",
            "iteration 13297 : loss : 0.156182, loss_ce: 0.025842 loss_dice: 0.243075\n",
            "iteration 13298 : loss : 0.089011, loss_ce: 0.029076 loss_dice: 0.128968\n",
            "iteration 13299 : loss : 0.152328, loss_ce: 0.024625 loss_dice: 0.237464\n",
            "iteration 13300 : loss : 0.134121, loss_ce: 0.031277 loss_dice: 0.202683\n",
            "iteration 13301 : loss : 0.078039, loss_ce: 0.037083 loss_dice: 0.105342\n",
            "iteration 13302 : loss : 0.098821, loss_ce: 0.044354 loss_dice: 0.135132\n",
            "iteration 13303 : loss : 0.157975, loss_ce: 0.030921 loss_dice: 0.242677\n",
            "iteration 13304 : loss : 0.132952, loss_ce: 0.034440 loss_dice: 0.198627\n",
            "iteration 13305 : loss : 0.164387, loss_ce: 0.020993 loss_dice: 0.259983\n",
            "iteration 13306 : loss : 0.147208, loss_ce: 0.043962 loss_dice: 0.216038\n",
            "iteration 13307 : loss : 0.243812, loss_ce: 0.027834 loss_dice: 0.387796\n",
            "iteration 13308 : loss : 0.173186, loss_ce: 0.006333 loss_dice: 0.284422\n",
            "iteration 13309 : loss : 0.127142, loss_ce: 0.020469 loss_dice: 0.198258\n",
            "iteration 13310 : loss : 0.135812, loss_ce: 0.013288 loss_dice: 0.217495\n",
            "iteration 13311 : loss : 0.093100, loss_ce: 0.012937 loss_dice: 0.146543\n",
            "iteration 13312 : loss : 0.177198, loss_ce: 0.007962 loss_dice: 0.290022\n",
            "iteration 13313 : loss : 0.133645, loss_ce: 0.030952 loss_dice: 0.202106\n",
            "iteration 13314 : loss : 0.067031, loss_ce: 0.021448 loss_dice: 0.097420\n",
            "iteration 13315 : loss : 0.128977, loss_ce: 0.060976 loss_dice: 0.174310\n",
            "iteration 13316 : loss : 0.081816, loss_ce: 0.016190 loss_dice: 0.125566\n",
            "iteration 13317 : loss : 0.139357, loss_ce: 0.035006 loss_dice: 0.208925\n",
            "iteration 13318 : loss : 0.090735, loss_ce: 0.026235 loss_dice: 0.133734\n",
            "iteration 13319 : loss : 0.139866, loss_ce: 0.022222 loss_dice: 0.218295\n",
            "iteration 13320 : loss : 0.220767, loss_ce: 0.015115 loss_dice: 0.357868\n",
            "save model to ./results/BEFUnet/BEFUnet_epoch_59.pth\n",
            "********************\n",
            "Running Inference after epoch 59\n",
            "Epoch 59\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A idx 0 case case0008 mean_dice 0.527483 mean_hd95 30.636650\n",
            "\n",
            "1it [02:22, 142.98s/it]\u001b[A idx 1 case case0022 mean_dice 0.715070 mean_hd95 18.322215\n",
            "\n",
            "2it [03:43, 106.28s/it]\u001b[A idx 2 case case0038 mean_dice 0.565883 mean_hd95 53.851136\n",
            "\n",
            "3it [05:15, 99.67s/it] \u001b[A idx 3 case case0036 mean_dice 0.675156 mean_hd95 55.171583\n",
            "\n",
            "4it [08:05, 127.40s/it]\u001b[A idx 4 case case0032 mean_dice 0.746482 mean_hd95 14.706409\n",
            "\n",
            "5it [10:18, 129.60s/it]\u001b[A idx 5 case case0002 mean_dice 0.800829 mean_hd95 7.087470\n",
            "\n",
            "6it [12:25, 128.54s/it]\u001b[A idx 6 case case0029 mean_dice 0.466246 mean_hd95 65.831767\n",
            "\n",
            "7it [13:42, 111.69s/it]\u001b[A idx 7 case case0003 mean_dice 0.544476 mean_hd95 79.176967\n",
            "\n",
            "8it [16:55, 137.64s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "!python train.py --root_path ./data/Synapse/train_npz --test_path ./data/Synapse/test_vol_h5 --batch_size 10 --eval_interval 20 --max_epochs 500 --model_name BEFUnet --num_workers 2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}